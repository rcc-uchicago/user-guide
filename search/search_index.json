{"config":{"lang":["en"],"separator":"[\\s\\.]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the Research Computing Center's (RCC) clusters user guide! Here, you'll find everything you need to know about accessing and utilizing the high-performance computing (HPC) resources offered by the University of Chicago's RCC.</p>"},{"location":"#how-to-use-rcc-high-performance-computing-clusters","title":"How to Use RCC High-Performance Computing Clusters","text":"<p>Getting Started: Explore the different types of RCC accounts available and learn how to apply for a PI (Principal Investigator) or general user account. Discover what comes with your RCC account to make the most of our services. </p> <p>Storage:  Learn how to store and access files on RCC ecosystems, including transferring files from your local computer to RCC systems for seamless integration.</p> <p>Computing:  Connect to RCC compute nodes and gain access to a wide array of software tools to support your research endeavors.</p> <p>Collaboration and Reproducibility:  Find out how to facilitate collaboration by extending RCC account access to non-UChicago collaborators. Ensure reproducibility in your projects with our user-friendly tools and environments.</p> <p>Getting Help: Access troubleshooting resources using this user guide, visit our lab at REG 216 or email us at help@rcc.uchicago.edu. </p> <p>Glossary: Consult our glossary for an overview of the key terms used throughout this user guide, ensuring clarity and understanding as you navigate RCC's resources. </p> <p>Whether you're a seasoned researcher or just getting started, RCC is here to support your computational needs every step of the way. Let's embark on this journey of discovery together! </p>"},{"location":"beagle3-overview/","title":"Beagle3","text":""},{"location":"beagle3-overview/#what-is-beagle3","title":"What is Beagle3?","text":"<p>Beagle3 is a high-performance computing cluster funded by the NIH grant led by Professor Benoit Roux, the Amgen Professor of Biochemistry and Molecular Biology. The project benefits biomedical research with cutting-edge HPC resources for modeling and large-scale simulations of the molecular building blocks for biological functions. The cluster also serves research projects that employ recent advances in imaging technology, like cryo-electronic microscopy, for producing images of molecules at unprecedented resolution. The enormous amount of data rapidly generated need commensurate amounts of computing horsepower to analyze. Beagle3 has been in service since February 2022.</p> <p>Beagle3 consists of 44 computing nodes, each with an 32-core Intel Xeon Gold 6346 CPUs and 4 NVIDIA A100 graphics processing units (GPUs).</p>"},{"location":"beagle3-overview/#gaining-access","title":"Gaining Access","text":"<p>You should contact your PI for access to Beagle3. You can also contact our Help Desk for assistance.</p>"},{"location":"beagle3-overview/#partitions","title":"Partitions","text":"Beagle3 Partition Nodes CPUs CPU Type GPUs GPU Type Total Memory beagle3 22 32 gold-6346 4 a40 256 GB beagle3 22 32 gold-6346 4 a100 256 GB beagle3 4 32 gold-6346 None None 512 GB"},{"location":"beagle3-overview/#quality-of-service","title":"Quality-of-Service","text":"<p>There are two quality-of-service (QoS) options available on the beagle3 partition. You can specify either one by using the --qos flag in your sbatch scripts or sinteractive commands.</p> <p><code>--qos=beagle3</code>: This QoS allows you to request up to 256 CPU-cores and 32 GPUs, and a maximum wall time of 48 hours. It is the default QoS for the beagle3 partition.</p> <p><code>--qos=beagle3-long</code>: This QoS allows you to request up to 128 CPU-cores and 16 GPUs, and a maximum wall time of 96 hours.</p>"},{"location":"beagle3-overview/#connecting-and-running-jobs","title":"Connecting and Running Jobs","text":"<p>You connect to and run jobs on Beagle3 in a similar manner to Midway. Your home space is the same on Midway3, and you can access other mount points on Beagle3 from Midway3 as well.</p>"},{"location":"beagle3-overview/#troubleshooting","title":"Troubleshooting","text":"<p>For further assistance, please contact our Help Desk.</p>"},{"location":"clusters/","title":"Hardware Overview","text":""},{"location":"clusters/#midway3-hpc-cluster","title":"Midway3 HPC Cluster","text":""},{"location":"clusters/#operating-system-and-connectivity","title":"Operating System and Connectivity","text":"<p>Midway3 runs CentOs 8, and all nodes are connected via HDR Mellanox InfiniBand (100 Gbps) Interconnect.</p>"},{"location":"clusters/#standard-compute-nodes","title":"Standard Compute Nodes","text":"<ul> <li>210 Intel Cascade Lake CPU-only compute nodes, each equipped with:<ul> <li>2x Intel Xeon Gold 6248R (48 cores per node)</li> <li>960 GB Local SSD Storage </li> <li>192 GB Memory </li> </ul> </li> </ul>"},{"location":"clusters/#specialized-nodes","title":"Specialized Nodes","text":""},{"location":"clusters/#gpu-nodes","title":"GPU Nodes","text":"<p>There are 11 GPU nodes that are part of the Midway3 communal resources. Each GPU node has the Standard Intel Compute Node specifications and the following GPU configurations:</p> <ul> <li>5 GPU nodes w/ 4x NVIDIA V100 GPUs per node</li> <li>5 GPU nodes w/ 4x NVIDIA Quadro RTX 6000 GPUs per node</li> <li>1 GPU node w/ 4x NVIDIA A100 GPUs per node</li> </ul>"},{"location":"clusters/#big-memory-nodes","title":"Big Memory Nodes","text":"<p>There are 2 big memory nodes available to all users. Each big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations:</p> <ul> <li>1 node w/ 768 GB of memory</li> <li>1 node w/ 1.54 TB of memory</li> </ul>"},{"location":"clusters/#amd-nodes","title":"AMD Nodes","text":"<p>There are 40 nodes with AMD CPUs and the following configuration:</p> <ul> <li>2x AMD EPYC Rome processors (128 cores per node)</li> <li>960 GB Local SSD Storage </li> <li>256 GB Memory</li> </ul>"},{"location":"clusters/#midway2-hpc-cluster","title":"Midway2 HPC Cluster","text":""},{"location":"clusters/#operating-system-and-connectivity_1","title":"Operating System and Connectivity","text":"<p>Midway2 runs CentOs 8, and all standard nodes are connected via HDR InfiniBand (100 Gbps) interconnect.</p>"},{"location":"clusters/#standard-compute-nodes_1","title":"Standard Compute Nodes","text":"<ul> <li>115 Intel Broadwell CPU-only compute nodes, each equipped with:<ul> <li>2x Intel E5-2680 v4 (28 cores per node)</li> <li>400 GB Local SSD Storage </li> <li>64 GB Memory </li> </ul> </li> </ul>"},{"location":"clusters/#specialized-nodes_1","title":"Specialized Nodes","text":""},{"location":"clusters/#gpu-nodes_1","title":"GPU Nodes","text":"<p>There are 6 GPU nodes that are part of the Midway2 communal resources. Each GPU node has the following configuration:</p> <ul> <li>GPU: 2x Nvidia K80</li> <li>CPU: 2 * Intel E5-2680 v4  2.40 GHz</li> <li>Memory: 128 GB </li> <li>Interconnect: InfiniBand FDR 56 Gb/s</li> </ul>"},{"location":"clusters/#big-memory-nodes_1","title":"Big Memory Nodes","text":"<p>There is 1 big memory node available to all users. The big memory node has the Standard Intel Compute Node specifications, but with the following larger memory configurations:</p> <ul> <li>1 node w/ 512 GB of memory</li> </ul>"},{"location":"http/","title":"HTTP - Public folder","text":"<p>Midway2 only</p> <p>Please note that HTTP-based data sharing is currently supported on Midway2 only.</p> <p>RCC provides web access to data on their storage system via public_html directories in users\u2019 home directories.</p> Local path Corresponding URL /home/[your_CNetID]/public_html/research.dat http://users.rcc.uchicago.edu/~[your_CNetID]/research.dat <p>Ensure your home directory and <code>public_html</code> have the execute permissions. If the folder <code>public_html</code> does not exist, create it.  Optionally, ensure public_html has read permissions if you would like to allow indexing.</p> <p>You may set these permissions using the following commands: <pre><code>chmod o+x $HOME\nmkdir -p $HOME/public_html\nchmod o+x $HOME/public_html\n// optional; if you would like to allow directory listing.\nchmod o+r $HOME/public_html\n</code></pre> Files in public_html must also be readable by the web user, \"other\", but should not be made executable.</p> <p>You may set read permissions for web users/\"other\" using the following command: <pre><code>chmod o+r $HOME/public_html/research.dat\n</code></pre></p> <p>Note</p> <p>Use of these directories must conform with the RCC usage policy. Please notify RCC if you expect a large number of people to access data hosted here.</p>"},{"location":"partitions/","title":"Partitions","text":"<p>Midway compute nodes are organized into \"partitions\", collections of compute nodes with similar characteristics, such as hardware configuration or ownership. When a user submits a job to a partition (via Slurm flag <code>--partition=&lt;partition&gt;</code>), the job is allocated by the Slurm scheduler to any idle compute node within that partition. If a user wants to submit a job to a particular compute node, this can be requested by adding <code>--nodelist=&lt;compute_node_ID&gt;</code>. Most users will submit jobs to a 'shared' partition: a partition accessible to all Midway users.  See the Slurm Partitions page for additional information about the Midway partitions.</p>"},{"location":"partitions/#how-do-i-get-a-full-list-of-partitions","title":"How Do I Get a Full List of Partitions?","text":"<p>To get a full list of partitions available On Midway2 or Midway3, log in to the system and type in the terminal: <pre><code>sinfo -o \"%20P %5D %14F %4c %8G %8z %26f %N\"\n</code></pre> The typical output will include: </p> Column Description <code>AVAIL_FEATURES</code> Available features such as CPUs, GPUs, and internode interfaces <code>NODELIST</code> IDs of the compute nodes within the given partition <code>NODES(A/I/O/T)</code> Number of nodes by state in the format \"allocated/idle/other/total\" <code>S:C:T</code> Number of sockets, cores, and threads <p>If a user wants to submit their job to the particular compute node, this can be requested by adding the Slurm flag <code>--nodelist=&lt;compute_node_ID&gt;</code>. Compute nodes that differ in available features can be allocated by setting an additional constraint <code>--constraint=&lt;compute_node_feature&gt;</code>; for example, <code>--constraint=v100</code> will allocate the job to the compute node with NVIDIA V100 GPUs. </p> <p>You can also check the state of nodes in a given partition, for example, <code>caslake</code>, by running the following command:  <pre><code>nodestatus caslake\n</code></pre></p>"},{"location":"partitions/#what-partitions-i-can-use","title":"What Partitions I Can Use?","text":"<p>To submit jobs to a partition, ensure that your account is accepted by the partition. Begin by determining the accounts you belong to. Then set the variable ACCOUNT to the account you would like to check (usually in the format pi-), and then retrieve the list of partitions using: <pre><code>groups\n</code></pre> Midway2Midway3, Midway-AMD, MidwaySSD, Beagle3 <p><pre><code>export ACCOUNT=&lt;account_name&gt;\n</code></pre> <pre><code>sacctmgr list assoc account=$ACCOUNT -n format=Partition | sort -u\n</code></pre></p> <p><pre><code>export ACCOUNT=&lt;account_name&gt;\n</code></pre> <pre><code>scontrol show partition | grep -B 1 -P \"(?=.*AllowAccounts)(?=.*$ACCOUNT) | (?=.*AllowAccounts=ALL)\" | grep Partition | sed 's/.*=//'\n</code></pre></p>"},{"location":"partitions/#configurations","title":"Configurations","text":"<p>All Midway users can submit jobs to any of the shared partitions.  Beagle3 users, in addition to shared partitions, have access to Beagle3 partitions too. </p> <p>Parameters are shown per node.</p> Midway2 - SharedDaLI - SharedMidway3 - SharedBeagle3 - DedicatedMidwaySSD - DedicatedKICP - Dedicated Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node Nodelist <code>broadwl</code> 323 28 e5-2680v4 None None 64 GB vary <code>broadwl-lc</code> 14 28 e5-2680v4 None None 64 GB midway2-[0203-0216] <code>bigmem2</code> 5 28 e5-2680v4 None None 512 GB midway2-bigmem[01-04,06] <code>gpu2</code> 6 28 e5-2680v4 4 k80 128 GB midway2-gpu[01-06] Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node Nodelist <code>dali</code> 29 40 gold-6148 None None 96 GB vary Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node Nodelist <code>caslake</code> 184 48 gold-6248r None None 192 GB vary <code>bigmem</code> 1 48 gold-6248r None None 768 GB midway3-0317 <code>bigmem</code> 1 48 gold-6248r None None 1536 GB midway3-0318 <code>amd-hm</code> 1 128 epyc-7702 None None 2048 GB midway3-0541 <code>amd</code> 40 128 epyc-7702 None None 256 GB midway3-0[501-539,549] <code>gpu</code> 1 48 gold-6248r 4 a100 384 GB midway3-0294 <code>gpu</code> 5 48 gold-6248r 4 v100 192 GB midway3-[0277-0281] <code>gpu</code> 5 48 gold-6248r 4 rtx6000 192 GB midway3-[0282-0286] Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node Nodelist <code>beagle3</code> 22 32 gold-6346 4 a100 256 GB beagle3-[0001-0022] <code>beagle3</code> 22 32 gold-6346 4 a40 256 GB beagle3-[0023-0044] <code>beagle3-bigmem</code> 4 32 gold-6346 None None 512 GB beagle3-bigmem[1-4] Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node Storage/node <code>ssd</code> 18 48 gold-6248r None None 192 GB 960 GB <code>ssd-gpu</code> 1 32 gold-6346 4 a100 256 GB 960 GB Partition # of Nodes # of Cores/node CPU Type # of GPUs/node GPU Type Memory/node <code>kicp</code> 6 48 gold-6248r None None 192 GB <code>kicp-gpu</code> 1 32 gold-5218 4 v100 192 GB"},{"location":"partitions/#partition-qos","title":"Partition QoS","text":"<p>This table details the job limits of each partition, set via a Quality of Service (QoS) accessible via  <pre><code>rcchelp qos\n</code></pre></p> Midway2 QoS - SharedMidway3 QoS - SharedMidwaySSD QoS - DedicatedKICP QoS - Dedicated Partition Max Nodes/User Max CPUs/User Max Jobs/User Max Wall Time <code>broadwl</code> 100 2800 100 36 H <code>gpu2</code> None None 10 36 H <code>bigmem2</code> None 112 5 36 H Partition Max Nodes/User Max CPUs/User Max Jobs/User Max Wall Time <code>caslake</code> 100 4800 1000 36 H <code>gpu</code> None None 12 36 H <code>bigmem</code> 96 192 10 36 H <code>amd</code> 64 128 200 36 H Partition Max Nodes/User Max CPUs/User Max Jobs/User Max Wall Time AllowAccount QoS <code>ssd</code> 5 240 N/A 36 H ssd ssd <code>ssd</code> 5 240 N/A 36 H ssd-stu ssd-stu <code>ssd-gpu</code> N/A N/A N/A 36 H ssd ssd <code>ssd-gpu</code> N/A N/A N/A 36 H ssd-stu ssd-stu Partition AllowAccount QoS Max Wall Time <code>kicp</code> kicp kicp 48 H <code>kicp-gpu</code> kicp kicp 48 H <p>You may apply for a special allocation if your research requires a temporary exception to a particular limit. Special allocations are evaluated on an individual basis and may or may not be granted.</p>"},{"location":"partitions/#private-partitions-cpp","title":"Private Partitions (CPP)","text":"<p>These partitions are typically associated with a PI or group of PIs. They can be shared with other PIs or researchers across the University of Chicago and with external collaborators with a Midway account. </p> <ul> <li>General Users: Check with your PI for more information. </li> <li>PIs: Private partitions can be purchased via Cluster Partnership Program to accommodate the needs of your research group. QOS can be tuned at any time by submitting a request.</li> </ul> <p>Note</p> <p>QoS for private and institutional partitions can be changed upon the owner's request. </p>"},{"location":"samba/","title":"SAMBA (Network drive)","text":"<p>SAMBA allows one to connect to (or \u201cmount\u201d) their home and project directories on their local computer.   </p> <p>Warning</p> <p>This method of accessing your RCC home and project space is only available from within the UChicago campus network. From off-campus, you will need to first connect through the UChicago VPN.</p> <p>Tip</p> <p>While transferring large files and/or datasets over SAMBA may be appealing, it slows file transfer for all other users. Please use Globus for large transfers.</p>"},{"location":"samba/#connecting-from-windows","title":"Connecting from Windows","text":"<p>On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which location on Midway you wish to connect to:  </p> Midway2, DaLIMidway3, Midway3-AMD, MidwaySSDBeagle3 HomeProject2ScratchCDSCDS2 <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\homes\n</code></pre> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\project2\n</code></pre> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\midway2-scratch\n</code></pre> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\cds\n</code></pre> <p>Note</p> <p>CDS storage can be mapped via Samba upon PI's request only.</p> <pre><code>\\\\midwaysmb.rcc.uchicago.edu\\cds2\n</code></pre> <p>Note</p> <p>CDS2 storage can be mapped via Samba upon PI's request only.</p> HomeProjectScratchCDS3 <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\homes\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\project\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\midway3-scratch\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\cds3\n</code></pre> Home (Midway3 Mirror)ProjectScratchCDS3 <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\homes\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\beagle3\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\beagle3-scratch\n</code></pre> <pre><code>\\\\midway3smb1.rcc.uchicago.edu\\cds3\n</code></pre> <p>Enter <code>ADLOCAL\\CNetID</code> for the username and enter your CNetID password.  </p> <p></p>"},{"location":"samba/#connecting-from-macos","title":"Connecting from macOS","text":"<p>On a macOS X computer, select \u201cConnect to Server\u201d (from \"Go\" dropdown in Finder) and enter one of the following URLs depending on which location on Midway you wish to connect to:  </p> Midway2, DaLIMidway3, Midway3-AMD, MidwaySSDBeagle3 HomeProject2ScratchCDSCDS2 <pre><code>smb://midwaysmb.rcc.uchicago.edu/homes\n</code></pre> <pre><code>smb://midwaysmb.rcc.uchicago.edu/project2\n</code></pre> <pre><code>smb://midwaysmb.rcc.uchicago.edu/midway2-scratch\n</code></pre> <pre><code>smb://midwaysmb.rcc.uchicago.edu/cds\n</code></pre> <p>Note</p> <p>CDS storage can be mapped via Samba upon PI's request only.</p> <pre><code>smb://midwaysmb.rcc.uchicago.edu/cds2\n</code></pre> <p>Note</p> <p>CDS2 storage can be mapped via Samba upon PI's request only.</p> HomeProjectScratchCDS3 <pre><code>smb://midway3smb1.rcc.uchicago.edu/homes\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/project\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/midway3-scratch\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/cds3\n</code></pre> Home (Midway3 Mirror)ProjectScratchCDS3 <pre><code>smb://midway3smb1.rcc.uchicago.edu/homes\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/beagle3\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/beagle3-scratch\n</code></pre> <pre><code>smb://midway3smb1.rcc.uchicago.edu/cds3\n</code></pre> <p>Enter <code>ADLOCAL\\CNetID</code> for the username and enter your CNetID password.  </p> <p> </p>"},{"location":"skyway-overview/","title":"Skyway","text":""},{"location":"skyway-overview/#what-is-skyway","title":"What is Skyway?","text":"<p>Skyway is an integrated platform developed at the RCC to allow users to burst computing workloads from the on-premise RCC cluster, Midway, to run on remote commercial cloud platforms such as Amazon AWS and Google GCP. Skyway enables users to run computing tasks in the cloud from Midway in a seamless manner without needing to learn how to provision cloud resources. Since the user does not need to setup or manage cloud resources themselves, the result is improved productivity with a minimum learning curve.</p> <p>Please refer to the Skyway home page for more information.</p>"},{"location":"skyway-overview/#gaining-access","title":"Gaining Access","text":"<p>You first need an active RCC User account (see accounts and allocations page). Next, you should contact your PI or class instructors for access to Skyway. Alternatively, you can contact our Help Desk for assistance.</p>"},{"location":"skyway-overview/#connecting-and-running-jobs","title":"Connecting and Running Jobs","text":"<p>Once your RCC User account is active, you log in to the Midway cluster with your <code>CNetID</code> <pre><code>  ssh [CNetID]@midway2.rcc.uchicago.edu\n</code></pre> then log in to Skyway from Midway2: <pre><code>  ssh [CNetID]@skyway.rcc.uchicago.edu\n</code></pre> If successful, you will get access to the Skyway login node, where you can access to the following locations:</p> <ol> <li><code>/home/[CNetID]</code> This is the temporary home directory (no backup) for users on Skyway. Note, this is NOT the home file system on Midway, so you won\u2019t see any contents from your home directory on midway. Please do NOT store any sizable or important data here. (<code>TODO</code>: Add note here about changing $HOME environment variable to <code>/cloud/aws/[CNetID]</code>.)</li> <li><code>/project</code> and <code>/project2</code> This is the RCC high-performance capacity storage file systems from Midway, mounted on Skyway, with the same quotas and usages as on Midway. Just as with running jobs on Midway, /project and /project2 should be treated as the location for users to store the data they intend to keep. This also acts as a way to make data accessible between Skyway and midway as the /project and /project2 filesystems are mounted on both systems. Run <code>cd /project/&lt;labshare&gt;</code> or <code>/project2/&lt;labshare&gt;</code>, where <code>&lt;labshare&gt;</code> is the name of the lab account, to access the files by your lab or group. This will work even if the lab share directory does not appear in a file listing, e.g., <code>ls /project</code>.</li> <li><code>/cloud/[cloud]/[CNetID]</code> Options of [cloud]: aws or gcp This is the cloud scratch folder (no backup), which is intended for read/write of cloud compute jobs. For example, with Amazon cloud resources (AWS) The remote cloud S3 AWS bucket storage is mounted to Skyway at this path. Before submitting jobs to the cloud compute resources, users must first stage the data, scripts and executables their cloud job will use to the /cloud/aws/[CNetID] folder. After running their cloud compute job, users should then copy the data they wish to keep from the /cloud/aws/[CNetID] folder back to their project folder. Similarly, if users are using Google Cloud Platform (GCP), the scratch folder /cloud/gcp/[CNetID] should be used.</li> </ol> <p>You can create your own folders, upload data, write and compile codes, prepare job scripts and submit jobs in a similar manner to what you do on Midway.</p> <p>Skyway provides compiled software packages (i.e. <code>modules</code>) that you can load to build your codes or run your jobs. The list of the modules is given in the Skyway home page.</p> <p>You submit jobs to SLURM in a similar manner to what do on Midway. The difference is that you should specify different partitions and accounts corresponding to the cloud services you have access to (e.g. AWS or GCP). Additionally, the instance configuration should be specified via <code>--constraint</code>.</p>"},{"location":"skyway-overview/#troubleshooting","title":"Troubleshooting","text":"<p>For further assistance, please contact our Help Desk.</p>"},{"location":"101/","title":"Introduction","text":"<p>This tutorial shows the basic steps to use the Midway3 cluster at the RCC.  For complete RCC technical documentation, see the main sections of this user guide.</p>"},{"location":"101/#summary","title":"Summary","text":"<p>In this tutorial, you will learn how to log in to Midway3, build your codes and/or load installed software packages, prepare input data and job scripts, and submit jobs to Slurm.</p>"},{"location":"101/#getting-help","title":"Getting Help","text":"<p>RCC support staff is available to assist with technical issues (help logging in, questions about using the cluster, etc).  Please don\u2019t hesitate to ask questions if you encounter any technical issues.</p> <ul> <li> <p>The preferred way of requesting support is to contact our Help Desk.</p> </li> <li> <p>RCC\u2019s walk-in lab is open during business hours and is located in Regenstein Library room 216. Feel free to drop by to chat with one of our staff members if you get stuck.</p> </li> </ul>"},{"location":"101/accounts/","title":"How to Apply for an RCC Account","text":"<p>Discovering the world of high-performance computing at RCC is as easy as pie! We've streamlined the account application process into two main categories: Principal Investigator (PI) accounts and General User accounts. If you're a course instructor, we've got you covered with the option to apply for an Education account.</p> <p> </p>"},{"location":"101/accounts/#principal-investigator-pi-accounts","title":"Principal Investigator (PI) Accounts","text":"<p>Since October 2018, distinguished academics with titles like professor, associate professor, assistant professor, and more are eligible to dive into the wonders of RCC with a PI account.</p> <ul> <li>Apply for an RCC PI account here.</li> <li>Check eligibility criteria for University of Chicago Principal Investigators here.</li> </ul>"},{"location":"101/accounts/#general-user-accounts","title":"General User Accounts","text":"<p>Everyone else, from graduate students to external collaborators, can grab an RCC general user account. Just keep in mind, a PI with an active RCC account must be your sponsor.</p> <ul> <li>Apply for an RCC general user account here.</li> </ul>"},{"location":"101/accounts/#education-accounts","title":"Education Accounts","text":"<p>Instructors aiming to bring the power of RCC clusters to their courses can apply for an RCC Education account quarterly using the provided form.</p> <ul> <li>Apply for an RCC education account here.</li> </ul> <p>Note: Instructors can request to carry course materials over to the next quarter or academic year by contacting help@rcc.uchicago.edu.</p>"},{"location":"101/accounts/#accounts-faq","title":"Accounts FAQ","text":""},{"location":"101/accounts/#new-rcc-users","title":"New RCC users","text":""},{"location":"101/accounts/#how-do-i-become-an-rcc-user","title":"How do I become an RCC user?","text":"<p>Submitting RCC user account requests is a breeze using our online application forms. Get all the details at RCC Account Request.</p>"},{"location":"101/accounts/#how-do-i-request-access-to-a-pis-rcc-resources","title":"How do I request access to a PI\u2019s RCC resources?","text":"<p>Simply submit a user account request with your CNetID and the PI Account name. The PI will get an automated email for authorization.</p>"},{"location":"101/accounts/#what-is-my-rcc-username-and-password","title":"What is my RCC username and password?","text":"<p>Your RCC credentials are the same as your University of Chicago CNetID. Once your RCC account is ready, your username and password will match your CNetID credentials. </p>"},{"location":"101/accounts/#can-an-external-collaborator-get-a-cnetid","title":"Can an external collaborator get a CNetID?","text":"<p>Absolutely! RCC can create CNetIDs for external collaborators. Dig into the details at RCC Account Request.</p>"},{"location":"101/accounts/#how-do-i-access-rcc-systems","title":"How do I access RCC systems?","text":"<p>Accessing RCC systems is a multi-faceted journey. Use an SSH client with enabled X11 forwarding or ThinLinc (remote desktop) for interactive access. Explore more details on Accessing RCC resources. For file access, employ SCP, Globus Online, or SAMBA.</p>"},{"location":"101/accounts/#current-rcc-users","title":"Current RCC users","text":""},{"location":"101/accounts/#how-do-i-changereset-my-password","title":"How do I change/reset my password?","text":"<p>UChicago IT services handle CNetID passwords. For changes or resets, reach out to IT services.</p>"},{"location":"101/accounts/#multiple-affiliations","title":"Multiple affiliations","text":"<p>Embrace multiple affiliations! Both general users and PIs can join multiple pi-accounts by submitting a general user account request. No need to fret about losing memberships; it's all about expanding possibilities.</p>"},{"location":"101/accounts/#what-groups-am-i-a-member-of","title":"What groups am I a member of?","text":"<p>To explore your group memberships, log into any Midway ecosystems login nodes through <code>SSH</code> and type <code>groups</code>.</p>"},{"location":"101/accounts/#leaving-uchicago","title":"Leaving UChicago","text":""},{"location":"101/accounts/#what-if-my-cnetid-password-doesnt-work-after-leaving-the-university","title":"What if my CNetID password doesn't work after leaving the university?","text":"<p>If you've left the university and can't log in, contact our Help Desk to request re-enabling access to your account.  To reenable your CNetID, you will need to request an RCC account extension.  </p>"},{"location":"101/accounts/#will-i-still-have-access-to-my-rcc-account-after-leaving-the-university","title":"Will I still have access to my RCC account after leaving the University?","text":"<p>Typically, UChicago IT will terminate your CNetID a few months after you leave. To keey using Midway clusters, request an RCC account extension.</p>"},{"location":"101/accounts/#what-to-do-after-completing-a-project","title":"What to Do After Completing a Project","text":"<p>Once your project is complete, it's essential to ensure smooth handover and file management. Follow these steps:</p> <ol> <li> <p>Grant Group Access: Allow your group members access to your files using the following SSH command:</p> <pre><code>chmod 2771 -R &lt;your_folders&gt;\n</code></pre> <p>For example:</p> <pre><code>chmod 2771 -R /project/drpepper/cell-tracker\n</code></pre> <p>This command sets the appropriate permissions for your folders.</p> </li> <li> <p>Assign Group Ownership: Ensure that your account's PI is the group owner of your files with:</p> <pre><code>chgrp pi-drpepper -R &lt;your_folders&gt;\n</code></pre> <p>For example:</p> <pre><code>chgrp pi-drpepper -R /project/drpepper/cell-tracker\n</code></pre> <p>This step facilitates proper file management within your research group.</p> </li> </ol> <p>Footnote: For an in-depth dive, visit the accounts and allocations page on our main website.</p>"},{"location":"101/allocations/","title":"Allocations and Service Units FAQ","text":""},{"location":"101/allocations/#what-is-an-allocation","title":"What is an allocation?","text":"<p>An allocation is a system designed to ensure fair usage of computing resources (service units) and storage (Gigabytes) granted to a Principal Investigator (PI) or an education account.</p>"},{"location":"101/allocations/#service-units-sus","title":"Service Units (SUs)","text":"<p>In simple terms, you consume service units as you run jobs on shared compute nodes. Applying for service units incurs no cost for PIs and is solely a means to ensure fair usage of shared compute nodes. Please refer to RCC Allocations for more detailed information. Note that certain nodes or partitions, such as those in the Cluster Partnership Program, as well as private nodes and partitions like Beagle3 and MidwaySSD, do not consume service units when utilized since they are not shared resources. </p>"},{"location":"101/allocations/#storage","title":"Storage","text":"<p>RCC offers a limited volume of free group share storage alongside service units when a PI applies for an allocation. If you require additional storage space beyond what is allocated, please contact our CPP team at cpp@rcc.uchicago.edu.</p>"},{"location":"101/allocations/#what-is-a-service-unit-su","title":"What is a service unit (SU)?","text":"<p>As you execute jobs on shared compute nodes at RCC, you deplete service units, akin to utilizing fuel. By imposing a cap on the number of service units that can be consumed per academic year, we ensure equitable utilization of our shared compute nodes. For a more precise definition, please visit RCC Service Units.</p>"},{"location":"101/allocations/#how-do-i-obtain-an-allocation","title":"How do I obtain an allocation?","text":"<p>For detailed information on obtaining an allocation, please refer to RCC Allocations.</p>"},{"location":"101/allocations/#how-does-rcc-calculate-the-service-units-used-for-running-a-job-on-shared-nodes","title":"How does RCC calculate the service units used for running a job on shared nodes?","text":"<p>For insights into how RCC calculates the service units expended during job execution on shared nodes, please consult RCC Allocations.</p>"},{"location":"101/allocations/#how-do-i-check-how-many-service-units-i-have-remaining-on-my-allocation","title":"How do I check how many service units I have remaining on my allocation?","text":"<p>The <code>accounts</code> tool offers a convenient means to check your account balance. Simply log into RCC clusters via <code>ssh</code> and execute the following command:</p> <pre><code>accounts balance  \n</code></pre> <p>You can also log into your MyRCC profile and check the service units of the accounts they are a member of in a user-friendly web interface.</p>"},{"location":"101/allocations/#how-do-i-review-the-usage-of-my-allocation","title":"How do I review the usage of my allocation?","text":"<p>The <code>accounts</code> tool provides several options for summarizing the usage of the allocations to which your RCC account has access to. To obtain a summary, execute the command <code>accounts usage</code> with the account name(s):</p> Midway2, DaLIMidway3, Beagle3 <pre><code>accounts usage\naccounts usage --account [pi-cnetid]\naccounts usage --accounts [pi-cnetid1],[pi-cnetid2]\n</code></pre> <pre><code>accounts usage\naccounts usage -a [pi-cnetid]\n</code></pre> <p>where <code>[pi-cnetid]</code> is the name of the account, often your PI's.</p> <p>You may use the <code>--byuser</code> option to view individual usage by group members:</p> Midway2, DaLIMidway3, Beagle3 <pre><code>accounts usage\naccounts usage --account [pi-cnetid] --byuser\n</code></pre> <pre><code>accounts usage\naccounts usage -a [pi-cnetid] -byuser\n</code></pre> <p>You can also use the <code>rcchelp</code> command (a wrapper of system-provided tools including <code>accounts</code>), which requires slightly different arguments (note only one character '-')</p> Midway2, DaLIMidway3, Beagle3 <pre><code>rcchelp usage \nrcchelp usage -account [pi-cnetid] -byuser\n</code></pre> <pre><code>rcchelp usage \nrcchelp usage -a [pi-cnetid] -byuser\n</code></pre> <p>To view the resource usage per job, you need to run on Midway2/DaLI using either <code>accounts</code>:</p> Midway2, DaLI <pre><code>accounts usage --byjob\naccounts usage --account [pi-cnetid] --byjob\n</code></pre> <p>or <code>rcchelp</code></p> Midway2, DaLI <pre><code>rcchelp usage -byjob\nrcchelp usage -account [pi-cnetid] -byjob\n</code></pre> <p>both of which include the jobs on both Midway2 and Midway3 partitions (e.g. <code>caslake</code> and <code>gpu</code>). </p> <p>Note</p> <p>These commands, although executed on Midway2 ecosystem, provide the necessary information about jobs run on both Midway2 and Midway3.</p> <p>The output is a table that lists the job IDs, partitions, number of CPU cores and SU consumptions. To further check the resource consumption of a job on Midway3, you need to log in to Midway3 and run <code>sacct -j</code> with the job ID. </p> <p>If the job is still running, you can use <code>scontrol show job</code> with the job ID to check the job information.</p> <p>For additional details on account creation, visit the accounts and allocations page on our main website.</p>"},{"location":"101/connecting/","title":"Accessing RCC clusters","text":"<p>This tutorial shows the basic steps to use the Midway3 cluster at the RCC. For complete RCC technical documentation, see the main sections of this user guide. The information here describes how users can connect to Midway to access RCC resources. All users are responsible for knowing and abiding by the RCC User Policy.</p>"},{"location":"101/connecting/#rcc-account-credentials","title":"RCC account credentials","text":"<p>To connect to RCC resources, you must have an RCC user account (request an account). Your RCC account uses your UChicago CNetID and its corresponding password: </p> <pre><code>Username: CNetID\nPassword: CNetID password\n</code></pre> <p>Copy code</p> <p>Wherever you see grey boxes like the one above, click the icon in the top right corner of the box to copy the contents to your clipboard. It's especially useful for longer code snippets! </p>"},{"location":"101/connecting/#supported-protocols","title":"Supported protocols","text":"<p>There are six methods to access RCC resources. The following table provides a summary of these methods:</p> Connection Method Description Access to Compute Nodes Data Transfer Data Sharing Secure Shell (SSH) Can be used to access data and software packages Yes Yes (two-way) RCC Internal ThinLinc A remote desktop to access data and software packages Yes Yes (two-way) RCC Internal Open OnDemand A web-based portal used to access data and software packages Yes Yes (two-way) RCC Internal + Globus SAMBA (SMB) Can be used to access data No Yes (two-way) No Globus Can be used to access and share data and scheduled data transfers No Yes (two-way) External and RCC collaborators HTTP Can be used to share data for public access (legacy service) No Yes (one-way) Public"},{"location":"101/connecting/#sshsftp","title":"SSH/SFTP","text":"<p>Here you will use Secure Shell (SSH) to connect to the login node from your local machine. </p> <p><code>ssh [your-cnetid]@midway3.rcc.uchicago.edu <pre><code>After putting in your password, you will choose an option to accept a push on the Duo app. If successful, you will land on your home folder on the Midway3 login node as shown at the command prompt `[your-cnetid]@midway3-login3` or `[your-cnetid]@midway3-login4`.\n\nYou can check where the present working directory by running the command `pwd`:\n</code></pre> pwd</code></p>"},{"location":"101/data/","title":"Data Storage","text":""},{"location":"101/data/#getting-your-data-ready","title":"Getting your data ready","text":"<p>Midway3 compute nodes have access to <code>/project</code> and <code>/project2</code>, in addition to the shared scratch space <code>/scratch/midway3</code>. It is recommended that you put your input and output data under one of those spaces for fast access from the compute nodes. See Storage for more details.</p> <p><pre><code>cd /project/[pi-folder]/[your-cnetid]\ngit clone https://github.com/[some-data-pool.git]\n</code></pre> or <pre><code>wget [some-url]\n</code></pre></p> <p>In this tutorial, let us say we have the input data in the <code>examples</code> folder in the <code>lammps</code> repo from above.</p>"},{"location":"101/ecosystems/","title":"Overview of RCC's HPC Systems","text":"<p>The University of Chicago Research Computing Center (RCC) hosts a diverse range of professionally managed high-performance computing clusters, forming the backbone of the RCC's advanced computational infrastructure. Notable clusters include Midway2, Midway3, Midway3-AMD, MidwaySSD, DaLI, Beagle3, KICP, GM4, MidwayR family, and Skyway.</p>"},{"location":"101/ecosystems/#midway-3-ecosystem","title":"Midway 3 ecosystem","text":""},{"location":"101/ecosystems/#shared-computing-partitions","title":"Shared computing partitions","text":""},{"location":"101/ecosystems/#midway3-and-midway3-amd","title":"Midway3, and Midway3-AMD","text":"<p>In 2021, Midway3 and Midway3-AMD were introduced as flagship clusters for multi-purpose scientific computing. It is recommended that new users opt for Midway3 due to its latest hardware and software modules. </p>"},{"location":"101/ecosystems/#restricted-computing-partitions","title":"Restricted computing partitions","text":""},{"location":"101/ecosystems/#beagle3","title":"Beagle3","text":"<p>Funded by an NIH grant, Beagle3, part of Midway3 ecosystems, supports biomedical research with cutting-edge HPC resources, specializing in modeling and large-scale simulations of molecular structures. Launched in February 2022, Beagle3 features 44 compute nodes with Intel CPUs and NVIDIA GPUs.</p>"},{"location":"101/ecosystems/#midwayssd","title":"MidwaySSD","text":"<p>MidwaySSD, part of the Midway3 ecosystem, serves computationally intensive Social Science Division research and educational purposes. </p>"},{"location":"101/ecosystems/#skyway","title":"Skyway","text":"<p>Skyway allows users to seamlessly burst computing workloads through Midway 2 and 3 ecosystems to remote commercial cloud platforms like Amazon Web Services (AWS) and Google Cloud: Cloud Computing Services (GCP). It simplifies cloud computing tasks without requiring users to manage cloud resources. </p>"},{"location":"101/ecosystems/#cpp-nodes","title":"CPP nodes","text":"<p>Cluster Partnership Program (CPP) or private nodes. </p>"},{"location":"101/ecosystems/#sde-midwayr-ecosystems-r1-r2-and-r3","title":"SDE MidwayR ecosystems (R1, R2, and R3)","text":""},{"location":"101/ecosystems/#sde-midwayr","title":"SDE MidwayR","text":"<p>MidwayR, within the Secure Data Enclave, provides a secure computing environment for research with high-security standards. It features a setup similar to Midway but tailored for secure data protection. </p>"},{"location":"101/ecosystems/#midway-2-ecosystem","title":"Midway 2 ecosystem","text":""},{"location":"101/ecosystems/#shared-computing-partitions_1","title":"Shared computing partitions","text":""},{"location":"101/ecosystems/#midway2","title":"Midway2","text":"<p>Midway2, succeeding the original Midway in 2016, boasts advanced features. </p>"},{"location":"101/ecosystems/#restricted-computing-partitions_1","title":"Restricted computing partitions","text":""},{"location":"101/ecosystems/#dali","title":"DaLI","text":"<p>DaLI, the Data Lifecycle Instrument, as a part of the Midway2 ecosystem, facilitates data management and sharing, offering a unified workflow for acquiring, transferring, processing, and storing experimental and observational data. It enhances data lifecycle management, sharing, and publication, supporting outreach and education.</p>"},{"location":"101/ecosystems/#gm4","title":"GM4","text":"<p>GM4, a GPU-enabled cluster, is part of the Midway2 ecosystem and facilitates multiscale materials modeling and machine learning, supporting diverse molecular dynamics and continuum simulations. Funded by the NSF under the MRI program, GM4 promotes collaborative efforts in algorithm and software development.</p>"},{"location":"101/ecosystems/#cpp-nodes_1","title":"CPP nodes","text":"<p>Cluster Partnership Program (CPP) or private nodes. </p>"},{"location":"101/glossary/","title":"Glossary","text":"<p>Welcome to the RCC Glossary, your go-to guide for understanding the key terms in high-performance computing (HPC). Let's demystify the world of clusters, nodes, and parallel processing!</p> Term Meaning Batch job <p>A job is the Slurm\u2019s computing unit by which resources are allocated and shared. Users create job submission scripts to ask Slurm for resources such as cores, memory, walltime, etc. Slurm puts the requests in a queue and allocates requested resources based on jobs\u2019 priority.</p> Compute cluster <p>A group of independent computers connected via a fast network interconnect, managed by a resource manage, and act as a large parallel computer. Each node in a cluster can be a shared memory parallel computer.</p> Compute node <p>A compute node is a stand-alone computer connected to other compute nodes via a fast network interconnect. A compute node is where a batch job runs and is not usually accessible directly by the users.</p> Core <p>Smallest computation unit that can run a program (used to be called a processor, still is, also called a CPU \u2013 Central Processing Unit).</p> <p>Distributed memory architecture</p> <p>Distributed memory architecture refers to a way to create a parallel computer. In this architecture, stand-alone compute nodes are connected using a fast interconnect such as Infiniband and exchange messages over the network.</p> FLOPS <p>Floating point Operation Per Second (FLOPS) is a measure of computing performance in terms of number of floating operations that a CPU can perfomr per second. Modern CPUs are capable of doing Tera FLOPS (10^12 floating point operations per second).</p> GPU <p>Graphics Processing Unit (GPU) is a specialized device initially used to generate computer output. GPUs have their own memory but should be hosted in a node. Each compute node can host one or more GPUs. Modern GPUs have many simple compute cores and have been used for parallel processing.</p> HPC <p>High Performance Computing (HPC) refers to the practice of aggregating computing power to achieve higher performance that would not possible by using a typical computer.</p> Infiniband <p>A computer network standard featuring high bandwidth and low latency. The current Infiniband devices are capable of transferring data at up to 100Gbits/sec with less than a microsecond latency. As of this writing, the popular Infiniband versions are FDR (Fourteen Data Rate) with 56Gbits/sec and EDR (Enhanced Data Rate) with 100Gbits/sec.</p> Job Login node <p>Login nodes (a.k.a. head nodes) are point of access to a parallel computer. Users usually connect to login nodes via SSH to compile and debug their code, review their results, do some simple tests, and submit their batch jobs to the parallel computer.</p> Modules <p>An open source software management tool used in most HPC facilities. Using modules enable users to selectively pick the software that they want and add them to their environment.</p> Node <p>A stand-alone computer system that contains one or more sockets, memory, storage, etc. connected to other nodes via a fast network interconnect.</p> OpenMP <p>Open Multi Processing (OpenMP) is a parallel programming model designed for shared memory architecture. In this programming mode, programmers insert compiler directives in their code and the compiler generates a code that can run on more than one core.</p> Partition <p>A subset of a compute cluster with a common feature. For example, compute nodes with GPU could form a partition.</p> <p>Shared memory architecture</p> <p>Shared memory architecture is a way to create a parallel computer. In this architecture, a large memory is shared among many cores and communication between cores is done via the shared memory. By introducing the multi-core CPUs, each computer is a shared-memory parallel computer.</p> Slurm <p>Simple Linux Utility for Resource Management (SLURM) is a software that manages high performance computing resources. SLURM coordinates running of many programs on a shared facility and makes sure that resources are used in a fair share manner.</p> Socket <p>A computational unit, packaged as one and usually made of a single chip often called processor. Modern sockets carry many cores (2, 4 on most laptops, 8 to 16 on most servers).</p> SSH <p>Secure Shell (SSH) is a protocol to securely access remote computers. Based on the client-server model, multiple users with an SSH client can access to a remote computer. Some operating systems such as Linux and Mac OS have a built-in SSH client and others can use one of many publicly available clients.</p> <p>Tightly-coupled nodes</p> <p>A set of compute nodes connected via fast Infiniband interconnect. These nodes can exchange data in a fast rate and are used to solve big problems that cannot fit in a single computer.</p> Walltime <p>The time that requires a program to finish execution.</p>"},{"location":"101/helpdesk/","title":"Helpdesk","text":""},{"location":"101/helpdesk/#help-requests","title":"Help Requests","text":"<p>You can contact us to get technical user support for RCC systems related issues. Please provide the RCC staff with all useful information when requesting assistance and submit requests using your UChicago email address. In the following section, we include instructions to submit an informative ticket.  </p> <ul> <li>Write an informative subject/title to the ticket/email that can include details such as cluster name, software name, brief description of the issue</li> <li>Submit screenshots of the error message when possible</li> <li>Explain briefly what you are trying to do and the problem you are encountering</li> <li>Include instructions on how to reproduce your issue with relevant details such as:<ul> <li>Submit the list of modules that were loaded<ul> <li>Output of <code>module list</code> command</li> </ul> </li> <li>Submit the <code>sbatch</code> script, along with the <code>.err</code> and <code>.out</code> files</li> <li>Submit the commands that led to the error, along with the error message</li> <li>Submit the job ID for SLURM job related issues  </li> <li>Submit the output of command <code>pwd</code> to inform us of your working directory  </li> </ul> </li> </ul> <p>We look forwarding to assisting you!</p>"},{"location":"101/jobs/","title":"Computing","text":""},{"location":"101/jobs/#running-jobs-on-the-compute-nodes","title":"Running jobs on the compute nodes","text":"<p>See Running Jobs on Midway for detailed documentation on how to run your own programs on the cluster once you've connected. In this tutorial, we will try interactive session and submit a batch job.</p> <p>Before running any job, you need to check if your account has any eligible allocations:</p> <pre><code>rcchelp balance\n</code></pre> <p>If you don't have any PI account, or if the balance column has negative numbers, then you cannot run any jobs on the shared partitions on Midway3. More on allocations can be found at Allocations.</p>"},{"location":"101/jobs/#interactive-session","title":"Interactive session","text":"<p>On the Midway3 login node, request an interactive node with 8 CPU cores:</p> <pre><code>sinteractive -A [pi-account] -p caslake -N 1 --ntasks-per-node=8\n</code></pre> <p>which will take a while to get you a compute node. This is because the <code>sinteractive</code> command essentially invokes the Slurm command <code>salloc</code> with the requested resource, and waits for the Slurm manager to return the resource. If successful, you will see an empty screen with the command prompt <code>[your-cnetid]@midway3-0xyz</code>, indicating that you are on the compute node node <code>midway3-0xyz</code>.</p> <p>You can load python as you did on the login node: <pre><code>module load python\n</code></pre></p> <p>and run <code>python</code></p> <pre><code>[your-cnetid@midway3-0xyz ] python\nPython 3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:50:21) \n[GCC 12.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\n</code></pre> <p>After quitting <code>python</code>, you can activate the environment you created, and list the installed packages</p> <p><pre><code>source /project/[pi-folder]/[your-cnetid]/my-venv/bin/activate\npip list\n</code></pre> You should see <code>numpy</code>, <code>matplotlib</code> and <code>pandas</code> installed in this environment.</p> <p>Let us prepare a simple Python script, namely, <code>simple.py</code> with a text editor like <code>nano</code>, in the current folder, with the following content:</p> <p><pre><code>import numpy as np\nfrom matplotlib import pyplot as plt \nx = np.arange(1,11) \ny = 2 * x + 5 \nplt.title(\"Matplotlib demo\") \nplt.xlabel(\"x axis caption\") \nplt.ylabel(\"y axis caption\") \nplt.plot(x,y)\nplt.savefig(\"output.pdf\", format=\"pdf\")\n</code></pre> And run it with </p> <pre><code>python simple.py\n</code></pre> <p>which should produce a file <code>output.pdf</code>.</p> <p>Change to the input data folder <pre><code>cd /project/[pi-folder]/[your-cnetid]/lammps/examples\n</code></pre></p> <p>Load the same modules you used to build LAMMPS (except <code>cmake</code>)</p> <pre><code>module load mpich/3.4.3+gcc-10.2.0 mkl/2023.1\n</code></pre> <p>Relax the locked memory limit <pre><code>ulimit -l unlimited\n</code></pre></p> <p>Run the LAMMPS binary you built above <pre><code>mpirun -np 8 /project/[pi-folder]/[your-cnetid]/lammps/build/lmp -in melt/in.melt\n</code></pre></p> <p>The run will produce the LAMMPS screen output and a file named <code>log.lammps</code> in the current folder.</p> <p>To terminate the interactive session, run</p> <pre><code>exit\n</code></pre> <p>You will get back to the login node.</p>"},{"location":"101/jobs/#batch-jobs","title":"Batch jobs","text":"<p>Next, let us run the same calculations in the batch mode. First, create a text file with <code>nano</code> or <code>vi</code> on the login node, namely, <code>batch_job_python.txt</code></p> <pre><code>#!/bin/bash\n#SBATCH --job-name=job-info\n#SBATCH --account=[pi-account]\n#SBATCH --partition=caslake\n#SBATCH --time=00:30:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\ncd /project/[pi-folder]/[your-cnetid]/\nsource my-venv/bin/activate\npython simple.py\n</code></pre> <p>Next, submit the job to Slurm <pre><code>sbatch batch_job_python.txt\n</code></pre></p> <p>Check your submitted job in the queue with</p> <pre><code>squeue -u $USER\n</code></pre> <p>Next, to test a run with LAMMPS in the batch mode, create another text file with <code>nano</code> or <code>vi</code> on the login node, namely, <code>batch_job_lammps.txt</code></p> <pre><code>#!/bin/bash\n#SBATCH --job-name=job-info\n#SBATCH --account=[pi-account]\n#SBATCH --partition=caslake\n#SBATCH --time=00:30:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\ncd /project/[pi-folder]/[your-cnetid]/lammps/examples\nmodule load mpich/3.4.3+gcc-10.2.0 mkl/2023.1\nulimit -l unlimited\nn=$(( SLURM_NNODES * SLURM_NTASKS_PER_NODE ))\nmpirun -np $n /project/[pi-folder]/[your-cnetid]/lammps/build/lmp -in melt/in.melt\n</code></pre> <p>After saving the file (Ctrl+X with <code>nano</code>, <code>:x</code> with <code>vi</code>), you will submit the script to Slurm:</p> <pre><code>sbatch batch_job_lammps.txt\n</code></pre> <p>As you can see, you can submit more than one jobs at a time. The more resource you request (number of nodes, number of tasks per node, memory per node, walltime and so on), the longer the jobs are pending.  Your usage history also affects how soon your jobs get running.  See Running Jobs on Midway for detailed documentation on how to monitor the submitted jobs.</p> <p>You can check the generated output <code>output.pdf</code> and <code>log.lammps</code> in the corresponding directories.</p>"},{"location":"101/mistakes/","title":"Common mistakes to avoid","text":"<p>Mistakes happen, but with a little know-how, you can steer clear of common pitfalls that might trip you up on your RCC journey. Here's what to watch out for: </p> <ol> <li> <p>Don't Overstuff Your Storage: Do not go over your storage quota. Going over your storage quota can spell trouble, leading to job failures, cryptic error messages, and X11 forwarding woes. Keep tabs on your usage with the <code>accounts quota</code> command and avoid unnecessary headaches. Learn more about what to do if you find yourself over quota here.</p> </li> <li> <p>Beware of Conda Environments: Do not install conda environments using <code>conda create --name=&lt;env_name&gt;</code>.  Installing Anaconda environments in the wrong directory can quickly eat up precious storage space. Avoid the trap by creating virtual environments in the <code>/project</code> directory instead. Check out the command to do so and save yourself the hassle. By default, this command will install a virtual conda environment into the <code>/home</code> directory with a low quota. Because Anaconda environments often require a large amount of storage and a number of files, this may easily result in exceeding quota. Instead install virtual environments inside /project or /project2 directories by running <code>conda create --prefix=/project/&lt;PI_CnetID&gt;/&lt;CNetID/anaconda/&lt;env_name&gt;</code>.</p> </li> <li> <p>Do not run jobs on the login nodes.  The login nodes are for quick tasks, not heavy lifting. Save the computational heavyweights for the Slurm job scheduler, or risk getting your account benched. When you connect to a cluster via SSH, you land on the login node, which all users share. The login node is reserved for submitting jobs, compiling codes, installing software, and running short tests that use only a few CPU cores and finish within a few minutes. Anything more intensive must be submitted to the Slurm job scheduler as either a batch or interactive job. Failure to comply with this rule may result in your account being temporarily suspended.</p> </li> <li> <p>Stay Offline in Jobs: Do not try to access the Internet from batch or interactive jobs.  Don't waste precious service units by allocating more CPU cores than you need for serial jobs. Keep it efficient and stick to one core for the job at hand. Jobs submitted to Slurm's domain don't have internet access. Plan ahead and make sure any necessary downloads or installations are done on the login node before you hit submit. All jobs submitted to the Slurm job scheduler run on compute nodes without Internet access, including ThinLinc sessions. Because of this, a running job cannot download files, install packages, or connect to GitHub. Before submitting the job, you will need to perform these operations on the login node.</p> </li> <li> <p>One Core is Enough for Serial Jobs: Do not allocate more than one CPU core for serial jobs.  Before diving into parallel computing, make sure you've done your scaling analysis. It's the smart move for maximizing efficiency and resource utilization. Serial codes cannot run in parallel, so using more than one CPU core will not cause the job to run faster. Instead, doing so will waste SUs allocated to your PI. Visit the Batch jobs page of the user guide to learn about job arrays, which are a convenient way to submit a large number of independent processing jobs, and run parallel batch jobs.</p> </li> <li> <p>Scale Up Responsibly: Do not run jobs with a parallel code without conducting a scaling analysis. If your code runs in parallel, you need to determine the optimal number of nodes and CPU cores. The same is true if it can use multiple GPUs. To do this, perform a scaling analysis.</p> </li> <li> <p>GPU for GPU Codes Only: Do not request a GPU for a code that can only use CPUs. Only codes explicitly written to use GPUs can take advantage of GPUs.  Don't hog the GPUs unless your code can actually put them to good use. Allocating resources you don't need only slows things down for everyone else. Allocating a GPU for a CPU-only code will not speed up the execution time, but it will increase your queue time, waste resources, and lower the priority of your next job submission. Furthermore, some codes are written to use only a single GPU.</p> </li> <li> <p>Keep Your GCC Up-to-Date: Do not use the system GCC when a newer version is needed Don't let outdated tools hold you back. If you need a newer version of GCC, load it up and keep your development environment cutting-edge. The GNU Compiler Collection (GCC) provides a suite of compilers (gcc, g++, gfortran) and related tools. You can determine the version of the system GCC by running the command \"gcc --version\". If the system version is insufficient then load the appropriate environment module to make a newer version available. Run the command \"module avail gcc\". Learn more about environment modules in the Software section of the user guide.</p> </li> <li> <p>Name That Module: Do not load environment modules using only the partial name. When loading environment modules, be specific. Don't leave it to chance\u2014use the full name to avoid any surprises down the line. When loading environment modules, be specific. Don't leave it to chance\u2014use the full name to avoid any surprises down the line. A common practice for Python users is to issue the \"module load python\" command. You should always specify the full name of the environment module (e.g., module load python/anaconda-2022.05) to ensure the default version hasn't changed. Also, you should avoid loading environment modules in your ~/.bashrc file. Instead, do this in Slurm scripts and on the command line when needed.</p> </li> <li> <p>Mind Your Scratch: Do not write temporary files to <code>/scratch</code> if your job has high throughput I/O If your job deals with lots of small files, think twice about dumping them in <code>/scratch</code>. Consider your options and choose wisely to optimize performance. Temporary files may accumulate and exceed your quota (both in size and/or number of files) unless removed on time. If your job is not distributed across multiple nodes and has high throughput I/O of many small files (size &lt; 4 MB), you may perform faster if you write temporary files to local rather than global scratch. You can learn about different types of scratch and when to use them in the Storage section of the user guide.</p> </li> <li> <p>Build Smart:: Do not compile and install heavy software using login nodes Heavy software installations belong in the build partition, not on the login nodes. Keep the system humming along smoothly by following the rules of the road. Sometimes software installation time can be dramatically reduced by using multiple cores. However, compute-intensive jobs are not permitted on login nodes and may be killed to provide equal opportunities for other connected users. Instead of login nodes, use a build partition dedicated to software installation.</p> </li> </ol> <p>By sidestepping these common missteps, you'll be on the fast track to success in no time. Happy computing!</p>"},{"location":"101/policies/","title":"RCC Terms of Use","text":"<p>Welcome to the Research Computing Center (RCC), where you gain access to a diverse range of clusters, computer systems, networks, applications, and technological assets. To ensure a positive and responsible experience, please familiarize yourself with the RCC Terms of Use outlined below. By using RCC resources, you agree to abide by these rules, ensuring ethical and lawful use.</p>"},{"location":"101/policies/#general-usage","title":"General Usage","text":"<p>Abiding by the following principles is mandatory for utilizing RCC resources responsibly:</p> <ul> <li>Responsibility: Users are accountable for proper tool utilization and maintaining confidentiality. In addition, they must maintain an environment in which all RCC users can fairly access RCC clusters to run jobs or store data. </li> <li>Legality and Ethics: RCC resources must not be used for illegal, malicious, or unethical purposes.</li> <li>Respect: Users should refrain from unauthorized use, academic dishonesty, or violation of software licenses.</li> <li>Confidentiality: Respect the privacy of individuals and report any security breach promptly.</li> <li>Security: Users must not attempt to circumvent system security or resource allocation mechanisms.</li> <li>Monitoring: Be aware that all activities on RCC systems are subject to monitoring.</li> </ul> <p>Failure to follow these principles may result in account termination.</p> <p>RCC resources are dedicated to supporting legitimate research activities at the University of Chicago, and users must align with their account's stated purpose.</p>"},{"location":"101/policies/#user-accounts-and-passwords","title":"User Accounts and Passwords","text":"<p>Account credentials are personal and should not be shared. If compromised, report immediately to RCC support staff. Sharing account or password information is strictly prohibited.</p>"},{"location":"101/policies/#data-management","title":"Data Management","text":"<p>RCC maintains an open research network but assumes no responsibility for data stored on the general-purpose HPC systems it operates. In these collaborative environments, researchers are responsible for overseeing the protection and sharing of their own data. Access to user data by RCC system administrators is limited to what is necessary for user support, technical troubleshooting, or maintaining system security, in accordance with UChicago Information Technology Policies.</p>"},{"location":"101/policies/#restricted-research-data","title":"Restricted Research Data","text":"<p>General-purpose RCC systems should not be used to store, process, transmit, or analyze restricted research data. Please contact us regarding your project as we offer a separate service, Secure Data Enclave, with resources dedicated to research on restricted data.</p>"},{"location":"101/policies/#data-integrity-and-retention","title":"Data Integrity and Retention","text":"<p>The RCC prioritizes robust filesystems and archival storage with performance and reliability. Backup services are limited and available only for directories with snapshots enabled. Users with specific data retention needs should notify RCC support staff for appropriate actions. </p> <p>Please adhere to these guidelines to ensure a positive and secure RCC experience. </p> <p>If you have any questions regarding these terms of use, please get in touch with us at help@rcc.uchicago.edu.  </p>"},{"location":"101/software/","title":"Software","text":""},{"location":"101/software/#getting-your-software-ready","title":"Getting your software ready","text":"<p>You should check what software packages are already installed on Midway3 via <code>module avail</code> and <code>module list</code>. Many commonly used software packages and libraries have been installed on Midway for your use.  For an overview of how to use Software Modules on Midway, consult the RCC Software documentation page.</p> <p>For this tutorial, let us load <code>python</code></p> <pre><code>module load python\n</code></pre> <p>which will load the default version of the <code>python/anaconda</code> module. You can do <code>module list</code> to see which version is just loaded.</p> <p>Suppose that you would like to install numpy, matplotlib and pandas for your calculations.  You should first create an environment in your own space and install these packages into this environment.  See managing Python environments for more information.</p> <p>Since Python environments might contain many files and/or take a lot space, it is recommended that you create your environments somewhere outside your home folder such as <code>/project</code> or <code>/scratch</code>. Suppose that your PI has a space under <code>/project/[pi-folder]</code> and you have a folder under that location.</p> <pre><code>cd /project/[pi-folder]/[your-cnetid]\npython -m venv my-venv\nsource ./my-venv/bin/activate\npip install matplotlib numpy pandas\n</code></pre> <p>Note that the base environment of the default <code>python</code> module already has many popular packages installed, including the above 3 packages. You can also create an environment and install packages with <code>conda</code> or <code>mamba</code>.</p> <p>If you need to compile your software packages from source, you can download the software source code from GitHub to your space, load the compiler modules and build the codes. In this tutorial, let us build LAMMPS from source code:</p> <pre><code>cd /project/[pi-folder]/[your-cnetid]\ngit clone https://github.com/lammps/lammps.git\ncd lammps\nmkdir build &amp;&amp; cd build\n</code></pre> <p>Load the modules for the preferred compiler, MPI libraries and MKL, and cmake to configure the build: <pre><code>module load mpich/3.4.3+gcc-10.2.0 mkl/2023.1 cmake/3.26\ncmake ../cmake -C ../cmake/presets/basic.cmake -DFFT=MKL -DFFTW3_INCLUDE_DIR=$MKLROOT/include/fftw\n</code></pre></p> <p>and finally build the code</p> <pre><code>make -j4\n</code></pre> <p>If the build succeeds, you will see a LAMMPS binary, namely <code>lmp</code>, generated under the folder <code>/project/[pi-folder]/[your-cnetid]/build</code>.</p> <p>You can use other compilers (Intel oneAPI, GNU GCC) and MPI libraries (OpenMPI, MPICH). For GPU codes, you can use NVIDIA HPC SDK and Intel oneAPI. More information on the available development tools is given in Compilers. </p>"},{"location":"databases/alphafold/","title":"AlphaFold/ColabFold datasets","text":"<p>The datasets for AlphaFold, AlphaFold 3 and ColabFold are available on Midway3. </p> <p>The datasets contain Multiple Sequence Alignment (MSA) data (Unifref90, MGnify, BFD, Uniclust30) for identifying homologous sequences that align with the input sequences and structure templates (PDB70 and PDB100) for predicting structures of the input sequences.</p> <p>The paths to these datasets are as follows:</p> Path AlphaFold 2 <code>/software/alphafold-data-2.3</code> AlphaFold 3 <code>/software/alphafold3.0-el8-x86_64/databases</code> ColabFold <code>/software/colabfold-data</code> <p>Please contact the RCC to request for updating the datasets when necessary.  Example uses of these datasets with AlphaFold can be found in AlphaFold.</p>"},{"location":"databases/bfi/","title":"BFI databases","text":"<p>List of BFI databases hosted on Midway2: </p> Database Name Point of contact (PoC) Group name Directory bfi-la_voters bfi-datagrants[@]uchicago[.]edu data-bfi-voter <code>/project2/databases/bfi/bfi-la_voters</code> bfi-loan bfi-datagrants[@]uchicago[.]edu data-bfi-loan <code>/project2/databases/bfi/bfi-loan</code> bfi-tax_deed bfi-datagrants[@]uchicago[.]edu data-bfi-tax_deed <code>/project2/databases/bfi/bfi-tax_deed</code> bfi-ushousehold bfi-datagrants[@]uchicago[.]edu data-bfi-ushousehold <code>/project2/databases/bfi/bfi-ushousehold</code> bfi-vgs bfi-datagrants[@]uchicago[.]edu data-bfi-vgs <code>/project2/databases/bfi/bfi-vgs</code> bfi-data-voter bfi-datagrants[@]uchicago[.]edu data-bfi-voter <code>/project2/databases/bfi/bfi-data-voter</code>"},{"location":"databases/bfi/#eligibility","title":"Eligibility","text":"<ul> <li>All University of Chicago faculty members (PIs) are eligible to request access to the BFI databases with approval from the designated point of contact (PoC) for the database.</li> <li>After the PI and database\u2019s PoC approval have been received, students, post-doctoral researchers, and collaborators, among others, can access the databases. </li> </ul>"},{"location":"databases/bfi/#accessing-databases","title":"Accessing databases","text":""},{"location":"databases/bfi/#method-1-smb-shared-drive","title":"Method 1: SMB - Shared Drive","text":""},{"location":"databases/bfi/#microsoft-windows","title":"Microsoft Windows","text":"<p>On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which database on Midway2 you wish to connect to, for example, <code>bfi-data-voter</code> here: </p> <p><code>\\\\midwaysmb.rcc.uchicago.edu\\project2\\databases\\bfi\\bfi-data-voter</code></p> <p>Enter <code>ADLOCAL\\{CNetID}</code> for the username and enter your CNetID password.</p>"},{"location":"databases/bfi/#apple-macos","title":"Apple macOS","text":"<p>On a macOS X computer, select \u201cConnect to Server\u201d (from the \u201cGo\u201d dropdown in Finder) and enter one of the following URLs depending on which database on Midway 2 you wish to connect to, for example, <code>bfi-data-voter</code> here:</p> <p><code>smb://midwaysmb.rcc.uchicago.edu/project2/databases/bfi/bfi-data-voter</code></p> <p>Enter <code>ADLOCAL\\{CNetID}</code> for the username and enter your CNetID password.</p>"},{"location":"databases/bfi/#method-2-globus","title":"Method 2: Globus","text":"<p>Follow the steps to connect to the Midway2 Globus endpoint here. </p> <p>Note</p> <pre><code>Always use absolute paths to access databases, as users lack read permissions for parent directories for privacy reasons.\n</code></pre>"},{"location":"databases/bfi/#method-3-ssh-scp-sftp-etc","title":"Method 3: SSH (SCP, SFTP, etc.)","text":"<p>Follow the steps to connect to Midway2 through SSH here. </p> <p>Note</p> <pre><code>Always use absolute paths to access databases, as users lack read permissions for parent directories for privacy reasons.\n</code></pre>"},{"location":"databases/booth/","title":"Booth databases","text":"<p>List of Booth databases hosted on Midway2: </p> Database Name Point of contact (PoC) Group name Directory L2 Data Consumer Jack Mountjoy (jack.mountjoy[@]chicagobooth[.]edu) <code>data-booth-consumer</code> <code>/project2/databases/booth/l2-data-consumer</code>"},{"location":"databases/booth/#eligibility","title":"Eligibility","text":"<ul> <li>All University of Chicago faculty members (PIs) are eligible to request access to the Booth databases with approval from the designated point of contact (PoC) for the database.</li> <li>After the PI and database\u2019s PoC approval have been received, students, post-doctoral researchers, and collaborators, among others, can access the databases. </li> </ul> <ul> <li>PI account request form </li> <li>General user access request form </li> </ul>"},{"location":"databases/booth/#accessing-databases","title":"Accessing databases","text":""},{"location":"databases/booth/#method-1-smb-shared-drive","title":"Method 1: SMB - Shared Drive","text":""},{"location":"databases/booth/#microsoft-windows","title":"Microsoft Windows","text":"<p>On a Windows computer, select \u201cMap Network Drive\u201d and enter one of the following UNC paths depending on which database on Midway2 you wish to connect to, for example, <code>l2-data-voter</code> here: </p> <p><code>\\\\midwaysmb.rcc.uchicago.edu\\project2\\databases\\booth\\l2-data-consumer</code></p> <p>Enter <code>ADLOCAL\\{CNetID}</code> for the username and enter your CNetID password.</p>"},{"location":"databases/booth/#apple-macos","title":"Apple macOS","text":"<p>On a macOS X computer, select \u201cConnect to Server\u201d (from the \u201cGo\u201d dropdown in Finder) and enter one of the following URLs depending on which database on Midway 2 you wish to connect to, for example, <code>l2-data-voter</code> here:</p> <p><code>smb://midwaysmb.rcc.uchicago.edu/project2/databases/booth/l2-data-consumer</code></p> <p>Enter <code>ADLOCAL\\{CNetID}</code> for the username and enter your CNetID password.</p>"},{"location":"databases/booth/#method-2-globus","title":"Method 2: Globus","text":"<p>Follow the steps to connect to the Midway2 Globus endpoint here. </p> <p>Note</p> <pre><code>Always use absolute paths to access databases, as users lack read permissions for parent directories for privacy reasons.\n</code></pre>"},{"location":"databases/booth/#method-3-ssh-scp-sftp-etc","title":"Method 3: SSH (SCP, SFTP, etc.)","text":"<p>Follow the steps to connect to Midway2 through SSH here. </p> <p>Note</p> <pre><code>Always use absolute paths to access databases, as users lack read permissions for parent directories for privacy reasons.\n</code></pre>"},{"location":"databases/main/","title":"Databases","text":""},{"location":"gis/","title":"GIS on High-Performance Computing at the RCC","text":""},{"location":"gis/#overview-of-gis-services","title":"Overview of GIS services","text":"<p>The Research Computing Center (RCC) at the University of Chicago provides comprehensive support for Geospatial Information Systems (GIS) on our high-performance computing (HPC) infrastructure. This integration empowers researchers to leverage HPC capabilities for complex spatial analyses, large-scale geospatial data processing, and cutting-edge GIS technologies.</p> <p>Visit our main GIS portal for all the RCC-GIS services.</p>"},{"location":"gis/#available-gis-software","title":"Available GIS Software","text":"<p>RCC supports a variety of GIS software platforms optimized for HPC environments:</p> Software Description GRASS GIS Open-source GIS for geospatial data management and analysis QGIS User-friendly, open-source GIS for viewing, editing, and analyzing data ArcPy Python site-package for ArcGIS Pro (available upon request) R (spatial packages) Statistical computing with powerful spatial capabilities Python (geospatial libraries) Versatile programming language with robust GIS support Orfeo Toolbox (OTB) Advanced remote sensing toolbox SAGA GIS System for Automated Geoscientific Analyses STATA Statistical software with spatial econometrics capabilities SAS Analytics software suite with geospatial procedures MATLAB Numerical computing environment with mapping toolbox <p>ArcGIS Pro named user licenses are available to all faculty, staff, and students at the University of Chicago.</p>"},{"location":"gis/#hpc-enabled-gis-capabilities","title":"HPC-Enabled GIS Capabilities","text":"<ul> <li>Big Data Processing: Analyze large-scale geospatial datasets that exceed the capacity of desktop systems.</li> <li>Parallel Computing: Utilize multiple cores for faster processing of computationally intensive spatial analyses.</li> <li>Remote Sensing: Process and analyze satellite imagery and LiDAR data efficiently.</li> <li>Spatial Statistics: Perform complex geostatistical analyses on large datasets.</li> <li>Machine Learning for GIS: Implement advanced machine learning algorithms for geospatial applications.</li> </ul>"},{"location":"gis/#advanced-gis-technologies","title":"Advanced GIS Technologies","text":""},{"location":"gis/#geoai-the-fusion-of-ai-and-geospatial-science","title":"GeoAI: The Fusion of AI and Geospatial Science","text":"<p>GeoAI integrates artificial intelligence with geospatial data and analysis, revolutionizing the GIS industry. On RCC's HPC infrastructure, researchers can leverage GeoAI capabilities for:</p> <ul> <li>Pattern Recognition: Identify complex spatial patterns and relationships in large datasets.</li> <li>Predictive Modeling: Enhance forecasting accuracy using historical geospatial data.</li> <li>Real-time Monitoring: Analyze streaming geospatial data for rapid detection of environmental changes.</li> <li>Automated Feature Extraction: Use machine learning algorithms to extract features from satellite imagery and LiDAR data.</li> </ul> <p>Our HPC environment supports popular GeoAI frameworks and libraries, enabling researchers to develop and run sophisticated AI models on geospatial data at scale.</p>"},{"location":"gis/#cybergis-unleashing-the-power-of-cyberinfrastructure","title":"CyberGIS: Unleashing the Power of Cyberinfrastructure","text":"<p>CyberGIS combines cyberinfrastructure capabilities with GIS to tackle computationally intensive spatial problems. RCC's HPC resources are well-suited for CyberGIS applications, offering:</p> <ul> <li>Scalable Processing: Handle very large spatial datasets and complex analytical software beyond the capabilities of desktop systems.</li> <li>Collaborative Environment: Enable multiple users to access CyberGIS capabilities and share resources.</li> <li>Advanced Geospatial Tools: Provide access to cutting-edge spatial analysis techniques optimized for high-performance environments.</li> <li>Interdisciplinary Integration: Facilitate the synthesis of geospatial approaches with other scientific domains.</li> </ul>"},{"location":"gis/#accessing-gis-on-hpc","title":"Accessing GIS on HPC","text":"<ol> <li>Request an RCC account if you don't already have one</li> <li>Connect to the RCC cluster via SSH or our user-friendly web portal</li> <li>Load GIS modules using the <code>module load</code> command (e.g., <code>module load qgis-ltr</code>)</li> <li>Execute your GIS workflows through batch jobs or interactive sessions</li> </ol>"},{"location":"gis/#training-and-support","title":"Training and Support","text":"<ul> <li>Workshops: RCC-GIS provides complimentary workshops and bootcamp courses on GIS, including specialized workshops on GeoAI and CyberGIS applications every quarter to assist UChicago researchers in addressing location-based data issues. Students, faculty, and staff can sign up through the RCC website. </li> <li>Documentation: RCC-GIS offers regularly updated documentation for running various GIS software, including popular tools and specialized applications. </li> <li>Consultation: One-on-one support is available for integrating GIS workflows with HPC and advanced GIS technologies. If you have specific questions about how GIS can assist with your research project or need guidance on getting started, please contact the RCC-GIS team.</li> </ul>"},{"location":"gis/#data-management","title":"Data Management","text":"<ul> <li>Access to shared geospatial datasets on RCC storage systems.</li> <li>Tools for efficient data transfer and management of large geospatial files.</li> <li>Integration with RCC's data management policies and best practices.</li> <li>Geocoding services available at geocoder.rcc.uchicago.edu and instructions.</li> </ul>"},{"location":"gis/#research-examples","title":"Research Examples","text":"<ul> <li>Climate modeling with high-resolution geospatial data</li> <li>Urban planning simulations using parallel processing</li> <li>Large-scale ecological analyses across multiple geographic regions</li> <li>Real-time environmental monitoring using GeoAI</li> <li>Complex spatial problem-solving with CyberGIS</li> </ul>"},{"location":"gis/#sign-up-for-training","title":"Sign up for Training","text":"<p>RCC-GIS provides complimentary workshops and bootcamp courses on advanced GIS techniques and software every quarter to assist UChicago researchers in addressing location-based data issues. Students, faculty, and staff can sign up through the RCC website.</p> <p>The workshops cover various topics and are suitable for most faculty, staff, and students. Introductory sessions for popular GIS software assume no previous knowledge of GIS technology, making them an excellent starting point. More advanced sessions are also available, focusing on specific GIS applications and techniques.</p>"},{"location":"gis/#use-online-training","title":"Use Online Training","text":"<p>As part of the University of Chicago's commitment to GIS education, RCC-GIS provides access to various online training resources through ESRI Training. These may include self-paced tutorials, video courses, and interactive learning modules covering a wide range of GIS topics and software.</p>"},{"location":"gis/#contact-rcc-gis-staff","title":"Contact RCC-GIS Staff","text":"<p>If you have questions about how GIS can enhance your research or need assistance on how to begin, reach out to the RCC-GIS team for customized support suited to your requirements and expertise. The RCC-GIS promotes interdisciplinary research and education, assisting UChicago users in incorporating GIS techniques and software across various fields.</p> <p>Sources [1] gis.rcc.uchicago.edu https://gis.rcc.uchicago.edu</p> <p>For more information on general RCC-GIS services, visit our main GIS portal.</p>"},{"location":"gis/MidwayGeoSpatial/","title":"Geospatial","text":"<p>Here is a guide on setting up an environment for geospatial analysis on the Midway3 cluster at the University of Chicago. This guide is divided into sections that detail the steps for connecting to the cluster, and using software and containers relevant to geospatial analysis.</p>"},{"location":"gis/MidwayGeoSpatial/#section-i-connecting-to-midway-cluster","title":"Section I: Connecting to Midway Cluster","text":""},{"location":"gis/MidwayGeoSpatial/#1-gui-based-access","title":"1. GUI-based Access","text":"<p>For geovisualization, a GUI-based approach is preferred. ThinLinc is recommended due to its seamless working environment which supports features like a shared clipboard. ThinLinc can be accessed in two ways:</p> <ul> <li>ThinLinc Client: Download and install the ThinLinc client from ThinLinc Download Page. It is available for all major operating systems.</li> <li>Web Access: You can also access ThinLinc through a browser by navigating to <code>https://midway3.rcc.uchicago.edu</code>. This method does not require any client installation.</li> </ul>"},{"location":"gis/MidwayGeoSpatial/#2-command-line-access-and-x-forwarding","title":"2. Command Line Access and X Forwarding","text":"<p>For users who prefer or require command-line access, especially for scripting and automation:</p> <ul> <li>Using SSH with X Forwarding:<ul> <li>Xshell and VcXsrv: Xshell is preferred for academic and home use as it is free and has a smaller memory footprint compared to other tools like MobaXterm. However, it requires the installation of an X11 client such as Xming or VcXsrv.</li> <li>Connect via SSH with X forwarding enabled:   <pre><code>ssh -Y &lt;user&gt;@midway3.rcc.uchicago.edu\n</code></pre>   Replace <code>&lt;user&gt;</code> with your actual username on the Midway3 cluster.</li> </ul> </li> </ul>"},{"location":"gis/MidwayGeoSpatial/#section-ii-software","title":"Section II: Software","text":""},{"location":"gis/MidwayGeoSpatial/#1-using-software-packages","title":"1. Using Software Packages","text":"<p>Key geospatial libraries and tools are available on Midway3, including GDAL for geospatial data manipulation and analysis, as well as spatial libraries for R and Python:</p> <ul> <li>For R:</li> <li>Load the R module and start R:     <pre><code>module load R\nR\n</code></pre></li> <li>For Python:</li> <li>Python and its libraries can be accessed via Anaconda modules, which support virtual environments:     <pre><code>module load python\nsource activate &lt;env_name&gt;\n</code></pre></li> </ul>"},{"location":"gis/MidwayGeoSpatial/#2-loading-qgis","title":"2. Loading QGIS","text":"<p>QGIS can be loaded and used directly on Midway3 by activating the appropriate Python environment and loading the software module: <pre><code>module load python\nsource activate qgis\nqgis\n</code></pre></p>"},{"location":"gis/MidwayGeoSpatial/#3-using-containers","title":"3. Using Containers","text":"<p>Containers provide a reproducible environment for more complex or customized setups. Singularity is used on Midway3 to manage containers:</p> <ul> <li>How to Use Singularity:</li> <li>Load the Singularity module and interact with a container:     <pre><code>ml singularity\nsingularity shell -B $HOME/code:&lt;mount_point&gt; -B $SCRATCH/$USER:/data &lt;image_path&gt;\n</code></pre>     For example, to load an OTBTF (Orfeo Toolbox with TensorFlow) image:     <pre><code>singularity shell -B $HOME/code/cook -B $SCRATCH/$USER:/data otbtf_6.3.1-cpu.sif\n</code></pre></li> </ul> <p>export SINGULARITY_TMPDIR=\"/software/src/tmp\" export SINGULARITY_CACHEDIR=\"/software/src/cache\" This guide covers the basic setup for geospatial analysis on Midway3. Depending on specific project requirements, additional configurations or software packages might be necessary.</p>"},{"location":"gis/geocoding/","title":"Geocoding","text":"<p>Welcome to the University of Chicago RCC-GIS Geocoding Service. This application allows UChicago affiliates to take lists of street addresses or place names and convert them into latitude and longitude coordinates. The coordinate pairs can then be used in any sort of mapping application or spatial analysis method.</p> <p></p> <p>The engine behind the RCC-GIS Geocoding Service is the ESRI\u2019s World Geocoder for ArcGIS. The Geocoding Service has the ability to retrieve coordinates for places around the world. However, coverage does differ from country to country. Click here to see what level of detail is available for different parts of the world. The RCC-GIS Geocoding Service is available to any UChicago affiliate with an active CNetID login and works on a credit-based system. All users are allocated 2000 credits by default. 2000 credits will allow a user to geocode 50,000 records. If a user needs to geocode more records, a request must be forwarded by email to gis-help@rcc.uchicago.edu for a larger allocation.</p>"},{"location":"gis/geocoding/#1-formatting-data-for-processing","title":"1. Formatting Data for Processing","text":"<p>Records must be formatted in a particular way for processing by the RCC-GIS Geocoding Service. The RCC-GIS Geocoding service requires data to be uploaded in a CSV (comma-separated value) format in the standard UTF-8 encoding. Different parts of the world have different formats and subdivisions for street addresses and place names. Records should be either in one column or\u00a0divided accordingly for processing. The following column headers are acceptable for your CSV file:</p> <p>ID ADDRESS NEIGHBORHOOD CITY SUBREGION REGION or STATE or ST POSTAL or ZIP or ZIPCODE COUNTRYCODE</p> <p>It is NOT necessary to provide data for all the variables listed above. However, if more data is provided, the geocoding service should provide a higher match rate.</p> <p>Example File: A formatted US address file can be downloaded from here.\u00a0 International address file formatting\u00a0 For the CSV file creation, RCC recommends the use of OpenOffice or LibreOffice over excel.</p>"},{"location":"gis/geocoding/#2-sign-in-and-execution-procedure","title":"2. Sign In and Execution Procedure","text":"<p>Log on to the enterprise ArcGIS Online portal for the University of Chicago by clicking on \u201cSign in with Enterprise Login\u201d.</p> <p></p> <p></p> <p></p> <ol> <li>Enter the portal\u2019s URL \u201cuchicago.maps.arcgis.com\u201d and click Continue.</li> <li>Sign in to the University of Chicago portal by clicking on UCHICAGO.</li> <li>Enter your University of Chicago CNetID username and password and click LOG IN.</li> <li>Upload your file to be geocoded by clicking Select File.</li> <li>Browse to your file\u2019s location, highlight it, and click Open.</li> <li>Click the Submit button to activate the geocoding service.</li> <li>The geocoding service page will notify you that your file has been uploaded. Refresh your browser to see the progress with your data. (The geocoding service will process approximately 250,000 - 500,000 records per hour.)</li> </ol> <p>When completed, click the link to Download the Geocoded File. Your geocoded file will be available for download for 7 days. After that time, it will be deleted from the queue.</p>"},{"location":"gis/geocoding/#3-activate-geocoding-service","title":"3. Activate Geocoding Service","text":"<p>Click the above link or navigate to http://geocoder.rcc.uchicago.edu</p>"},{"location":"gis/geocoding/#4-interpreting-geocoding-output","title":"4. Interpreting Geocoding Output","text":"<p>The downloaded output file will include the user's original data along with 3 new variables, LATITUDE, LONGITUDE, and MATCH SCORE.</p>"},{"location":"gis/geocoding/#latitudelongitude","title":"Latitude/Longitude","text":"<p>The latitude and longitude variables are the real-world coordinates as interpreted by the ESRI\u2019s World Geocoder for ArcGIS.</p>"},{"location":"gis/geocoding/#match-score","title":"Match Score","text":"<p>The match score is a calculation of how closely the interpreter came to finding the exact same address or place name. A perfect match score of 100% is optimal. However, a match score above 90% may also be suitable for many cases.</p> <ul> <li>Example: a score of 92% may occur when the user provides the following address: 1100 E. 57th, Chicago, IL. A score of 100% might have been achieved if the user included the street type (ST) in the address record. Therefore, a perfect score could be achieved for 1100 E. 57th St., Chicago, IL.</li> </ul> <p>Most match scores below 90% should be scrutinized. A low match score will still produce a latitude/longitude coordinate pair but it may be incorrectly placed. If the interpreter cannot locate a street address, it defaults to the next highest location variable.</p> <ul> <li>Example: if the user has 1100 N. Woodlawn Ave., Chicago, IL as a record, the interpreter may produce a match score of 72% along with a latitude/longitude coordinate pair. However, since 1100 N. Woodlawn Ave. does not exist, the interpreter will assign the location to the center of Chicago, IL instead. IT WILL NOT PRODUCE AN ERROR, ONLY A LOWER MATCH SCORE.</li> </ul> <p>Any records with a low match score should be re-evaluated, validated with another geocoding service, or dropped from the record-set altogether.</p>"},{"location":"gis/geocoding/#note","title":"Note","text":"<p>Please refer to the FAQ section if your geocoding process fails. If you have any questions or issues with the RCC-GIS Geocoding Service, please email us: gis-help@rcc.uchicago.edu.</p>"},{"location":"globus/access-files/","title":"Login to Globus &amp; Browse Your Files","text":"<p>Globus is a robust file-sharing and transfer service. This guide explains how to use Globus to browse files you have stored in the RCC Midway 2 and 3 ecosystems. </p>"},{"location":"globus/access-files/#why-use-globus","title":"Why Use Globus?","text":""},{"location":"globus/access-files/#login-to-globus","title":"Login to Globus","text":"<p>Go to globus.rcc.uchicago.edu. Select \"University of Chicago\" from the drop-down list of existing organizational logins and click \"Continue.\":</p> <p> </p> <p>If you are accessing Globus with your University of Chicago login for the first time, you will need to agree to the Globus Terms of Service and Privacy Policy:</p> <p> </p> <p>If you are accessing Globus with your University of Chicago login for the first time, you will need to configure your Globus permissions:</p> <p> </p>"},{"location":"globus/access-files/#browse-your-files","title":"Browse Your Files","text":"<p>Once you have signed in, click into the File Manager from the toolbar on the left of your screen and type \"University of Chicago Research Computing Center\" into the collection search bar. The RCC manages three Globus collections (also called endpoints):</p> <p> </p>"},{"location":"globus/access-files/#rcc-managed-globus-collections","title":"RCC-Managed Globus Collections","text":"Collection name Description\u00a0 UChicago RCC DaLI is a collection within the RCC's Midway2 ecosystem. It provides additional storage for PIs who contributed to the DaLI project.\u00a0Selecting the DaLI collection, you land in Midway2's `/dali/` directory. UChicago RCC Midway houses files from the RCC's Midway2 ecosystem. When you select this collection, you land in your Midway2 home directory, `/home/`, denoted by a `/~/` path.  UChicago RCC Midway3 houses files from the RCC's Midway3 ecosystem. When you select this collection, you land in your Midway3 home directory, `/home/`, denoted by a `/~/` path.  <p>To see files in different collections at the same time, click the two panes icon next to Panels in the upper-right corner. </p> <p> </p>"},{"location":"globus/access-files/#connecting","title":"Connecting","text":"<p>Midway clusters to your personal computer using Globus. See Transfer Files with Globus for help moving files between collections. This guide also describes how to make your computer a Globus endpoint so you can move files between your local system and RCC cluster (Midway2 and Midway3). In addition, you might find Globus documentation helpful if you need to schedule transfer files here. \"../../img</p>"},{"location":"globus/cloud-sync/","title":"Syncing Globus with UChicago Cloud Storage","text":"<p>Note</p> <p>The follwing content is outdated. Please check with RCC helpdesk for more information. </p> <p>Globus is a robust file-sharing and transfer service. This page explains how to sync Globus with University of Chicago cloud storage so you can use Globus features, like scheduled file transfers, with files stored in your UChicago Box, Google Drive, and OneDrive accounts.</p> <p>Globus calls a collection of files an endpoint. UChicago has Globus endpoints for Box, Google Drive, and OneDrive. By connecting to these endpoints, you can access files stored in your UChicago Box, Google Drive, and OneDrive accounts through Globus.</p> <p>Start by logging into the Globus Web App with your CNet ID. Go into the File Manager and search for the endpoint for your cloud platform of choice using the Collection search bar:</p> <p>Globus Staff GCSv5.4 Demo Box (UChicago)  Globus Staff GCSv5.4 Demo OneDrive </p> <p>Note</p> <p>The UChicago Google Drive endpoint is not available. To access your files, please log in to Midway 3 using ThinLinc, open a browser, and sign in to Google Drive. From there, you can download the files to your working directory. </p> <p>When you choose a UChicago cloud storage endpoint, you will need to give Globus permission to access files you have stored on that cloud platform. For example, if you choose the Globus Staff GCSv5.4 Demo Box (UChicago) endpoint, you will see a message like this:</p> <p> </p> <p>When you click \"Continue,\" Globus will route you to an identity verification page. Click \"Globus Staff (globus.org)\" to proceed:</p> <p> </p> <p>When you click \"Globus Staff (globus.org),\" Globus will route you to the Box sign-in page. Choose the Google account associated with the files you would like to access through Globus:</p> <p> </p>"},{"location":"globus/share-files/","title":"Share Files with Globus","text":"<p>Globus is a robust file-sharing and transfer service. Other sections of this user guide detail how to browse files with Globus and project directories.) Your external collaborators will each need their own Globus login, which they have several options for creating. Alternatively, you can sync Globus with Box, Google Drive, or OneDrive. If you share files this way, your external collaborators will not need to login to Globus.</p>"},{"location":"globus/share-files/#select-files-to-share","title":"Select Files to Share","text":"<p>Go to the \"File Manager\" tab of the Globus Web App. Navigate to the folder that houses the files you want to share (read more about browsing files here), right-click it, and select \"Share\" from the menu that appears:</p> <p> </p>"},{"location":"globus/share-files/#create-a-collection","title":"Create a Collection","text":"<p>If the files you have selected are not already part of a Guest Collection, you will see a message that \"No collections match that filter.\" Click \"Add Guest Collection\" in the upper-right corner to create a collection of your selected files to share with external collaborators:</p> <p> </p> <p>The Directory field will default to the folder that houses the files you have selected to share. Fill in the Display Name field and any other fields you like, then click \"Create Collection\":</p> <p> </p> <p>The Filer Manager will open to the Permissions tab of your new collection, which you can now share.</p>"},{"location":"globus/share-files/#share-a-collection","title":"Share a Collection","text":"<p>If the files you have selected are already part of a Guest Collection, click the collection name:</p> <p> </p> <p>The File Manager will open to an overview of the collection. Click \"Permissions\" in the upper-left menu bar, then click \"Add Permissions \u2013 Share With\" in the upper-right corner:</p> <p> </p> <p>The <code>/</code> in the Path field indicates you are in the top-level directory of a collection. If you only want to grant permissions for a sub-directory, click \"Browse\" to navigate into the sub-directory you want to share. Enter your collaborator's Globus username or search for them via email. If they do not already have a Globus login, they can follow the steps below to create one.</p>"},{"location":"globus/share-files/#globus-login-options-for-external-collaborators","title":"Globus Login Options for External Collaborators","text":"<p>External collaborators can login to Globus through the Globus Web App. They can login with an organizational login, GitHub account, Google account, ORCID iD, or Globus ID.</p> <p>If your collaborator's university or lab uses Globus, they can select their organization from the drop-down menu and click \"Continue\" to login with their existing organizational credentials (their equivalent of a CNet ID):</p> <p> </p> <p>Alternatively, your collaborator can login with an existing GitHub, Google, or ORCID account. If they click the button corresponding to their preferred platform, they will be prompted to login through that platform. For example, if they click \"Sign in with GitHub,\" they will be redirected to GitHub, where they can authorize Globus to use their GitHub login:</p> <p> </p> <p> </p> <p>Finally, if your external collaborator prefers not to use an existing login (e.g., university, lab, GitHub), they can create a Globus ID and use that to login. If they click \"use Globus ID to sign in\" at the bottom of the Globus Web App home page, they will be prompted to enter their Globus ID or create one if needed:</p> <p> </p> <p> </p>"},{"location":"globus/transfer-files/","title":"Transfer Files with Globus","text":"<p>Globus is a robust file-sharing and transfer service. Globus calls a collection of files an endpoint. The RCC has several Globus endpoints. This guide explains how to make your computer a Globus endpoint and transfer files between Globus endpoints. Put another way, this guide explains how to move files between your local system (i.e., your computer, lab computers, etc.) and the RCC's Midway 2 and 3 ecosystems. </p> <p>Note that this guide focuses on transferring files through the Globus web app. Advanced users can access additional functionality by using the Globus command line interface (CLI), a standalone app that you can install on your computer and then use to access Globus.</p>"},{"location":"globus/transfer-files/#make-your-computer-a-globus-endpoint","title":"Make Your Computer a Globus Endpoint","text":"<p>Follow the instructions in the Globus documentation to install Globus Connect Personal and make your computer a Globus endpoint (also called a collection). When Globus Connect Personal asks you to authenticate (Step 4), log in with your UChicago CNetID. </p> <p>Once your computer is a Globus endpoint, you will be able to access files stored on your local system, as well as files stored in the RCC's ecosystems, from globus.rcc.uchicago.edu. To access your locally stored files, click the \"File Manager\" in the toolbar on the left of your screen and type the name you gave your personal endpoint into the collection search bar: </p> <p> </p>"},{"location":"globus/transfer-files/#manually-transfer-files","title":"Manually Transfer Files","text":"<p>To see files in different collections at the same time, click the \"two panes\" icon next to \"Panels\" in the upper-right corner:</p> <p> </p> <p>To transfer files between collections, open the source directory (where the files are currently) in one pane of the File Manager and the destination directory (where you want to move the files) in the other. Select the files you want to transfer from the source directory and drag and drop them into the destination directory or click the blue \"Start\" button above the source directory:</p> <p> </p> <p>You can customize your transfer with the \"Transfer &amp; Timer Options\" drop-down menu at the center top of your screen. You can also use this menu to schedule transfers (see below). Advanced users can access additional file transfer functionality by using the Globus command line interface (CLI).</p>"},{"location":"globus/transfer-files/#schedule-a-file-transfer","title":"Schedule a File Transfer","text":"<p>To schedule a one-time or recurring file transfer, open the File Manager with your source directory in one pane and your destination directory in the other, as you would for a manual file transfer (see above). Select the files you want to transfer in the source directory, then click \"Transfer &amp; Timer Options\" at the center top of your screen:</p> <p> </p> <p>Specify the date and time you would like your transfer to occur with the \"Schedule Start\" option at the bottom of the menu. If you are scheduling a recurring transfer, this will be the date and time of the first occurrence. Use MM/DD/YYYY for the date and 12-hour time. For example, 12/15/2023, 1:30 PM:</p> <p> </p> <p>Use the \"Repeat\" option at the bottom of the menu to schedule a recurring file transfer. Specify how frequently you would like the transfer to occur and, optionally when you would like the transfer to stop. For example, you could schedule a transfer to happen every other day for a year:</p> <p> </p>"},{"location":"globus/transfer-files/#globus-flows","title":"Globus Flows","text":"<p>You can also transfer files (and more!) with Globus Flows, which offers a way to set up automated, reusable, and sharable workflows. This is a brief overview of Globus Flows. For a comprehensive guide to the service, including detailed examples, see the Globus Flows documentation.</p> <p>Think of a flow like a function: you run a flow when you want something to happen on Globus, just like you call a function when you want something to happen in your code. Globus offers two ready-made flows:</p> <ul> <li> <p>The Move (Copy and Delete) flow copies data between collections then deletes the original data from the source collection.</p> </li> <li> <p>The Two-Stage Transfer flow copies data between two collections using a third collection as an intermediate location, which can be useful for meeting security and compliance requirements</p> </li> </ul> <p>You can also run flows other Globus users have created, just like you can call functions from different libraries, or create custom flows, just like you can define your own functions.</p> <p>To work with Globus Flows, go to the Flows section of the Globus Web App. The first time you click into the Flows section, you will need to give Globus permission to manage flows on your account:</p> <p> </p> <p> </p> <p>When you click \"Allow,\" Globus will route you to the Runs tab of the Flows section:</p> <p> </p> <p>A full list of flows you can view or use is available in the Library tab. Use the search bar at the top of the page to search for flows and/or the filters in the top-right corner to narrow down your options:</p> <p> </p> <p>Steps for creating additional, custom flows are listed in the Deploy a Flow tab:</p> <p> </p>"},{"location":"midwayR3/Software/","title":"Offline CRAN Snapshot on MidwayR3","text":"<p>As a secure system, MidwayR does not have direct Internet access. An offline snapshot of CRAN is created with name sdeCRAN that can be used to install R packages by any general user. It could be accessed by setting up  repos = \"file:///software/sdeCRAN\"  As an example, to install dplyr <pre><code>install.packages(\"dplyr\", repos = \"file:///software/sdeCRAN\", type = \"source\", dependencies = TRUE)\n</code></pre></p>"},{"location":"midwayR3/accessing/","title":"Accessing","text":""},{"location":"midwayR3/accessing/#accessing-midwayr3","title":"Accessing MidwayR3","text":"<p>To use MidwayR3 resources, you will need to have a MidwayR3 user account. Although both Midway and MidwayR3 use CNetID for authentication, they do not share accounts. If you do not have a MidwayR3 user account, please see the Getting Started section for how to apply for an account.</p> <p>Note</p> <p>General users can apply only after the PI has been approved for MidwayR3 account. Only authorized users listed in Data Use Agreement (DUA) and/or Internal Review Board (IRB) protocol can get access to a project hosted on MidwayR3 upon PI approval. If the list of authorized users is not set explicitly in the data use agreement, then any UChicago researcher approved by the PI can work with the project data hosted on MidwayR3.</p> <p>Please also note that you must have enabled  Two Factor Authentication for your CNetID before connecting to MidwayR.</p>"},{"location":"midwayR3/connecting/","title":"Connecting","text":""},{"location":"midwayR3/connecting/#quick-overview","title":"Quick Overview:","text":"<p>Because MidwayR3 has no connection to the Internet, accessing MidwayR3 is a two-step process where you first connect to the Secure Data Enclave (SDE) Desktop using the Azure Virtual Desktop (AVD) client and then log into MidwayR3.</p> <p></p> <ul> <li>You do not need to be connected to the University VPN before connecting to MidwayR. Azure takes care of encrypting and securing all communications between your local computer and the Virtual Desktop.</li> <li>You can connect from your web browser, in addition to the Microsoft Remote Desktop application.</li> <li>It is not possible to copy/paste between your local computer and the Virtual Desktop. However, you can still copy/paste from within the AVD environment.</li> </ul>"},{"location":"midwayR3/connecting/#connecting-to-sde-desktop","title":"Connecting To SDE Desktop","text":""},{"location":"midwayR3/connecting/#using-web-browser","title":"Using Web Browser","text":"<p>Navigate to https://rdweb.wvd.microsoft.com/arm/webclient on your computer's web browser. Select \"AVD Host\" to launch the Virtual Desktop:</p> <p></p> <p>You will be prompted for your username (cnetID@uchicago.edu) and password:</p> <p></p> <p>After logging in, you will arrive at the Desktop where you can launch applications:</p> <p></p>"},{"location":"midwayR3/connecting/#using-microsoft-remote-desktop-client","title":"Using Microsoft Remote Desktop Client","text":"<p>You can also connect from the Microsoft Remote Desktop App, available for download on the Windows or MacOS app store. After launching the app, click on the \"+\" symbol and select \"Add Workspace\":</p> <p></p> <p>In the dialog box, put the URL \"https://rdweb.wvd.microsoft.com\":</p> <p></p> <p>You should then be able to launch the AVD from within the App.</p>"},{"location":"midwayR3/connecting/#connecting-to-midwayr3","title":"Connecting To MidwayR3","text":"<p>Once you are connected to the SDE environment using the AVD client following the steps given above, please follow one of the methods below to connect to MidwayR3 from the SDE environment.</p>"},{"location":"midwayR3/connecting/#using-ssh-client","title":"Using SSH client","text":"<p>You can use Powershell or PuTTy terminal to connect to MidwayR3. Run the following command: ssh @sde.rcc.uchicago.edu:"},{"location":"midwayR3/connecting/#using-thinlinc","title":"Using ThinLinc","text":"<p>ThinLinc is a remote desktop server application. It is recommended to use ThinLinc when you run software that requires a graphical user interface, or \"GUI\" (e.g., Stata, MATLAB). To use ThinLinc to connect to MidwayR3, please take the following steps on the SDE desktop:</p> <ol> <li> <p>Open a browser (Chrome or Firefox) and enter    <code>https://sde.rcc.uchicago.edu</code> in the address bar.</p> </li> <li> <p>Enter your CNetID and password on the ThinLinc login page: </p> </li> <li> <p>Follow the two-factor authentication prompts: </p> </li> <li> <p>If the login process is successful, you will see a Linux desktop environment. To access the command-line shell, select the Applications menu, then the Terminal icon: </p> </li> <li> <p>After selecting the Terminal icon, you should see a Terminal window appear. Typically this will give a console prompt showing which login node you are connected to: </p> </li> </ol> <p>To exit ThinLinc, type <code>exit</code> in any Terminal window, select the top-right icon, then select the \"Log Out\" menu item and follow the instructions. Finally, close the browser window. </p>"},{"location":"midwayR3/connecting/#logging-out","title":"Logging Out","text":"<p>You can log out of the AVD by clicking the \"Log off\" application on the Desktop.</p> <p>Warning</p> <p>Once logged off, any data stored in your AVD user-space will be purged.</p>"},{"location":"midwayR3/data-transfer/","title":"Data transfer","text":"<p>Transferring data from a Data Provider Server to the MidwayR3 HPC system involves a two-step process, using the Secure Data Enclave (SDE) Virtual Desktop as an intermediate staging area. The SDE desktop itself does not have computational capabilities and is intended only for temporary data storage until the data is fully migrated to MidwayR3. Since MidwayR3 does not have internet access available to general users, this intermediate step is necessary.</p> <p>For moderately sized datasets (up to 1TB), users can follow the steps outlined below. If you need to transfer larger datasets, please contact us at midwayr-help@rcc.uchicago.edu to discuss alternative arrangements.</p>"},{"location":"midwayR3/data-transfer/#step-1-from-data-provider-to-sde-virtual-desktop","title":"Step 1. From Data Provider to SDE Virtual Desktop","text":"<p>Log in to SDE virtual desktop using your CNetID credential as described in connecting chapter. Please note that only MidwayR3 users have access to the MidwayR3 HPC system. Having an RCC account on Midway ecosystem, such as Midway2 or Midway3, does not automatically grant you an account on MidwayR3.</p>"},{"location":"midwayR3/data-transfer/#method-1-download-data-from-a-website","title":"Method 1. Download Data from a Website","text":"<p>The SDE virtual desktop provides standard web browsers that can be used to access websites, log in with your credentials, and download data.</p>"},{"location":"midwayR3/data-transfer/#method-2-download-data-from-a-server","title":"Method 2. Download Data from a Server","text":"<p>In some cases, data provider servers may limit access through web browsers or support only a narrow range of data transfer protocols. </p> <p>Open the Command Prompt on the SDE virtual desktop. By default, it opens in your home directory. Be sure to navigate to the Downloads folder, which has a larger storage quota available. <pre><code>cd Downloads\n</code></pre> When connecting over HTTPS, you can use curl as a reliable alternative. Often, the data is provided in a compressed format such as .zip or .tar.gz. For example, GitHub repositories offer downloadable archives in these formats, making them a practical example for demonstration. <pre><code>set url=https://github.com/example-owner/example-repo.zip\nset output=data.zip\ncurl -L -o %output% %url% \n</code></pre> In this case, the repo is assumed to be public and no credentials are used. In cases when the repo is private, it is recommended to use an authorization token pre-configured on the remote host. <pre><code>set GITHUB_TOKEN=yourtoken\ncurl --header \"PRIVATE-TOKEN: %GITHUB_TOKEN%\" -L -o data.zip https://github.com/example-owner/example-repo.zip\n</code></pre> For cases when the data is hosted on the FTP server, make sure you have enabled TSL encryption and entered the username on the host server not your CNetID: <pre><code>curl --ssl-reqd -u username ftp://example.host.edu/\n</code></pre> You will be prompted to enter the password when establishing the connection. Avoid hardcoding the password directly in the curl command.</p> <p>Warning</p> <p>Once your login session ends with SDE Virtual Desktop, all data that was downloaded will be purged.</p> <p>Warning</p> <p>You can also run PowerShell on the SDE virtual desktop. However, the curl and wget commands are actually aliases for the slower Invoke-WebRequest cmdlet, not the real curl or wget utilities. To ensure proper functionality and performance, use curl.exe explicitly in your commands.</p>"},{"location":"midwayR3/data-transfer/#method-3-download-data-from-uchicago-box","title":"Method 3. Download Data from UChicago Box","text":"<p>If regulated data was shared with you via UChicago Box or was originally collected through UChicago Box, you can access it using browser. Please consult with UChicago Sensitive Data Usage Guide for data types allowed in UChciago Box.</p> <p>Once you logged in to the MidwayR3 desktop , you can open a browser and log in to a Box account at https://uchicago.account.box.com: </p> <p>Download files into the SDE desktop using the built-in Box Download function: </p> <p>By default it will copy the files into your Downloads folder, e.g. C:\\Users[CNetID]\\Downloads: </p>"},{"location":"midwayR3/data-transfer/#step-2-from-sde-virtual-desktop-to-midwayr3","title":"Step 2. From SDE Virtual Desktop to MidwayR3","text":"<p>After the regulated data has been transferred from the Data Provider to the SDE virtual desktop, open the WinSCP application. While WinSCP can be used to connect to MidwayR3, connecting to any non-UChicago hosts is currently prohibited. Therefore, it cannot be used for the data transfer described in Step 1.  </p> <p>Connect to midwayr.rcc.uchicago.edu with your CNet ID and password: </p> <p>Add the host key if this is your first time using WinSCP to move files: </p> <p>Move the folders or files you wish to MidwayR3 using the Upload function -- please do remember there is a 30GB quota on the home directories and a 500GB quota (default) on project, so we strongly recommend keeping your data in project: </p>"},{"location":"midwayR3/overview/","title":"Welcome to MidwayR3 user guide","text":"<p>MidwayR3 (also known as MidwayR) is the RCC's secure HPC cluster that provides a trusted research environment to support work with regulated research data that requires high-level protection. </p> <p>Examples of regulated research data include:</p> <ul> <li>Personally Identifiable Information (PII)</li> <li>Limited data sets as per Health Insurance Portability and Accountability Act (HIPAA) definition</li> <li>Some Types of Health Information </li> <li>Data covered under the Federal Information Security Management Act (FISMA)</li> <li>Data covered under the Federal Education Rights and Privacy Act (FERPA)</li> <li>Data with security requirements set by the Institutional Review Board (IRB)</li> <li>Commercial data with security requirements set by the Data Use Agreement (DUA)</li> </ul> <p>The research data classification is provided by University Research Administration. If you have any questions about MidwayR3, please email midwayr-help@rcc.uchicago.edu.</p>"},{"location":"midwayR3/overview/#system-overview","title":"System Overview","text":"<p>MidwayR3 is comprised of two login nodes and four compute nodes. The total installed storage on MidwayR3 is 441TB. It uses SLURM as its workload manager and the software environment module system to manage installed software.  Login Nodes: MidwayR3 hosts login nodes with the following specifications: </p> <ul> <li>CPUs: 2x Intel Xeon Gold 6130 2.1GHz</li> <li>Total cores per node: 16 cores</li> <li>Threads per core: 2</li> <li>Memory: 96GB of RAM</li> </ul> <p>Compute Nodes:  There are no limits on SU usage at the moment. PIs don't need to apply for SUs allocation. See Partitions</p> <p>Network:</p> <ul> <li>Intel Ethernet Controller 10Gbps Adapter</li> <li>Mellanox EDR Infiniband up to 100Gbps bandwidth and a sub-microsecond latency</li> <li>Neither compute nor login nodes have direct access to the Internet</li> </ul> <p>File Systems:</p> <ul> <li>MidwayR3 utilizes a GPFS filesystem, with <code>/home</code> and <code>/project</code> directories mounted for private and collaborative work.  The <code>/home/&lt;CNetID&gt;</code> directory has a strict quota of 30GB and the quota for <code>/project/pi-&lt;PI_CNETID&gt;-&lt;ProjectName&gt;</code> varies depending on the project with the default startup storage allocation of 500 GB. MidwayR3 does not have a scratch filesystem.</li> </ul> <p>Using MidwayR3:</p> <ul> <li>MidwayR3 nodes run CentOS 7. Its job scheduler is the SLURM. Slurm commands enable you to submit, manage, monitor, and control your jobs.</li> </ul> <p>Software:</p> <ul> <li>Organized in modules</li> <li>Use <code>module avail</code>, to see what is available</li> <li>To load a particular available package, for example, <code>gcc</code> version 8.2.0, do <code>module load gcc/8.2.0</code></li> <li>If you do not specify a version of the package, the default one is loaded</li> <li>To see what environmental variables are modified when <code>gcc/8.2.0</code> is loaded, do <code>module show gcc/8.2.0</code></li> <li>To unload <code>gcc/8.2.0</code>, do <code>module unload gcc/8.2.0</code></li> </ul>"},{"location":"midwayR3/partitions/","title":"Slurm Partitions","text":"<p>Partitions are collections of compute nodes with similar characteristics. Normally, a user submits a job to a partition (via Slurm flag <code>--partition=&lt;partition&gt;</code>) and then the job is allocated to any idle compute node within that partition. To get a full list of available partitions, type the following command in the terminal <pre><code>sinfo -o \"%20P %5D %14F %4c %8G %8z %26f %N\"\n</code></pre> The typical output will include: </p> Column Description <code>S:C:T</code> Number of sockets, cores, and threads <code>NODES(A/I/O/T)</code> Number of nodes by state in the format \"allocated/idle/other/total\" <code>AVAIL_FEATURES</code> Available features such as CPUs, GPUs, internode interfaces <code>NODELIST</code> Compute nodes IDs within the given partition <p>If a user wants to submit their job to the particular compute node, this can be requested by adding the Slurm flag <code>--nodelist=&lt;compute_node_ID&gt;</code>. Compute nodes that differ in available features can be allocated by setting an additional constraint <code>--constraint=&lt;compute_node_feature&gt;</code>, for example <code>--constraint=v100</code> will allocate job to the compute node with NVIDIA V100 GPUs.</p>"},{"location":"midwayR3/partitions/#midwayr3-shared-partitions","title":"MidwayR3 Shared Partitions","text":"<p>All MidwayR3 users can submit jobs to any of the following shared partitions:</p> MidwayR3 Partition Nodes CPUs CPU Type Total Memory Local Scratch skylake 4 40 gold-6148 96 GB 900 MB caslake-bigmem 1 40 gold-6248 1536 GB 900 MB"},{"location":"midwayR3/partitions/#midwayr3-institutional-partitions","title":"MidwayR3 Institutional Partitions","text":"<p>If you are a MidwayR3 researcher affiliated with the Booth School of Business, you are entitled to Booth purchased hardware resources. Each node has 1.8 GB of local scratch.</p> MidwayR3 Partition Nodes Cores/nodes CPU Type GPUs GPU Type Total Memory Local Scratch Nodelist booth 1 40 gold-6248 None None 1536 GB 1.8 GB sde006 booth 2 48 gold-6248r None None 384 GB 1.8 GB sde[007-008] booth 1 48 gold-6248r 2 v100 384 GB 1.8 GB sde009"},{"location":"midwayR3/partitions/#midwayr3-qoc","title":"MidwayR3 QOC","text":"MidwayR3 QOS QOS Partitions Max Wall Time Max Sub Job / User normal skylake, caslake-bigmem 36 H 350 long skylake, caslake-bigmem, booth 7 Days 200 <p>To see a full list of QOS run the following <pre><code>sacctmgr list qos format=Name,MaxWall,MaxSubmitPU\n</code></pre></p> <p>Note</p> <p>QOS for private and institutional partitions can be changed upon owner's request.</p>"},{"location":"midwayR3/partitions/#private-partitions","title":"Private Partitions","text":"<p>Private MidwayR partitions are typically associated with a research group with access approved by PI. Private partitions can be purchased via RCC Cluster Partnership Program to better accommodate the needs of a research group. PI may request to change QOS of private partitions at any time.</p>"},{"location":"midwayR3/partitions/#do-i-have-access-to-a-partition","title":"Do I Have Access to a Partition?","text":"<p>To check if you have access to a partition, first determine which groups your account belongs to:  <pre><code>groups\n</code></pre> and then check AllowAccounts field in the partition summary:  <pre><code>scontrol show partition &lt;partition_name&gt;\n</code></pre> If AllowAccount is set to All then it is a shared partition available to all users. Otherwise, it is an institutional or private partition and one of your groups must match the AllowAccounts field in order to submit SLURM jobs to that partition. </p>"},{"location":"midwayR3/running-jobs/","title":"Running jobs on midwayR3","text":"<p>Running jobs on MidwayR3 is no different from running jobs on Midway. These HPC systems use SLURM scheduler to allocate jobs to compute nodes. The SUs are shared across Midway2, Midway3, and MidwayR, meaning that if you have allocated SUs on Midway2/Midway3 you will also have them on MidwayR3. However, the space allocation is different on MidwayR3. The default storage for each project is 500 GB, and it can be increased if required.   Upon connecting to midwayR3, you will be located on one of the midwayR3 login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, and submitting jobs. Login nodes should not be used for computionally intensive work. All intensive computations should be performed on compute nodes. </p>"},{"location":"open_ondemand/open_ondemand/","title":"Welcome to Open OnDemand at RCC UChicago","text":""},{"location":"open_ondemand/open_ondemand/#introduction","title":"Introduction","text":"<p>Open OnDemand (OOD) is a web-based portal that provides seamless, user-friendly access to High-Performance Computing (HPC) resources at the Research Computing Center (RCC), University of Chicago. With OOD, you can manage files, submit and monitor jobs, and launch interactive applications such as Jupyter, RStudio, and graphical desktop sessions\u2014all from your web browser, without needing to use the command line.</p> <p>Key features of Open OnDemand:</p> <ul> <li>Web-based Access: Access the cluster securely from anywhere using your browser.</li> <li>File Management: Upload, download, move, and edit files directly in your home or project directories.</li> <li>Job Management: Submit, monitor, and manage batch jobs using the Slurm scheduler with intuitive interfaces like Job Composer.</li> <li>Interactive Apps: Launch interactive sessions (e.g., Jupyter, RStudio, Visual Studio Code, Desktop) that run on compute nodes with easy resource selection.</li> <li>Terminal Access: Open a shell session to the cluster directly in your browser.</li> <li>Project Organization: Organize your work with project management tools.</li> </ul>"},{"location":"open_ondemand/open_ondemand/#why-use-open-ondemand","title":"Why Use Open OnDemand?","text":"<p>Open OnDemand is designed to lower the barrier to HPC usage for both new and experienced users. It provides:</p> <ul> <li>a consistent, graphical interface for common HPC tasks,</li> <li>access to powerful interactive applications and remote desktops on the compute nodes,</li> <li>a platform that supports both research and teaching needs, and</li> <li>the ability to work with files and jobs without learning Linux commands.</li> </ul>"},{"location":"open_ondemand/open_ondemand/#accessing-open-ondemand-at-the-rcc","title":"Accessing Open OnDemand at the RCC","text":"<p>To access the RCC Open OnDemand service:</p> <ol> <li>Open your favorite web browser (Chrome, Firefox, Safari, or Edge are recommended).</li> <li>Navigate to <code>https://midway3-ondemand.rcc.uchicago.edu</code> using on-campus networks or cVPN.</li> <li>You will be prompted to log in with your CNetID and password.</li> </ol> <p></p> Figure 1: Login screen"},{"location":"open_ondemand/open_ondemand/#open-ondemand-dashboard","title":"Open OnDemand Dashboard","text":"<p>After logging in, you will see the Open OnDemand dashboard (Figure 2). This is your main portal for accessing HPC resources.</p> <p></p> Figure 2: OOD Dashboard showing commonly used apps <p>The entries in the top bar menu include:</p> <ul> <li> <p>Apps: Show the commonly used apps.</p> </li> <li> <p>Files: Manage files and folders in your home directory and other accessible storage locations on Midway. You can upload, download, copy, move, rename, and delete files and folders.</p> </li> </ul> <p> Figure 3: OOD File Manager with Upload dialog </p> <ul> <li> <p>Jobs:</p> <ul> <li>Active Jobs: View and manage your currently running and queued jobs on the Slurm scheduler.</li> <li>Job Composer: Create and submit new batch jobs using predefined templates or by writing your own submission scripts.</li> </ul> <p> Figure 4: OOD Job Composer user interface</p> <p> Figure 5: OOD Job Composer showing job details and script contents</p> </li> <li> <p>Clusters: Access shell (terminal) access to the Midway3 cluster directly from your browser.</p> </li> <li> <p>Interactive Apps: Launch interactive graphical applications or server-based applications like Jupyter Notebooks, RStudio Server, and full Linux Desktop environments.</p> </li> </ul>"},{"location":"open_ondemand/open_ondemand/#typical-workflow","title":"Typical Workflow","text":"<ol> <li>Manage Files: Use the Files app to upload data, organize directories, and edit scripts.</li> <li>Submit Jobs: Request resources to run the interactive applications, either by filling in the app form or by using the Job Composer app.</li> <li>Launch Interactive Apps: Start a Jupyter Notebook, RStudio Server, or a full Linux desktop session in a new tab on your web browser on the compute node. You can close the tab, and resume the session by clicking the button <code>Launch [AppName]</code> or <code>Connect to [ServerName]</code> in the Job card.</li> <li>Monitor and Manage: Track your jobs and sessions, and clean up resources when finished. Manage your research projects, potentially including data and job organization.</li> </ol>"},{"location":"open_ondemand/open_ondemand/#using-interactive-apps","title":"Using Interactive Apps","text":"<p>One of the most powerful features of Open OnDemand is the ability to launch interactive applications that run on the compute nodes of the Midway3 cluster.</p> <p>General Steps to Launch an Interactive App:</p> <ol> <li> <p>From the OOD dashboard, click on \"Interactive Apps\" in the top menu.</p> <p> Figure 6: OOD Interactive Apps Dropdown Menu</p> </li> <li> <p>A dropdown list of available applications will appear (e.g., Midway3 Desktop, Jupyter Server, RStudio Server).</p> </li> <li>Select the application you wish to use.</li> <li>You will be presented with a form (Figure 7) to specify the resources for your session:<ul> <li>Account: Your Slurm account/allocation (if applicable).</li> <li>Partition: The Slurm partition to run the job on.</li> <li>Number of hours: How long you need the session.</li> <li>Number of cores: The number of CPU cores requested.</li> <li>Memory: The amount of memory (RAM) required.</li> <li>Other application-specific options may also be available.  Figure 7: Job form to request resources for running the app</li> </ul> </li> <li>Once you have filled out the form, click <code>Launch</code>.</li> <li>Your job will be submitted to the Slurm scheduler. You will see its status in the \"My Interactive Sessions\" section of the dashboard.</li> <li>When the job starts and resources are allocated, which may take some time depending on the cluster load and your recent usage history, a Job card (Figure 8) will appear with the <code>Host</code> field showing the compute node where your session is running on. Click on the button <code>Connect</code> or <code>Launch</code> to open your interactive session in a new browser tab.      Figure 8: Job card showing the running app with Host and Session ID with a link to the location where the log files of the session are stored.</li> <li>When you are finished with your session, explicitly close the application and then delete your interactive session from the \"My Interactive Sessions\" page to free up resources.</li> </ol>"},{"location":"open_ondemand/open_ondemand/#managing-your-sessions-and-files","title":"Managing Your Sessions and Files","text":"<ul> <li>Interactive Sessions: Always remember to explicitly delete your interactive sessions from the \"My Interactive Sessions\" page when you are finished. Simply closing the browser tab does NOT terminate the job on the cluster.</li> <li>File Management: Be mindful of your storage quotas. Data generated within Open OnDemand sessions is stored in your standard RCC home or project directories.</li> </ul>"},{"location":"open_ondemand/open_ondemand/#getting-help","title":"Getting Help","text":"<p>For questions, issues, or assistance:</p> <ul> <li>Refer to the main RCC User Guide.</li> <li>Contact RCC Support: <code>help@rcc.uchicago.edu</code></li> </ul> <p>We appreciate your help in making Open OnDemand a valuable resource for the RCC UChicago community!</p>"},{"location":"slurm/faq/","title":"Running Jobs FAQ","text":""},{"location":"slurm/faq/#set-up-and-general-questions","title":"Set-up and general questions","text":""},{"location":"slurm/faq/#how-do-i-submit-a-job-to-midway","title":"How do I submit a job to Midway?","text":"<p>RCC systems use Slurm to manage resources and job queues. To learn more, see Running jobs on RCC clusters.</p>"},{"location":"slurm/faq/#can-i-login-directly-to-a-compute-node","title":"Can I login directly to a compute node?","text":"<p>You can start up an interactive session on a compute node with the <code>sinteractive</code> command. This command takes the same arguments as <code>sbatch</code>. For more information about interactive jobs, see submitting Interactive Jobs.</p>"},{"location":"slurm/faq/#how-do-i-run-jobs-in-parallel","title":"How do I run jobs in parallel?","text":"<p>There are many ways to configure parallel jobs. The best approach will depend on your software and resource requirements. For more information on two commonly used approaches, see Job arrays and Parallel batch jobs.</p>"},{"location":"slurm/faq/#are-there-any-limits-to-running-jobs-on-midway","title":"Are there any limits to running jobs on Midway?","text":"<p>Run <code>rcchelp qos</code> on Midway to view the current \"Quality of Service\"--a set of parameters and constraints that includes maximum number of jobs and maximum wall time.</p>"},{"location":"slurm/faq/#i-am-a-member-of-multiple-accounts-how-do-i-choose-which-allocation-is-charged","title":"I am a member of multiple accounts. How do I choose which allocation is charged?","text":"<p>If you belong to multiple accounts, jobs will get charged to your default account unless you specify the <code>--account=&lt;account_name&gt;</code> option when you submit a job with sbatch. You may request a change in your default account by contacting our Help Desk.  </p>"},{"location":"slurm/faq/#how-can-i-get-emails-when-my-job-starts-and-when-it-finishes","title":"How can I get emails when my job starts and when it finishes?","text":"<p>For security reasons, sending out notification emails directly using the standard Slurm command <code>#SBATCH --mail-user=&lt;CNetID&gt;@uchicago.edu</code> is not allowed. As a robust alternative, we suggest using the RCC mail server to send out notification emails. Update your script with the following lines: <pre><code>#SBATCH --mail-type=ALL# Mail events (NONE, BEGIN, END, FAIL, ALL)\n#SBATCH --mail-user=&lt;CNetID&gt;@rcc.uchicago.edu  # Where to send email\n</code></pre></p>"},{"location":"slurm/faq/#how-do-i-run-jobs-that-need-to-run-longer-than-the-maximum-wall-time","title":"How do I run jobs that need to run longer than the maximum wall time?","text":"<p>The RCC queuing system is designed to provide fair resource allocation to all RCC users. The maximum wall time is intended to prevent individual users from using more than their fair share of cluster resources.</p> <p>If you have specific computing tasks that cannot be solved with the current constraints, please submit a special request for resources to our Help Desk.</p>"},{"location":"slurm/faq/#can-i-create-a-cron-job","title":"Can I create a cron job?","text":"<p>The RCC does not support users creating cron jobs. However, it is possible to use Slurm to submit \u201ccron-like\u201d jobs. See Cron-like.  </p>"},{"location":"slurm/faq/#job-submission-trouble","title":"Job submission trouble","text":""},{"location":"slurm/faq/#why-is-my-job-not-starting","title":"Why is my job not starting?","text":"<p>This could be due to a variety of factors. Running <code>squeue --user=&lt;userid&gt;</code> can will help to find the answer; see in particular the NODELIST(REASON) column in the <code>squeue</code> output. A job that is waiting in the queue may show one of the following labels in this column:</p> <p>(Priority):  Other jobs currently have higher priority than your job.</p> <p>(Resources):  Your job has enough priority to run, but there aren\u2019t yet enough free resources to run it.</p> <p>(QOSResourceLimit):  Your job exceeds the QOS limits. The QOS limits include wall time, number of jobs a user can have running at once, number of nodes a user can use at once, and so on. For example, if you are at or near the limit of number of jobs that can be run at once, your job will become eligible to run as soon as other jobs finish.</p> <p>Please contact RCC support if you believe that your job is not being handled correctly by the Slurm queuing system.</p> <p>Note: If you see a large number of jobs that aren\u2019t running when many resources are idle, it is possible that RCC staff have scheduled an upcoming maintenance window. In this case, any jobs requesting a wall time that overlaps with the maintenance window will remain in the queue until after the maintainence period is over. The RCC staff will typically notify users via email prior to performing a maintenance and after a maintenance is completed.</p>"},{"location":"slurm/faq/#why-does-my-job-fail-after-a-few-seconds","title":"Why does my job fail after a few seconds?","text":"<p>This is most likely because there is an error in your job submission script, or because the program you are trying to run is producing an error and terminating prematurely.</p> <p>If you need help troubleshooting the issue, please send your job submission script, as well as the error generated by your job submission script to ourHelp Desk</p>"},{"location":"slurm/faq/#why-does-my-job-fail-with-message-exceeded-memory-limit-being-killed","title":"Why does my job fail with message \u201cexceeded memory limit, being killed\u201d?","text":"<p>Let's understand this with an example. Let's say on the main midway2 partition, broadwl, Slurm allocates 2 GB of memory per allocated CPU by default. If your computations require more than the default amount, you should adjust the memory allocated to your job with the <code>--mem</code> or <code>--mem-per-cpu</code> flags. For example, to request 10 cores and 40 GB of memory on a broadwl node, include these options when running <code>sbatch</code> or <code>sinteractive</code>: <code>--ntasks=1 --cpus-per-task=10 --mem=40G</code>.</p>"},{"location":"slurm/faq/#why-does-my-sinteractive-job-fail-with-connection-closed","title":"Why does my <code>sinteractive</code> job fail with \u201cConnection closed.\u201d?","text":"<p>There are two likely explanations for this error.</p> <p>One possibility is that you are over the time limit. The default walltime for sinteractive is 2 hours. This can be increased by including the <code>--time</code> flag to your <code>sinteractive</code> call.</p> <p>Another possiblity is that your job exceeded the memory limit. You can resolve this by requesting additional memory using <code>--mem</code> or <code>--mem-per-cpu</code>.</p>"},{"location":"slurm/faq/#why-does-my-sinteractive-job-fail-with-ssh-symbol-lookup-error-ssh-undefined-symbol-evp_kdf_ctrl-version-openssl_1_1_1b","title":"Why does my <code>sinteractive</code> job fail with <code>ssh: symbol lookup error: ssh: undefined symbol: EVP_KDF_ctrl, version OPENSSL_1_1_1b?</code> \"","text":"<p>The error <code>ssh: symbol lookup error: ssh: undefined symbol: EVP_KDF_ctrl, version OPENSSL_1_1_1b</code> indicates the mismatch version of the OpenSSL used by <code>sinteractive</code> and that by the <code>python</code> module loaded in your shell environment. There are two options to resolve this issue:</p> <p>1) Prepend <code>LD_LBIRARY_PATH</code> with the path to the SSH-compatible version of OpenSSL: <pre><code>export LD_LIBRARY_PATH=/lib64:$LD_LIBRARY_PATH\n</code></pre> and run <code>sinteractive</code> again.</p> <p>2) Unload the <code>python</code> module: <pre><code>module unload python\n</code></pre> then run <code>sinteractive</code> again, and load the <code>python/anaconda</code> module within the interactive session.</p>"},{"location":"slurm/faq/#technical-questions","title":"Technical questions","text":""},{"location":"slurm/faq/#what-compilers-does-the-rcc-support","title":"What compilers does the RCC support?","text":"<p>The RCC supports the GNU, Intel, PGI and NVidia\u2019s CUDA compilers.</p>"},{"location":"slurm/faq/#which-versions-of-mpi-does-rcc-support","title":"Which versions of MPI does RCC support?","text":"<p>The RCC maintains OpenMPI, IntelMPI, and MVAPICH2 compilers. See MPI jobs for more information and instructions for using these MPI frameworks.</p>"},{"location":"slurm/faq/#can-rcc-help-me-parallelize-and-optimize-my-code","title":"Can RCC help me parallelize and optimize my code?","text":"<p>The RCC support staff are available to consult with you or your research team to help parallelize and optimize your code for use on RCC systems. Contact our Help Desk to set up a consultation.</p>"},{"location":"slurm/faq/#does-rcc-provide-gpu-computing-resources","title":"Does RCC provide GPU computing resources?","text":"<p>Yes. The RCC high-performance systems provide GPU-equipped compute nodes. For instructions on using the GPU nodes, see GPU jobs.</p>"},{"location":"slurm/main/","title":"Running jobs on RCC clusters","text":"<p>This page describes core concepts for running programs on RCC clusters. </p>"},{"location":"slurm/main/#service-units-allocations-and-accounts","title":"Service units, allocations, and accounts","text":"<p>All jobs running on RCC clusters compute nodes consume service units (SUs). In short, SUs measure the amount of computing resources (CPUs/GPUs/time) consumed on a compute cluster. </p> <p>More information on SUs</p> <p>In standard settings, 1 SU equals the usage of 1 processing unit for 1 hour, but the exact calculation will vary depending on the amount of memory requested, as well as additional factors like the use of GPUs and CPU architecture. By using SUs, we aim to provide \u201cfair\u201d access to computing resources.</p> <p>SUs can be requested through an allocation. Allocations are ultimately associated with a PI's account. Thus, when we submit a job, we specify the account to which the SUs will be charged. If we submit a job on Midway2 without specifying an account, your default account (likely <code>pi-drpepper</code>) will be used. On Midway3 you must specify an account for a job to be successfully submitted. </p>"},{"location":"slurm/main/#slurm-workload-manager","title":"Slurm Workload Manager","text":"<p>RCC's shared clusters (Midway2, Midway3, etc.) are compute clusters shared with the entire RCC user community. To keep track of the usage of this sharing computational resources:</p> <ol> <li> <p>Jobs must be scheduled in a way that is fair to all users. </p> </li> <li> <p>Consumption of resources needs to be recorded. </p> </li> <li> <p>Access to resources needs to be controlled. </p> </li> </ol> <p>Consequently, the compute clusters use a scheduler to queue the requests for access to compute resources. These requests are called jobs and contain directions about the scripts/programs the user wants to run. In particular, we use the Slurm workload manager to schedule jobs in batch and interactive formats.  </p> <p>You can think of Slurm as the queue manager that facilitates access to the compute nodes. We submit a job to Slurm, which decides (based on current node utilization and the requested parameters) which compute nodes are permitted to use and available to send your job to. </p>"},{"location":"slurm/main/#submitting-jobs","title":"Submitting Jobs","text":"<p>The flowchart below illustrates the main steps in that process. </p> <p> </p>"},{"location":"slurm/main/#interactive-active-vs-batch-passive-jobs","title":"Interactive (active) vs. batch (passive) jobs","text":"<p>There are two main ways to run programs on RCC clusters: </p> <ul> <li> <p>Active via an \"interactive session\"; </p> </li> <li> <p>Passive via a \"batch job\" </p> </li> </ul> <p>It is important to note that in both ways you are essentially submitting a job to Slurm. You have to wait for the requested resource (i.e. number of CPU cores, memory, and GPUs, if any) to be allocated to your session or job.</p> <p>Interactive jobs allow you to actively interact with the programs running on compute node(s) (e.g., executing cells in a Jupyter Notebook or analyzing output data using GUI applications). In an interactive session, you will load the necessary software modules, and run the programs or execute your scripts. This is helpful for exploratory work or troubleshooting.  An interactive job will persist until you disconnect from the compute node or until you reach the maximum requested time.</p> <p>Batch jobs are non-interactive: you prepare a text-based script where you specify the requested resource and the list of commands to be excuted on the compute nodes. You then submit the script to Slurm via the <code>sbatch</code> command. As soon as Slurm allocates the requested resource to the job, the commands in the script will get executed on the allocated nodes. Typically, a batch job may terminate when (1) all the commands in the job script are complete, (2) the job's wall time is reached, (3) an error occurs during the command execution, or (4) you cancel the job via the <code>scancel</code> command.</p> <ul> <li>Running jobs on RCC compute nodes through <code>sinteractive</code> (active) </li> <li>Submitting jobs to RCC compute nodes through <code>sbatch</code> (passive) </li> </ul> <p>You can submit more than one interactive and batch jobs simultaneously. However, the number of simultaneous jobs and the accumulated requested resources are subject to the quality of service (QoS) of the partitions to which you submit the jobs.</p> <p>Note</p> <p>You can use the command <code>scontrol show config</code> to see the default values of the requested resource that Slurm will use for an interactive or batch job.</p>"},{"location":"slurm/main/#job-limits-and-qos","title":"Job limits and QoS","text":"<p>To distribute computational resources fairly, the RCC limits the computing resources users request. These limits are enforced by the QoS (Quality of Service) assigned to each partition. A QoS is a set of parameters (e.g., MaxNodes, MaxCPUs, MaxWall, etc.) Read more about these regulations on our partitions page. </p> <p>Groups participating in the cluster partnership program (CPP) may customize resource limits for their partitions. </p> <p>Additional information on limits can be found by entering the command: <pre><code>rcchelp qos\n</code></pre> Observe that QoS are often different depending on the partition.</p> <p>You can request temporary exceptions to a particular limit by contacting our Help Desk. Special allocations are evaluated on an individual basis and may or may not be granted.</p>"},{"location":"slurm/sbatch/","title":"Batch jobs","text":"<p>The <code>sbatch</code> command requests computing resources for non-interactive batch jobs. Rather than requesting resources from the command line, users typically write an <code>.sbatch</code> script to request resources for a job and then submit that job to be run on a cluster. A batch job doesn\u2019t require the user to be logged in after submission and ends when either:</p> <ol> <li>The program finishes running, </li> <li>The job's maximum time is reached, </li> <li>An error occurs. </li> </ol>"},{"location":"slurm/sbatch/#sbatch-scripts","title":"<code>.sbatch</code> scripts","text":"<p>In an <code>.sbatch</code> script, all Slurm parameters are declared with <code>#SBATCH</code> followed by a flag. Here is a sample script you can use to test out the sbatch parameters described below.</p> <p>Each time you run a script, Slurm gives that particular run a job ID. This sample script creates a .txt file with the job ID as the filename and writes information about the job run to the file. It does this by referencing some of the environment variables Slurm sets when it runs the job.</p> <p>To set up the sample script, first connect to Midway via SSH or ThinLinc. Next, create a <code>job-info.sbatch</code> file and copy this code into it. Replace <code>pi-drpepper</code> in the  <code>--account=</code> flag with your group and <code>jdoe</code> in the <code>--mail-user=</code> flag with your CNet ID. You can also change the <code>--mail-type=</code> flag if you don\u2019t want to receive email notifications every step of the way.</p> Midway3MidwaySSD <pre><code>#!/bin/bash\n#SBATCH --job-name=job-info\n#SBATCH --output=job-info.out\n#SBATCH --error=job-info.err\n\n#SBATCH --account=pi-drpepper\n#SBATCH --partition=caslake\n\n#SBATCH --time=00:03:30\n\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=14\n\n#SBATCH --mail-type=ALL  # Email notification options: ALL, BEGIN, END, FAIL, ALL, NONE\n#SBATCH --mail-user=jdoe@rcc.uchicago.edu  # Replace jdoe with your CNET and be sure to include \"@rcc\"\n\ntouch $SLURM_JOB_ID.txt\necho \"Job ID: $SLURM_JOB_ID\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Job name: $SLURM_JOB_NAME\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N tasks: $SLURM_ARRAY_TASK_COUNT\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N cores: $SLURM_CPUS_ON_NODE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N threads per core: $SLURM_THREADS_PER_CORE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Minimum memory required per CPU: $SLURM_MEM_PER_CPU\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Requested memory per GPU: $SLURM_MEM_PER_GPU\" &gt;&gt; $SLURM_JOB_ID.txt\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=job-ssd-test\n#SBATCH --output=job-ssd-test.out\n#SBATCH --error=job-ssd-test.err\n\n#SBATCH --account=ssd\n#SBATCH --partition=ssd         # for ssd-gpu partition, change to --partition=ssd-gpu\n#SBATCH --qos=ssd\n\n#SBATCH --time=00:03:30\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n\n#SBATCH --mail-type=ALL  # Email notification options: ALL, BEGIN, END, FAIL, ALL, NONE\n#SBATCH --mail-user=jdoe@rcc.uchicago.edu  # Replace jdoe with your CNET and be sure to include \"@rcc\"\n\ntouch $SLURM_JOB_ID.txt\necho \"Job ID: $SLURM_JOB_ID\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Job name: $SLURM_JOB_NAME\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N tasks: $SLURM_ARRAY_TASK_COUNT\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N cores: $SLURM_CPUS_ON_NODE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N threads per core: $SLURM_THREADS_PER_CORE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Minimum memory required per CPU: $SLURM_MEM_PER_CPU\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Requested memory per GPU: $SLURM_MEM_PER_GPU\" &gt;&gt; $SLURM_JOB_ID.txt\n</code></pre> <p>Here is an explanation of what each of these parameters means:</p> Option Description <code>--job-name=my_run</code> Assigns name <code>job-info</code> to the job. <code>--output=my_run.out</code> Writes console output to file <code>job-info.out</code>. <code>--error=my_run.err</code> Writes error messages to file <code>job-info.err</code>. <code>--account=pi-drpepper</code> Charges the job to the account <code>pi-drpepper</code> <code>--partition=caslake</code> Requests compute nodes from the Cascade Lake partition on the Midway3 cluster. <code>--time=1-03:30:00</code> Reserves the computing resources for 1 day, 3 hours, and 30 minutes max (actual time may be shorter if your run completes before this time wall). <code>--nodes=4</code> Requests 4 compute nodes (computers) <code>--ntasks-per-node=14</code> Requests 14 cores (CPUs) per node, for a total of 14 * 4 = 56 cores. <code>--mem-per-cpu=2000</code> Requests 2000 MB (2 GB) of memory (RAM) per core, for a total of 2 * 14 = 28 GB per node. <code>--mail-type=ALL</code> Mail events (NONE, BEGIN, END, FAIL, ALL) <code>--mail-user=jdoe@rcc.uchicago.edu</code> Add <code>rcc.</code> to your email. <p>In this example, we use <code>sbatch</code> commands to request 4 compute nodes with 14 CPUs each. This means we are requesting a total of 56 CPUs to our program. The <code>touch</code> command creates a file and the <code>echo</code> commands write information about the job run to that file.</p>"},{"location":"slurm/sbatch/#submitting-a-sbatch-script","title":"Submitting a <code>.sbatch</code> script","text":"<p>Continuing the example above, suppose that the sbatch script is saved in the current directory into a file called <code>job.sbatch</code>. This script is submitted to the cluster using the following command: <pre><code>sbatch ./job.sbatch\n</code></pre> or more generally: <pre><code>sbatch ./&lt;your_sbatch_file&gt;\n</code></pre></p> <p>You can find more example <code>.sbatch</code> submission scripts in the RCC Slurm workshop materials.</p>"},{"location":"slurm/sbatch/#managing-jobs","title":"Managing jobs","text":"<p>Slurm job scheduler provides several command-line tools for checking on the status of your jobs and for managing them.</p>"},{"location":"slurm/sbatch/#checking-job-status","title":"Checking job status","text":"<p>Use the <code>squeue</code> (Slurm queue) command to check on the status of jobs. Running <code>squeue</code> with no flags will show the full queue (all pending and running jobs.)</p> <p>To view only the jobs that you have submitted, use the <code>--user</code> flag:  <pre><code>squeue --user=&lt;CNetID&gt;\n</code></pre> For example:  <pre><code>squeue --user=jdoe\n</code></pre></p> <p>!!! Note: <code>0:00</code> jobs     Any job with <code>0:00</code> in the TIME column is still waiting in the queue. </p> <p>To get information about all jobs that are waiting to run on the <code>gpu</code> partition, enter: <pre><code>squeue --state=PENDING --partition=gpu\n</code></pre></p> <p>To get information about all your jobs that are running on the <code>gpu</code> partition, type: <pre><code>squeue --state=RUNNING --partition=gpu --user=&lt;CNetID&gt;\n</code></pre></p> <p>To get the estimated start time (if available) of your submitted jobs, use <pre><code>squeue -user $USER  --start\n</code></pre> or <pre><code>scontrol show job [jobID] | grep StartTime\n</code></pre></p> <p>To get what jobs are running on a specific node, like <code>midway3-0213</code> <pre><code>squeue -w midway3-0213\n</code></pre></p>"},{"location":"slurm/sbatch/#squeue-status-and-reason-codes","title":"<code>squeue</code> status and reason codes","text":"<p>The <code>squeue</code> command details a variety of information on an active job\u2019s status with state and reason codes. </p> <p>The following tables outline a variety of job states and reason codes you may encounter when using <code>squeue</code> to check on your jobs.</p>"},{"location":"slurm/sbatch/#job-state-codes","title":"Job State Codes","text":"Status Code Explaination COMPLETED <code>CD</code> The job has completed successfully. COMPLETING <code>CG</code> The job is finished, but some processes are still active. FAILED <code>F</code> The job terminated with a non-zero exit code and failed to execute. PENDING <code>PD</code> The job needs resource allocation. It will eventually run. PENDING <code>CF</code> The job is being configured. The resources are allocated but are waiting for them to become ready for use. PREEMPTED <code>PR</code> The job was terminated because of preemption by another job. RUNNING <code>R</code> The job is currently allocated to a node and is running. SUSPENDED <code>S</code> A running job has been stopped with its cores released to other jobs. STOPPED <code>ST</code> A running job has been stopped with its cores retained. <p>A full list of these Job State codes can be found in Slurm\u2019s documentation..</p>"},{"location":"slurm/sbatch/#job-reason-codes","title":"Job Reason Codes","text":"Reason Code Explanation <code>AssociationCpuLimit</code> All CPUs assigned to your job\u2019s specified association are in use; the job will run eventually. <code>AssociationMaxJobsLimit</code> Maximum number of jobs for your job\u2019s association has been met; the job will run eventually. <code>AssociationNodeLimit</code> All nodes assigned to your job\u2019s specified association are in use; the job will run eventually. <code>Dependency</code> This job is waiting for a dependent job to complete and will run afterward. <code>InvalidAccount</code> The job\u2019s account is invalid. Cancel the job and rerun with the correct account. <code>InvaldQoS</code> The job\u2019s QoS is invalid. Cancel the job and rerun with the correct account. <code>PartitionCpuLimit</code> All CPUs assigned to your job\u2019s specified partition are in use; the job will run eventually. <code>PartitionMaxJobsLimit</code> Maximum number of jobs for your job\u2019s partition has been met; the job will run eventually. <code>PartitionNodeLimit</code> All nodes assigned to your job\u2019s specified partition are in use; the job will run eventually. <code>Priority</code> One or more higher priority jobs are in queue for running. Your job will eventually run. <code>QOSGrpCpuLimit</code> All CPUs assigned to your job\u2019s specified QoS are in use; the job will run eventually. <code>QOSGrpMaxJobsLimit</code> Maximum number of jobs for your job\u2019s QoS has been met; the job will run eventually. <code>QOSGrpNodeLimit</code> All nodes assigned to your job\u2019s specified QoS are in use; the job will run eventually. <code>QOSMaxJobsPerUserLimit</code> The number of jobs you have submitted exceeds the maximum number set by the QoS <code>Resources</code> The job is waiting for resources to become available and will eventually run. <p>A full list of these Job Reason Codes can be found in Slurm\u2019s documentation..</p> <p>For more information, consult the command-line help by typing <code>squeue --help</code>, or visit the official online documentation.</p>"},{"location":"slurm/sbatch/#pausing-and-resuming-submitted-jobs","title":"Pausing and resuming submitted jobs","text":"<p>Jobs can be paused using the command: <pre><code>scontrol suspend &lt;job_id&gt;\n</code></pre> This can be especially useful if a job produces a large output that needs to be moved to a new location before the job finishes.</p> <p>To resume a suspended job, run the following: <pre><code>scontrol resume &lt;job_id&gt;\n</code></pre></p>"},{"location":"slurm/sbatch/#canceling-a-submitted-jobs","title":"Canceling a submitted jobs","text":"<p>To cancel a job you have submitted, use the <code>scancel</code> command. This requires you to specify the ID of the job you wish to cancel. </p> <p>For example, to cancel a job with ID 8885128, do the following: <pre><code>scancel 8885128\n</code></pre> If you are unsure what job ID to cancel, see the JOBID column from running <code>squeue --user=&lt;CNetID&gt;</code>.</p> <p>To cancel all jobs you have submitted that are either running or waiting in the queue, enter the following: <pre><code>scancel --user=&lt;CNetID&gt;\n</code></pre></p>"},{"location":"slurm/sbatch/#monitoring-running-jobs","title":"Monitoring running jobs","text":"<p>You can monitor your job by connecting to the compute node it runs on via <code>SSH</code> and using the <code>htop</code> command.</p> <p>To do this, run the following to see your running jobs and which compute nodes your jobs are running on: <pre><code>squeue --state=RUNNING --user=&lt;CNetID&gt;\n</code></pre> The last column of the output tells us which nodes are allocated for each job. You can connect to the compute node using the following command, where, for example, we are connecting to the compute node <code>midway2-0172</code>. <pre><code>ssh midway2-0172\n</code></pre> Then, you can view processes running on this compute node, including your job, which will be listed under your CNetID in the USER column, entering the following command:  <pre><code>htop\n</code></pre></p>"},{"location":"slurm/sbatch/#getting-the-accounting-information-of-jobs","title":"Getting the accounting information of jobs","text":"<p>The <code>sacct</code> command displays accounting data for all jobs and job steps in the Slurm job accounting log or Slurm database.</p> <p>To inquiry the resources used by a job ID (pending, running or terminated), use <pre><code>sacct -j [jobID]\n</code></pre></p> <p>Advanced tip</p> <p>You can customize the output of <code>squeue</code> and <code>sacct</code> by configuring your slurm environment variables: <pre><code>export SACCT_FORMAT=\"jobid,partition,user,account%12,alloccpus,node%12,elapsed,totalcpu,maxRSS,ReqM\"\nexport SQUEUE_FORMAT=\"%13i %12j %10P %10u %12a %8T %9r %10l %.11L %5D %4C %8m %N\"\nsqueue -u cnetid\n</code></pre> You can put the two export commands into a configuration bash file <code>set_slurm_env.sh</code> like here, and <code>source set_slurm_env.sh</code> before running <code>squeue</code>.</p>"},{"location":"slurm/sbatch/#monitoring-sus-consumed-per-job","title":"Monitoring SUs consumed per Job","text":"<p>When the job accepted by the Slurm scheduler is completed or failed, the account specified in the Slurm script is charged for SUs. A user can retrieve info on SUs consumed per job using (need to be logged in to Midway2): <pre><code>rcchelp usage -accounts &lt;account_name&gt; -byjob | grep &lt;user_cnetid&gt;\n</code></pre> or alternatively: <pre><code>accounts usage -accounts &lt;account_name&gt; -byjob | grep &lt;user_cnetid&gt;\n</code></pre></p>"},{"location":"slurm/sbatch/#examples","title":"Examples","text":"<p>Below are some example submission scripts you can adapt to run your jobs on Midway. See also the materials from the RCC Slurm workshop for additional examples. </p> <p>The SLURM documentation is always a good reference for all the <code>#SBATCH</code> parameters below.</p> <p>Note</p> <p>If you need help to troubleshoot a Slurm submission script, please ensure that the script is not located in your <code>/home</code> or <code>/scratch</code> directories that no one except you can access. Instead, please place your script and associated input files in a project directory and set read permission to the group owner <code>pi-cnetid</code>.</p>"},{"location":"slurm/sbatch/#simple-jobs","title":"Simple jobs","text":""},{"location":"slurm/sbatch/#a-single-core-job-to-the-standard-compute-partition","title":"A single core job to the standard compute partition","text":"Midway2Midway3 <pre><code>#!/bin/bash\n\n#SBATCH --job-name=single-node-cpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=broadwl  # accessible partitions listed by the sinfo command\n#SBATCH --ntasks-per-node=1  # number of tasks per node\n#SBATCH --cpus-per-task=1    # number of CPU cores per task\n\n# Load the require module(s)\nmodule load python\n\n# match the no. of threads with the no. of CPU cores\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK  \n\n# Load the require module(s)\npython analyze.py\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=single-node-cpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=caslake  # accessible partitions listed by the sinfo command\n#SBATCH --ntasks-per-node=1  # number of tasks per node\n#SBATCH --cpus-per-task=1    # number of CPU cores per task\n\n# Load the require module(s)\nmodule load python\n\n# match the no. of threads with the no. of CPU cores\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK  \n\n# Load the require module(s)\npython analyze.py\n</code></pre>"},{"location":"slurm/sbatch/#a-single-node-gpu-job-to-the-gpu-partition","title":"A single node GPU job to the GPU partition","text":"Midway2Midway3 <pre><code>#!/bin/bash\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu2\n#SBATCH --gres=gpu:1\n#SBATCH --ntasks-per-node=1 # num cores to drive each gpu\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n# TO USE V100 specify --constraint=v100\n# TO USE RTX600 specify --constraint=rtx6000\n#SBATCH --constraint=v100   # constraint job runs on V100 GPU use\n#SBATCH --ntasks-per-node=1 # num cores to drive each gpu\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <p>Notes</p> <ul> <li>If your application supports multithreading (e.g., with OpenMP), you want to specify the number of CPU cores per task greater than 1, e.g., <code>#SBATCH --cpus-per-task=8</code></li> <li>You can check the available partitions to your account via the command <code>rcchelp sinfo</code> to specify in <code>--partition</code>.</li> <li>You can concatenate more than one run in a job script.</li> <li>If the job submission fails, please read the error message carefully: there is information regarding invalid combinations of <code>partition</code>, <code>account</code>, or <code>qos</code> that may help you correct.</li> </ul>"},{"location":"slurm/sbatch/#large-memory-jobs","title":"Large-Memory Jobs","text":"<p>If your calculations need more than 60 GB of memory, submit the job to the <code>bigmem</code> partition. You can query the technical specification of the partition via the following command: </p> <p><pre><code>scontrol show partition bigmem\n</code></pre> and then <code>scontrol show node</code> to find out the memory capacity of its individual nodes.</p> <p>To submit a job to <code>bigmem</code>, include this line in your <code>.sbatch</code> script:</p> <pre><code>#SBATCH --partition=bigmem\n</code></pre>"},{"location":"slurm/sbatch/#mpi-jobs","title":"MPI jobs","text":"<p>Many applications use Message Passing Interface (MPI) to improve performance for distributed and parallel computing. For more information on the MPI libraries available on RCC clusters, run  <code>module avail openmpi</code> and <code>module avail intelmpi</code>. using more recent modules to compile your codes (e.g., <code>intelmpi</code> 2021 and later, <code>openmpi</code> 3.0 and later) is recommended. </p> <p>Read more about the MPI module here.</p> <p>Below is a simple C program (<code>test-mpi.c</code>) you can test for your MPI build and the loaded MPI libraries.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;mpi.h&gt;\n\nint main(int argc, char *argv[], char *envp[]) {\n  int numprocs, rank, namelen;\n  char processor_name[MPI_MAX_PROCESSOR_NAME];\n\n  MPI_Init(&amp;argc, &amp;argv);\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n  MPI_Get_processor_name(processor_name, &amp;namelen);\n\n  printf(\"Process %d on %s out of %d\\n\", rank, processor_name, numprocs);\n\n  MPI_Finalize();\n}\n</code></pre> <p>Copy <code>test-mpi.c</code> to your home directory on Midway 2 or 3, load the default OpenMPI module, and compile the program on one of the login nodes:</p> <pre><code>module load openmpi\nmpicc test-mpi.c -o mytest\n</code></pre> <p>Note</p> <p>It is recommended to check that the version of <code>mpicc</code> is the one you wanted via <code>which mpicc</code>.</p> <p>Then prepare a job script <code>test.sbatch</code> to submit a job to Midway to run the program:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=test\n#SBATCH --output=test.out\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=28\n#SBATCH --partition=broadwl\n\n# Load the default OpenMPI module you used to compile the source file.\nmodule load openmpi\n\n# relax the locked memory limit\nulimit -l unlimited\n\n# Run the MPI program with mpirun. Although the -n flag is not required and\n# mpirun will automatically figure out the best configuration from the\n# Slurm environment variables, it is recommended to specify -n and/or -ppn\n# as explicit as possible.\n\nn=$(( SLURM_NUM_NODES * SLURM_NTASKS_PER_NODE ))\nmpirun -n $n --bind-to core --map-by core ./mytest\n</code></pre> <p>Note</p> <p>The options <code>--bind-to core --map-by core</code> were added to the <code>mpirun</code> command, indicating that the MPI tasks should be bound to physical CPU cores to improve performance.</p> <p>Submit the MPI job:</p> <pre><code>sbatch test.sbatch\n</code></pre> <p>Here is an example output: <pre><code>Process 1 on midway2-0172.rcc.local out of 56\nProcess 3 on midway2-0172.rcc.local out of 56\nProcess 5 on midway2-0172.rcc.local out of 56\n...\nProcess 50 on midway2-0174.rcc.local out of 56\nProcess 33 on midway2-0174.rcc.local out of 56\n</code></pre></p> <p>This output shows that the computation is distributed on four different nodes, with many threads running simultaneously on the same node.</p> <p>It is recommended to specify the number of tasks per node with the <code>--ntasks-per-node</code> option. For example, submitting the job like this:</p> <pre><code>sbatch --ntasks=56 --ntasks-per-node=1 hellompi.sbatch\n</code></pre> <p>results in each task running on a different node:</p> <pre><code>Process 52 on midway2-0175.rcc.local out of 56 \nProcess 50 on midway2-0173.rcc.local out of 56\nProcess 49 on midway2-0172.rcc.local out of 56\n...\nProcess 6 on midway2-0017.rcc.local out of 56\nProcess 21 on midway2-0096.rcc.local out of 56\nProcess 19 on midway2-0072.rcc.local out of 56\nProcess 23 on midway2-0100.rcc.local out of 56\n</code></pre> <p>If you want to minimize the number of nodes by packing as many tasks into a node as possible (which is usually good for reducing communication overhead), then do:</p> <pre><code>sbatch --nodes=2 --ntasks-per-node=28 hellompi.sbatch\n</code></pre>"},{"location":"slurm/sbatch/#hybrid-mpiopenmp-jobs","title":"Hybrid MPI/OpenMP jobs","text":"<p>The following simple C source code (<code>test-hybrid.c</code>) illustrates a hybrid MPI/OpenMP program you can use to test.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;omp.h&gt;\n#include \"mpi.h\"\n\nint main(int argc, char *argv[]) {\n  int numprocs, rank, namelen;\n  char processor_name[MPI_MAX_PROCESSOR_NAME];\n  int iam = 0, np = 1;\n\n  MPI_Init(&amp;argc, &amp;argv);\n  MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);\n  MPI_Get_processor_name(processor_name, &amp;namelen);\n\n  #pragma omp parallel default(shared) private(iam, np)\n  {\n    np = omp_get_num_threads();\n    iam = omp_get_thread_num();\n    printf(\"Hello from thread %d out of %d from process %d out of %d on %s\\n\",\n           iam, np, rank, numprocs, processor_name);\n  }\n\n  MPI_Finalize();\n}\n</code></pre> <p>To run the program on the RCC cluster, copy <code>test-hybrid.c</code> to your home directory, then compile the code by entering the following commands into a terminal on a login node:</p> <pre><code>module load openmpi\nmpicc -fopenmp test-hybrid.c -o mytest\n</code></pre> <p>Here, we load the default OpenMPI compiler, but it should be possible to use any available MPI compiler to compile and run this example. Note that the option <code>-fopenmp</code> must be used here to compile the program because the code includes OpenMP directives (use <code>-openmp</code> or <code>-qopenmp</code> for the Intel compiler or <code>-mp</code> for the PGI compiler).</p> <p>Then prepare <code>test.sbatch</code> is a submission script that can be used to submit a job to Midway2 to run the <code>mytest</code> program. </p> <pre><code>#!/bin/bash\n\n# A job submission script for running a hybrid MPI/OpenMP job on Midway2.\n\n#SBATCH --job-name=test\n#SBATCH --output=test.out\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=2\n#SBATCH --cpus-per-task=8\n#SBATCH --partition=caslake\n\n# Load the default OpenMPI module.\nmodule load openmpi\n\n# relax the locked memory limit\nulimit -l unlimited\n\n# Set OMP_NUM_THREADS to the number of CPUs per task we asked for.\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\nn=$(( SLURM_NUM_NODES * SLURM_NTASKS_PER_NODE ))\nmpirun -np $n ./hellohybrid\n</code></pre> <p>The options are similar to running an MPI job, with some differences:</p> <ul> <li><code>--nodes=2</code> specifies the number of nodes.</li> <li><code>--ntasks-per-node=2</code> specifies the number of MPI processes (or tasks) per node.</li> <li><code>--cpus-per-task=8</code> allocates 8 CPUs for each task.</li> <li><code>export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK</code> sets the number of OpenMP threads to the number of requested cores (CPUs) for each task.</li> </ul> <p>You can submit <code>test.sbatch</code> using the following command from one of the Midway2 login nodes:</p> <pre><code>sbatch test.sbatch\n</code></pre>"},{"location":"slurm/sbatch/#gpu-jobs","title":"GPU jobs","text":"<p>There are shared GPU nodes on both Midway2 and Midway3 where you can run GPU-enabled applications. You can check the partition <code>gpu2</code> (on <code>Midway2</code>) and <code>gpu</code> (on Midway3) to see their constituent nodes: </p> Midway2Midway3 <pre><code>scontrol show partition gpu2\n</code></pre> <pre><code>scontrol show partition gpu\n</code></pre> <p>and then check the features of the individual nodes, for example,</p> Midway2Midway3 <pre><code>scontrol show node midway2-gpu02\n</code></pre> <pre><code>scontrol show node midway3-0278\n</code></pre> <p>which shows NVIDIA Tesla K80, Tesla V100 or Quadro RTX6000 GPUs.</p> <p>To submit a job to one of the GPU nodes, you must specify the correct partition and the number of GPUs in the <code>.sbatch</code> scripts, for example, for job scripts on Midway2:</p> <p><pre><code>#SBATCH --partition=gpu2\n#SBATCH --gres=gpu:N\n</code></pre> where <code>N</code> is the number of GPUs requested. Allowable settings for <code>N</code> range from 1 to 4, depending on the number of GPUs per node. </p> <p>If your application is entirely GPU-driven, you do not need to explicitly request cores, as one CPU core will be assigned by default to act as a master to launch the GPU-based calculation. However, if your application is mixed CPU-GPU, then you will need to request the number of cores with <code>\u2013ntasks</code> as is required by your job.</p> Midway2Midway3 <pre><code>#!/bin/bash\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1        # number of GPUs per node  \n#SBATCH --ntasks-per-node=1 # number of tasks per node to drive the GPUs in the node\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=1gpu-example\n#SBATCH --account=pi-[group]\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n# TO USE V100 specify --constraint=v100\n# TO USE RTX600 specify --constraint=rtx6000\n#SBATCH --constraint=v100   # constraint job runs on V100 GPU use\n#SBATCH --ntasks-per-node=1 # num cores to drive each gpu\n#SBATCH --cpus-per-task=1   # set this to the desired number of threads\n\n# LOAD MODULES\nmodule load tensorflow\nmodule load cudnn\n\n# DO COMPUTE WORK\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\npython training.py\n</code></pre> <p>Depending on the software packages you use in the script, their dependency would be the CUDA and OpenACC modules. When you load the modules provided on Midway2 and Midway3 (e.g., <code>module load tensorflow</code>), the CUDA dependency modules will be automatically loaded (comparing the output of <code>module list</code> before and after doing <code>module load</code> command).</p> <p>If you build the codes using one of those CUDA modules, remember to load these modules in your script. </p> <p>An example batch script requests GPU resources, loads the CUDA libraries, and runs the MPI application: In this case, the application <code>your-app</code> supports hybrid MPI/GPU parallelization. </p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=test-gpu   # job name\n#SBATCH --output=%N.out       # output log file\n#SBATCH --error=%N.err        # error file\n#SBATCH --time=01:00:00       # 1 hour of wall time\n#SBATCH --nodes=1             # 1 node\n#SBATCH --ntasks-per-node=2   # 2 CPU cores to drive the GPUs\n#SBATCH --partition=gpu       # gpu partition\n#SBATCH --gres=gpu:1          # 1 GPU per node\n\n\n# Load all required modules below\nmodule load cuda/11.5\n\nulimit -l unlimited\n\n# Launch your run\nmpirun -np 2 ./your-app input.txt\n</code></pre>"},{"location":"slurm/sbatch/#job-arrays","title":"Job arrays","text":"<p>Slurm job arrays provide a convenient way to submit a large number of independent processing jobs. For example, Slurm job arrays can be useful for applying the same or similar computation to a collection of data sets. Or, you can launch independent calculations, each with a different set of input parameters, by submitting a single <code>.sbatch</code> script. When a job array script is submitted, a specified number of array tasks are created based on the \u201cmaster\u201d <code>.sbatch</code> script. </p> <p>Consider the following example (from <code>array.sbatch</code>):</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=array\n#SBATCH --output=array_%A_%a.out\n#SBATCH --error=array_%A_%a.err\n#SBATCH --array=1-16\n#SBATCH --time=01:00:00\n#SBATCH --partition=caslake\n#SBATCH --ntasks=1\n#SBATCH --mem=4G\n\n# Print the task id.\necho \"My SLURM_ARRAY_TASK_ID: \" $SLURM_ARRAY_TASK_ID\n\n# Add lines here to run your computation on each job\n./my_app -input $SLURM_ARRAY_TASK_ID\n</code></pre> <p>In this simple example, <code>--array=1-16</code> requests 16 array tasks (numbered 1 through 16). The \u201carray tasks\u201d are copies of the master script automatically submitted to the scheduler on your behalf. In each array task, the environment variable <code>SLURM_ARRAY_TASK_ID</code> is set to a unique value (in this example, numbers ranging from 1 to 16). The application should use the array index to handle the corresponding data.</p> <p>Job array indices can be specified in several different ways. Here are some examples:</p> <p><pre><code># A job array with array tasks numbered from 0 to 31.\n#SBATCH --array=0-31\n</code></pre> or <pre><code># A job array with array tasks numbered 1, 2, 5, 19, 27.\n#SBATCH --array=1,2,5,19,27\n</code></pre> or <pre><code># A job array with array tasks numbered 1, 3, 5, and 7.\n#SBATCH --array=1-7:2\n</code></pre></p> <p>In the example <code>.sbatch</code> script above, the <code>%A_%a</code> notation is filled in with the master job id (<code>%A</code>) and the array task id (<code>%a</code>). This is a simple way to create output files in which the file name differs for each job in the array.</p> <p>The remaining options in the <code>.sbatch</code> script are the same as the options used in other, non-array settings; in this example, we are requesting that each array task be allocated 1 CPU (<code>--ntasks=1</code>) and 4 GB of memory (<code>--mem=4G</code>) on the <code>broadwl</code> partition (<code>--partition=broadwl</code>) for up to one hour (<code>--time=01:00:00</code>).</p> <p>Most partitions have limits on the number of array tasks that can run simultaneously. Consider parallel batch jobs to achieve a higher throughput.</p> <p>For more information about Slurm job arrays, refer to the Slurm documentation on job arrays.</p>"},{"location":"slurm/sbatch/#parallel-processing-jobs","title":"Parallel processing jobs","text":""},{"location":"slurm/sbatch/#gnu-parallel","title":"GNU Parallel","text":"<p>Computations involving a very large number of independent computations should be combined in some way to reduce the number of jobs submitted to Slurm. We illustrate one strategy for doing this using GNU Parallel and srun. The parallel program executes tasks simultaneously until all tasks have been completed. </p> <p>Here\u2019s an example script, <code>parallel.sbatch</code>:</p> <pre><code>#!/bin/bash\n\n#SBATCH --time=01:00:00\n#SBATCH --partition=broadwl\n#SBATCH --ntasks=28\n#SBATCH --mem-per-cpu=2G  # NOTE DO NOT USE THE --mem= OPTION\n\n# Load the default version of GNU parallel.\nmodule load parallel\n\n# When running a large number of tasks simultaneously, it may be necessary to increase the user process limit.\nulimit -u 10000\n\n# This specifies the options used to run srun. The \"-N1 -n1\" options are used to allocate a single core to each task.\nsrun=\"srun --exclusive -N1 -n1\"\n\n# This specifies the options used to run GNU parallel:\n#   --delay of 0.2 prevents overloading the controlling node.\n#   -j is the number of tasks run simultaneously.\n#   The combination of --joblog and --resume create a task log that can be used to monitor progress.\n\nparallel=\"parallel --delay 0.2 -j $SLURM_NTASKS --joblog runtask.log --resume\"\n\n# Run a script, runtask.sh, using GNU parallel and srun. Parallel will run the runtask script for the numbers 1 through 128. To illustrate, the first job will run like this:\n\n# srun --exclusive -N1 -n1 ./runtask.sh arg1:1 &gt; runtask.1\n\n$parallel \"$srun ./runtask.sh arg1:{1} &gt; runtask.sh.{1}\" ::: {1..128}\n\n# Note that if your program does not take any input, use the -n0 option to call the parallel command:\n\n#   $parallel -n0 \"$srun ./run_noinput_task.sh &gt; output.{1}\" ::: {1..128}\n</code></pre> <p>In this example, we aim to run the script <code>runtask.sh</code> 128 times. The <code>--ntasks</code> option is set to 28, so at most, 28 tasks can be run simultaneously.</p> <p>Here is the <code>runtask.sh</code> script that is run by GNU Parallel:</p> <pre><code>#!/bin/bash\n\n# This script outputs some useful information so we can see what parallel\n# and srun are doing.\n\nsleepsecs=$[ ( $RANDOM % 10 ) + 10 ]s\n\n# $1 is arg1:{1} from GNU parallel.\n#\n# $PARALLEL_SEQ is a special variable from GNU parallel. It gives the\n# number of the job in the sequence.\n#\n# Here, we print the sleep time, hostname, and the date and time.\necho task $1 seq:$PARALLEL_SEQ sleep:$sleepsecs host:$(hostname) date:$(date)\n\n# Sleep a random amount of time.\nsleep $sleepsecs\n</code></pre> <p>To submit this job, copy <code>parallel.sbatch</code> and <code>runtask.sh</code> to the same directory, and run <code>chmod +x runtask.sh</code> to make <code>runtask.sh</code> executable. Then the job can be submitted to the Slurm queue:</p> <pre><code>sbatch parallel.sbatch\n</code></pre> <p>When this job is completed, you should see output files with <code>runtask.sh.N</code>, where <code>N</code> is between 1 and 128. The content of the first output file (i.e., <code>runtask.sh.1</code>) should look something like this:</p> <pre><code>task arg1:1 seq:1 sleep:14s host:midway2-0002 date:Thu Jan 10 09:17:36 CST 2017\n</code></pre> <p>Another file <code>runtask.log</code> is also created. It gives a list of the completed jobs. (Note: If the <code>.sbatch</code> is submitted again, nothing will be run until <code>runtask.log</code> is removed.)</p> <p>Using this same technique to run multithreaded tasks in parallel is also possible. Here is an example <code>.sbatch</code> script, <code>parallel-hybrid.sbatch</code>, that distributes multithreaded computations (each using 28 CPUs) across two nodes:</p> <pre><code>#!/bin/bash\n\n#SBATCH --partition=broadwl\n#SBATCH --time=01:00:00\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=28\n#SBATCH --exclusive\n\n# Load the default version of GNU parallel.\nmodule load parallel\n\nsrun=\"srun --exclusive -N1 -n1 --cpus-per-task $SLURM_CPUS_PER_TASK\"\n\n# Instead of $SLURM_NTASKS, use $SLURM_NNODES to determine how\n# many jobs should be run simultaneously.\nparallel=\"parallel --delay 0.2 -j $SLURM_NNODES --joblog runtask.log --resume\"\n\n# Run the parallel command.\n$parallel \"$srun ./runtask.sh arg1:{1} &gt; runtask.sh.{1}\" ::: {1..6}\n</code></pre>"},{"location":"slurm/sbatch/#launching-concurrent-processes","title":"Launching concurrent processes","text":"<p>Another option for setting up parallel runs is to launch background processes concurrently. This setup would be suitable for independent runs that use a single node exclusively. You can then submit multiple jobs, each on a separate node, if the total number of runs require more cores than on a single node.</p> <pre><code>#!/bin/bash\n\n#SBATCH --partition=broadwl\n#SBATCH --time=06:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=12\n#SBATCH --exclusive\n\nmodule load openmpi/4.1.1\nmpirun --cpu-set 0-7 --bind-to core -np 8 ./your-mpi-app1 &amp;\nmpirun --cpu-set 8-11 --bind-to core -np 4 ./your-mpi-app2 &amp;\nwait\n</code></pre> <p>Here, the first <code>mpirun</code> uses 8 CPU cores for eight tasks, and the second uses another 4 CPU cores to avoid oversubscription. The two \"&amp;\" mean to launch the <code>mpirun</code> commands to the background, and the <code>wait</code> command ensures all the processes are complete before terminating the job.</p> <p>A common use case is to launch multiple Python instances with the same script, each processing a set of input parameters:</p> <pre><code>#!/bin/bash\n\n#SBATCH --partition=caslake\n#SBATCH --time=06:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=32\n#SBATCH --exclusive\n#SBATCH --mem=0\n\nmodule load python\n\nfor idx in {0..31}\ndo\n   taskset -c $idx python script.py input-$idx.txt &gt; output-$idx.txt &amp;\ndone\nwait\n</code></pre> <p>Breakdown:</p> <ol> <li> <p><code>for idx in {0..31} do ... done</code>: This loop iterates 32 times, with idx taking values from 0 to 31.</p> </li> <li> <p><code>taskset -c $idx</code>: This command binds the execution of the following command (<code>python script.py ...</code>) to a specific CPU core, where <code>$idx</code> specifies the core number.</p> </li> <li> <p><code>python script.py input-$idx.txt &gt; output-$idx.txt &amp;</code>: This runs the Python script with a specific input file (<code>input-$idx.txt</code>) and writes the output to a corresponding output file (<code>output-$idx.txt</code>). The <code>&amp;</code> at the end puts each command in the background, allowing them to run in parallel.</p> </li> <li> <p><code>wait</code>: This command makes the script wait until all background processes have finished before it exits</p> </li> </ol> <p>Summary:</p> <p>The job script parallelizes the execution of script.py across 32 CPU cores, each processing a different input file and saving the results in corresponding output files.</p>"},{"location":"slurm/sbatch/#dependency-jobs","title":"Dependency jobs","text":"<p>You can schedule jobs depending on the termination status of previously scheduled jobs. This way, you can concatenate your jobs into a pipeline or expand to more complicated dependencies.</p> <p>For example, <code>job1.sbatch</code> is a submission script you plan to submit a batch job:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=hellompi\n#SBATCH --output=hellompi.out\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=16\n#SBATCH --partition=broadwl\n\n# Load the MPI module that was used to build the application\nmodule load openmpi\n\nulimit -l unlimited\n\nmpirun -np 32 ./hellompi\n</code></pre> <p>Submit the job script to the Slurm job scheduler from a Midway login node:</p> <pre><code>sbatch job1.sbatch\n</code></pre> <p>which returns the job ID, for example, <code>1234567</code>.</p> <p>You can then submit another job that is put on the waiting list of the queue (pending)</p> <pre><code>sbatch -dependency=afterany:1234567 job2.sbatch\n</code></pre> <p>This command indicates that <code>job2.sbatch</code> will be put in the queue after the job ID <code>1234567</code> is terminated for any reason. The dependency option flag can be <code>after</code>, <code>afterany</code>, <code>afterok</code> and <code>afternotok</code>, which are self-explanatory.</p> <p>For more information on job dependencies, please refer to the Slurm documentation.</p>"},{"location":"slurm/sbatch/#cron-like-jobs-limited-support-on-midway2","title":"Cron-like jobs - Limited support on Midway2","text":"<p>Cron-like jobs are Slurm jobs submitted to the queue with a specified schedule. These jobs persist until they are canceled or encounter an error. The Midway2 cluster has a dedicated partition, <code>cron</code>, for running cron-like jobs. Please contact our Help Desk to request submitting cron-like jobs. These jobs are subject to scheduling limits and resource requested, and will be monitored. We strongly recommend using <code>dependency jobs</code> which offer more flexibility and better resource management than using cron-like jobs.</p> <p>Here is an example of a batch script that internally submits a cron-like job (<code>cron.sbatch</code>):</p> <pre><code>#!/bin/bash\n\n#SBATCH --time=00:05:00\n#SBATCH --output=cron.log\n#SBATCH --open-mode=append\n#SBATCH --account=cron-account\n#SBATCH --partition=cron\n#SBATCH --qos=cron\n\n# Specify a valid Cron string for the schedule. This specifies that\n# The Cron job runs once per day at 5:15a.\nSCHEDULE='15 5 * * *'\n\n# Here is an example of a simple command that prints the hostname and\n# the date and time.\necho \"Hello on $(hostname) at $(date).\"\n\n# This schedules the next run.\nsbatch --quiet --begin=$(next-cron-time \"$SCHEDULE\") cron.sbatch\n</code></pre> <p>After executing a simple command (print the hostname, date, and time), the script schedules the next run with another call to <code>sbatch</code> with the <code>--begin</code> option.</p>"},{"location":"slurm/sinteractive/","title":"Interactive jobs","text":"<p>Interactive jobs are the most intuitive way to use RCC clusters, as they allow you to interact with the program running on compute node/s (e.g., execute cells in a Jupyter Notebook) in real-time. This is great for exploratory work or troubleshooting. An interactive job will persist until you disconnect from the compute node or until you reach the maximum requested time.  </p> <p>To request an interactive job with default parameters, run the following command while connected to a login node:  </p> Midway2Midway3 <pre><code>sinteractive\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI CNETID&gt;\n</code></pre> <p>Note</p> <p>On Midway3, you always need to specify the account to be charged for the job explicitly. Slurm will use the default partition (Midway2: <code>broadwl</code>, Midway3: <code>caslake</code>) if you do not specify it.</p> <p>Note</p> <p>On Midway3, to use the partitions with AMD CPUs, it is recommended that you log in to the <code>midway3-amd.rcc.uchicago.edu</code> login node and submit jobs from this login node. </p> <p>As soon as the requested resources become available, <code>sinteractive</code> will do the following: </p> <ol> <li>Log in to the compute node/s in the requested partition.  </li> <li>Change into the directory you were working in.  </li> <li>Set up X11 forwarding for displaying graphics.  </li> <li>Transfer your shell environment, including any previously loaded modules.  </li> </ol> <p>Note</p> <p>By default, an interactive session times out after 2 hours. If you would like more than 2 hours, include a <code>--time=HH:MM:SS</code> flag to specify the necessary amount of time. </p> <p>For example, to request an interactive session for 6 hours, run the following command:</p> Midway2Midway3 <pre><code>sinteractive --time=06:00:00\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI's CNETID&gt; --time=06:00:00\n</code></pre> <p>There are many additional options for the sinteractive command, including options to select the number of nodes, the number of cores per node, the amount of memory, and so on. For example, to request exclusive use of two compute nodes on the default CPU partition for 8 hours, enter the following:</p> Midway2Midway3 <pre><code>sinteractive --exclusive --partition=broadwl --nodes=2 --time=08:00:00\n</code></pre> <pre><code>sinteractive --account=pi-&lt;PI's CNETID&gt; --exclusive --partition=caslake --nodes=2 --time=08:00:00\n</code></pre> <p>For more details about these and other useful parameters, check Slurm <code>sbatch</code> page.</p> <p>Tip</p> <p>All options in the <code>sbatch</code> command are also available for the <code>sinteractive</code> command. </p>"},{"location":"slurm/sinteractive/#debug-qos","title":"Debug QoS","text":"<p>There is a debug QOS (Quality of Service) setup to help users quickly access some resources to debug or test their code before submitting their jobs to the main partition. The debug QoS will allow you to run one job and get up to four cores for 15 minutes without consuming SUs. To use the debug QoS, specify <code>--time</code> as 15 minutes or less. For example, to get two cores for 15 minutes, you could run:</p> <p><pre><code>sinteractive --qos=debug --time=00:15:00 --ntasks=2 --account=pi-&lt;PI CNETID&gt;\n</code></pre> You can find out the available <code>qos</code> for your account with the command <code>rcchelp</code></p> <pre><code>rcchelp qos\n</code></pre> <p>Additionally, it is important to use the <code>--mem</code> or <code>--mem-per-cpu</code> options. For example, to request 8 CPU cores and 128 GB of memory on a bigmem2 node, add the following to your <code>.sbatch</code> script:</p> <pre><code>#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=128G\n</code></pre> <p>These same options can also be used to set up a sinteractive session. For example, on Midway3 to access a <code>bigmem</code> node with 1 CPU and 128 GB of memory, run: </p> <pre><code>sinteractive --partition=bigmem --ntasks=1 --cpus-per-task=8 --mem=128G --account=pi-&lt;PI CNETID&gt;\n</code></pre>"},{"location":"software/","title":"Software packages and compilers","text":"<p>The best way to view the latest software packages offered on RCC clusters is to check the list of available software modules with the <code>module avail</code> command.</p> <p>All users can install software packages privately in their home and project directories. It is recommended to use compute nodes rather than login nodes when compilation and installation processes are time-consuming and require significant resources. Please check our documentation on how to start and use a <code>sinteractive</code> session here. </p>"},{"location":"software/#loading-and-using-available-software-modules","title":"Loading and using available software modules","text":"<p>RCC uses Environment Modules for managing software. The modules system permits us to set up the shell environment to make running and compiling software easier. It also allows us to make available many software packages and libraries that would otherwise conflict with one another. </p> <p>When you first log into RCC clusters, you will be entered into a basic user environment with minimal software available.  The <code>module</code> system is a script-based system used to manage the user environment and to <code>activate</code> software packages.  You must first load the corresponding software module to access software packages installed on RCC clusters. </p> <p>Basic <code>module</code> commands:</p> Command Description <code>module avail</code> lists all available software modules <code>module avail [name]</code> lists modules matching [name] <code>module load [name]</code> loads the named module <code>module unload [name]</code> unloads the named module <code>module list</code> lists the modules currently loaded for the user <p>Module dependencies</p> <p>Note that some modules require other specific modules, i.e., dependencies, to be loaded (or unloaded). If there is a conflict, you must explicitly unload the conflicting module (<code>module unload ...</code>), then load the desired module again. In certain cases, usually with loading an out-of-date module, you may get an error such as <code>Error: Requirement...</code> if a dependency is absent. In those situations, you can try <code>module load -f &lt;module&gt;</code> to force the module to load.</p> <p>Note on software for AMD CPUs</p> <p>For the <code>amd</code> partitions on Midway3, you need the software modules built specifically for AMD CPUs.</p> <pre><code>module use /software/modulefiles-amd\nmodule list\n</code></pre>"},{"location":"software/#requesting-a-software-package-installation","title":"Requesting a software package installation","text":"<p>If you need software not currently available in the module system and believe that multiple research groups can benefit from installing this software, send a detailed request to our Help Desk providing:</p> <ol> <li>Complete the name of the software package </li> <li>Exact version number </li> <li>Link to the package website </li> <li>Explain in a paragraph how this software is crucial for your research and having it on RCC clusters. </li> </ol>"},{"location":"software/#commonly-used-software-packages","title":"Commonly used software packages","text":"<p>This guide contains instructions for some commonly used applications and environments, including: </p> <ul> <li>Alphafold</li> <li>CryoSPARC</li> <li>Gaussian</li> <li>GROMACS </li> <li>LAMMPS</li> <li>MATLAB </li> <li>Mathematica</li> <li>NAMD</li> <li>NWChem</li> <li>OpenMM</li> <li>OpenPose</li> <li>ORCA</li> <li>Perl </li> <li>Python, Anaconda, Jupyter Notebook &amp; JupyterLab</li> <li>R and RStudio</li> <li>Singularity</li> <li>Spark</li> <li>Stata </li> <li>Tensorflow and PyTorch</li> <li>VS Code (SCode)</li> </ul>"},{"location":"software/cmake/","title":"CMake","text":"<p>CMake is a widely used tool for configuring the build of a software package. It is recommended to load the latest version of <code>cmake</code> before configuring your build.</p> <pre><code>   module load cmake/3.19\n</code></pre>"},{"location":"software/compilers/","title":"Compilers","text":"<p>In addition to having access to the provided software modules, you can always compile and use your codes or other open-source codes on Midway. You can check out the source files from GitHub (via <code>git clone</code>) or copy from your local machine to your own space on Midway (e.g. under <code>/home</code> or <code>/project</code>).</p> <p>Depending on the requirements of the codes, you can load the compilers and libraries that are provided as modules.</p> <p>GNU GCC, Intel and AMD compilers are provided through modules on Midway2 and Midway3. The table below lists details about each of the module-provided compilers.</p> Midway2Midway3 Vendor Module Language Compiler GNU <code>gcc</code> C C++Fortran <code>gcc</code><code>g++</code><code>gfortran</code> Intel <code>intel</code>, <code>oneapi</code> C C++Fortran <code>icc</code>, <code>icx</code><code>icpc</code>, <code>icpx</code>, <code>dpcpp</code><code>ifort</code>, <code>ifx</code> Vendor Module Language Compiler GNU <code>gcc</code> C C++Fortran <code>gcc</code><code>g++</code><code>gfortran</code> Intel <code>intel</code>, <code>oneapi</code> C C++Fortran <code>icc</code>, <code>icx</code><code>icpc</code>, <code>icpx</code>, <code>dpcpp</code><code>ifort</code>, <code>ifx</code> AMD <code>aocc</code> C C++ <code>clang</code><code>clang++</code> NVIDIA <code>nvhpc</code> C C++Fortran <code>nvc</code><code>nvc++</code><code>nvfortran</code> <p>Note</p> <p>AMD compilers are available on the Midway3 AMD cluster and with <code>module use /software/modulefiles-amd</code>.</p> <p>Each module may have different versions. The default version is always loaded if you do not specify explicitly with <code>module load</code>. You should check with <code>module avail</code> to see what versions are available. For example, on Midway3 <code>module avail gcc</code> will return</p> <p><pre><code>---------------------------- /software/modulefiles -----------------------------\ngcc/7.4.0  gcc/10.2.0(default) gcc/12.2.0 gcc/13.2.0\n</code></pre> and <code>module avail oneapi</code> <pre><code>---------------------------- /software/modulefiles -----------------------------\noneapi/2023.1 oneapi/2024.1 oneapi/2024.2\n</code></pre> You can check the changes to the environment variables made by a particular module by the <code>module show</code> command.</p>"},{"location":"software/compilers/#multithreading-with-openmp","title":"Multithreading with OpenMP","text":"<p>To compile your code or software packages that support multithreading with OpenMP, you just need to add to the compiling flags <code>-fopenmp</code> for GNU GCC and AMD compilers and <code>-qopenmp</code> for Intel compilers.</p>"},{"location":"software/compilers/#message-passing-interface-mpi","title":"Message-passing interface (MPI)","text":"<p>To compile your code or software packages with MPI, you need to load the MPI modules that are available. The list of libraries and software suites that provide MPI libraries is given as below.</p> Midway2Midway3 Implementation Module Language Wrapper OpenMPI <code>openmpi</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> MPICH <code>mpich</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> Intel <code>intelmpi</code><code>oneaapi</code> C C++Fortran <code>mpiicc</code><code>mpiicpc</code><code>mpiifort</code> NVIDIA <code>nvhpc</code> C C++Fortran <code>nvc</code><code>nvc++</code><code>nvfortran</code> Implementation Module Language Wrapper OpenMPI <code>openmpi</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> MPICH <code>mpich</code> C C++Fortran <code>mpicc</code><code>mpicxx</code><code>mpif90</code> Intel <code>intelmpi</code><code>oneaapi</code> C C++Fortran <code>mpiicc</code><code>mpiicpc</code><code>mpiifort</code> NVIDIA <code>nvhpc</code> C C++Fortran <code>nvc</code><code>nvc++</code><code>nvfortran</code> <p>Note</p> <p>For AMD C/C++ compilers <code>clang</code> and <code>clang++</code> (available with <code>module load aocc</code>), you need to load a MPI module (e.g. <code>openmpi</code> or <code>intelmpi</code>) to compile MPI codes.</p> <p>Note</p> <p>Experienced users can build the MPI libraries of their preferences in their own space using the provided compilers above.</p>"},{"location":"software/compilers/#gpu-codes","title":"GPU codes","text":"<p>To compile GPU codes, you can use NVIDIA CUDA Toolkit and HPC SDK (with OpenACC), Intel OneAPI (with SYCL), and GNU GCC 4.0+ (with GPU offloading). </p>"},{"location":"software/compilers/#nvidia-toolsets","title":"NVIDIA toolsets","text":""},{"location":"software/compilers/#cuda-toolkit","title":"CUDA Toolkit","text":"<p>There are several NVIDIA CUDA toolkit versions on Midway2 and Midway3. You can check the version provided with <code>module avail cuda</code>. On Midway3 there are several CUDA versions:</p> <p><pre><code>--------------------------- /software/modulefiles -----------------------------\ncuda/10.2  cuda/11.2  cuda/11.3  cuda/11.5 cuda/11.7 cuda/12.0 cuda/12.2\n</code></pre> The current version of the GPU driver on the GPU nodes supports all the above CUDA toolkit versions. You can check the GPU driver version via the <code>nvidia-smi</code> command after loading a <code>cuda</code> module.</p> <p>Note</p> <p>Although you can compile your CUDA code on the login node with the CUDA toolkit module loaded,  running the generated binary on the login node will fail because there is no GPU on the login node.</p>"},{"location":"software/compilers/#nvidia-hpc-sdk","title":"NVIDIA HPC SDK","text":"<p>NVIDIA HPC SDK provides another toolset for compiling GPU-enabled C/C++/Fortran codes via OpenACC. NVIDIA HPC SDK also provides a set of GPU-optimized tools and math libraries. These compilers are available through the <code>nvhpc</code> module. <pre><code>module load nvhpc\n</code></pre> and check for the location of the compilers <pre><code>which nvc++\nwhich nvfortran\n</code></pre></p>"},{"location":"software/compilers/#intel-oneapi","title":"Intel oneAPI","text":"<p>The DPC++ Compiler compiles C++ and SYCL* source files with code for both CPU and a wide range of compute accelerators such as GPU and FPGA. You can load the <code>oneapi</code> module on Midway2 to get access to this compiler: <pre><code>module load oneapi\n</code></pre> and remember to source the shell script to setup the necessary environment variables: <pre><code>source /software/oneapi-2021.beta7-el7-x86_64/inteloneapi/setvars.sh\n</code></pre> and check for the location of the compilers <pre><code>which dpcpp\n</code></pre></p>"},{"location":"software/compilers/#go","title":"Go","text":"<p>Go is an open-source compiled programming language that gain an rapidly increasing interest and usage by the industry.  Although Go is not a traditional compiler, we include it here for convenience. You can load Go as a module on Midway3.</p>"},{"location":"software/compilers/#java","title":"Java","text":"<p>Java is available as modules on Midway2 and Midway3. You can check the available modules via <code>module avail java</code>.</p>"},{"location":"software/dev-tools/","title":"Developer Tools","text":""},{"location":"software/dev-tools/#debuggers","title":"Debuggers","text":"<p>On Midway3 GDB and Valgrind as modules for debugging and memory leak checking with your code.</p> <p>To debug your code with <code>gdb</code>, you compile your code with <code>-g</code> and then run <code>gdb</code>: <pre><code>g++ -g -o test test.cpp\nmodule load gdb\ngdb --args ./test param1 param2\n</code></pre> You can also use <code>gdb</code> to debug your Python codes. Alternatively, use <code>pbd</code>.</p> <p><pre><code>python3 -m pdb myscript.py\n</code></pre> To check if there is any memory leak with your code, use <code>valgrind</code> <pre><code>g++ -g -o test test.cpp\nmodule load valgrind\nvalgrind --leak-check=full --track-origins=yes ./test param1 param2\n</code></pre> Please refer to the official documentation of GDB and Valgrind for more information.</p> <p>For CUDA codes, after loading the CUDA toolkit module (e.g. <code>module load cuda/12.2</code>) you can use <code>cuda-gdb</code> and <code>cuda-sanitizer</code>.</p>"},{"location":"software/dev-tools/#profilers","title":"Profilers","text":"<p>On Midway3 there are currently 3 profiling tools: TAU, NVIDIA Nsight and Intel VTune.</p> <p>TAU is a tool for profiling and tracing toolkit for performance analysis of parallel programs written in Fortran, C, C++, UPC, Java, Python. You can load <code>tau/2.31</code> on Midway3.</p> <p>The TAU binaries and scripts in the subfolders <code>$TAU_HOME/bin</code>, and several <code>Makefile.*</code> in <code>$TAU_HOME/lib</code> . To use TAU, you need to rebuild your code using one of the scripts inside <code>$TAU_HOME/bin</code>: C codes use <code>tau_cc.sh</code>; C++ codes use <code>tau_cxx.sh</code> (see for example, the doc page at OLCF). Should a new <code>Makefile.foo</code> be needed, then the <code>CC</code> and <code>CXX</code> environment variables need to be exported: </p> <p><pre><code>export CC=tau_cc.sh CXX=tau_cxx.sh F90=tau_f90.sh\n</code></pre> before the first <code>cmake</code> run, or before running <code>make</code>.</p> <p>Run the generated binaries as usual (e.g. <code>mpirun -np 4 ./binary args</code>) the output will now include the files <code>profile.*</code> in the working directory. At this point, run <code>paraprof</code> to launch the GUI analysis (need <code>module load java</code>), or <code>pprof</code> for command-line output.</p> <p>Different options for compile time are available (e.g. <code>-optVerbose</code>), options for run time (e.g. <code>TAU_TRACK_MEMORY_LEAKS=1</code>)</p> <p>NVIDIA Nsight is a system-wide performance analysis tool designed to visualize an application\u2019s algorithms, identify the largest opportunities to optimize, and tune to scale efficiently across any quantity or size of CPUs and GPUs.</p> <p>To use NVIDIA Nsight System and Nsight Compute, load one of the available <code>cuda</code> modules. <pre><code>module load cuda/12.2\n</code></pre> To launch the corresponding GUI applications, use <pre><code>nsys-ui\n</code></pre> and <pre><code>ncu-ui\n</code></pre> You can also use the command-line interface <code>nsys</code> and <code>ncu</code>. Please refer to the NVIDIA Nsight documentation for further details.</p> <p>Intel VTune is part of the oneAPI(C) software suite for optimizing application performance, system performance, and system configuration for HPC. To use the profilers, <code>vtune</code> and the GUI <code>vtune-gui</code>, in a ThinLinc session, you load the <code>oneapi</code> module <pre><code>module load oneapi/2024.2\nvtune-gui\n</code></pre></p>"},{"location":"software/faq/","title":"Software FAQ","text":""},{"location":"software/faq/#what-software-does-rcc-offer-on-its-compute-systems","title":"What software does RCC offer on its compute systems?","text":"<p>Software available within RCC is constantly evolving. We regularly install new software, and new versions of existing software. Information about available software and how to use specific software packages can be found in the Software section of the User Guide.</p> <p>To view the current list of installed software on RCC clusters, run the following command: </p> <pre><code>module avail\n</code></pre> <p>To view the list of available versions for a specific software, run the following command: </p> <pre><code>module avail &lt;software&gt;\n</code></pre>"},{"location":"software/faq/#how-do-i-get-help-with-rcc-software","title":"How do I get help with RCC software?","text":"<p>Documentation for many programs can be viewed with the following command.</p> <pre><code>man &lt;command&gt;\n</code></pre> <p>Many programs also provide documentation through command-line options such as <code>--help</code> or <code>-h</code>. For example,</p> <pre><code>module load gcc\n</code></pre> <pre><code>gcc --help\n</code></pre> <p>RCC also maintains supplementary documentation for software specific to our systems. Consult the Software page for more information.</p>"},{"location":"software/faq/#why-is-my-favorite-command-not-available","title":"Why is my favorite command not available?","text":"<p>Most likely it is because you have not loaded the appropriate software module. Most software packages are only available after first loading the appropriate software module. See Software for more information on how to access pre-installed software on RCC systems.</p>"},{"location":"software/faq/#why-do-i-get-an-error-that-says-a-module-cannot-be-loaded-due-to-a-conflict","title":"Why do I get an error that says a module cannot be loaded due to a conflict?","text":"<p>Occasionally, modules are incompatible with each other and cannot be loaded simultaneously. The module command typically gives you hints about which previously loaded module conflicts with the one you are trying to load. If you see such an error, try unloading a module with this command:</p> <pre><code>module unload &lt;module-name&gt;\n</code></pre>"},{"location":"software/faq/#how-do-i-request-installation-of-a-new-or-updated-software-package","title":"How do I request installation of a new or updated software package?","text":"<p>Please contact our Help Desk with the details of your software request, including the following informaiton: </p>"},{"location":"software/faq/#how-can-i-use-gaussian-on-the-rcc-machines","title":"How can I use Gaussian on the RCC machines?","text":"<p>Gaussian is a commercial software. If you need to use Gaussian for your research, please fill out this from and for the <code>Principal Investigator account name (probably pi-CNetID):</code> type in <code>gaussian</code>. Our team will process you request in a few hours. </p>"},{"location":"software/faq/#how-can-i-run-comsol-on-the-rcc-machines","title":"How can I run COMSOL on the RCC machines?","text":"<p>COMSOL is a commercial software. To use COMSOL for your research, please fill out this from and for the <code>Principal Investigator account name (probably pi-CNetID):</code> type in <code>comsol</code>. Our team will process you request in a few hours.</p>"},{"location":"software/libraries/","title":"Libraries","text":"<p>There are several commonly used libraries that are available as modules on Midway2 and Midway3. After loading the module into your environment, you can find several environment variables and paths are added: <pre><code>module show [module-name]\n</code></pre> These added paths can be used in your Makefile or in the build configuration with cmake.</p>"},{"location":"software/libraries/#gsl","title":"GSL","text":"<p>The GNU Scientific Library GSL is a numerical library for C and C++ programmers.</p> <p><pre><code>module load gsl\n</code></pre> which sets up the paths and environment variables for the libraries.</p>"},{"location":"software/libraries/#fftw3","title":"FFTW3","text":"<p>FFTW3 can be loaded via <pre><code>module load fftw3\n</code></pre> which sets up the paths and environment variables for the libraries.</p>"},{"location":"software/libraries/#intel-oneapi-mkl","title":"Intel oneAPI MKL","text":"<p>Intel oneAPI MKL can be loaded via <pre><code>module load mkl\n</code></pre> which sets up the paths and environment variables for the libraries. The MKL libraries support core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math.</p>"},{"location":"software/libraries/#nvidia-hpc-sdk","title":"NVIDIA HPC SDK","text":"<p>NVIDIA HPC SDK provides another toolset for compiling GPU-enabled C/C++/Fortran codes via OpenACC. NVIDIA HPC SDK also provides a set of GPU-optimized tools and math libraries. These compilers are available through the <code>nvhpc</code> module.</p>"},{"location":"software/apps-and-envs/%20spaceranger/","title":"Space Ranger","text":"<p>Spaceranger is a set of analysis pipelines that process Visium Spatial Gene Expression data with brightfield and fluorescence microscope images. Spaceranger Manual</p>"},{"location":"software/apps-and-envs/%20spaceranger/#installation","title":"Installation","text":"<p>The spaceranger comes as a binary that doesnot require compiling. Use Firefox in Thinlic to download the software. You may create a folder called 'software' in your home or project directory and extract it to that location. Change pi-cnetid with the the group name. if using for personal purpose, you can use scratch storage available at <code>$SCRATCH/$USER</code> folder. Change the extraction location to <code>/project/pi-cnetid/software</code>, or somewhere else and use the following command:</p> <pre><code>tar -xzvf spaceranger-3.0.0.tar.gz --directory /project/pi-cnetid/software\n</code></pre>"},{"location":"software/apps-and-envs/%20spaceranger/#updating-path","title":"Updating PATH","text":"<p>After extracting the software, update the PATH as follows:</p> <p>Update PATH:</p> <pre><code>export PATH=/project/pi-cnetid/software/spaceranger-3.0.0:$PATH\n</code></pre> <p>Save in .bashrc: Command above will change the $PATH temperorly only for that bash shell. You can permanently update the PATH by appending the following command to the .bashrc file:</p> <pre><code>echo 'export PATH=/project/pi-cnetid/software/spaceranger-3.0.0:$PATH' &gt;&gt; ~/.bashrc\n</code></pre> <p>These commands will ensure that <code>spaceranger-3.0.0</code> is extracted to the specified location and added to the PATH for permanent access. Follow instructions here to proceed: https://www.10xgenomics.com/support/software/space-ranger/downloads/space-ranger-installation</p> <p>Running as a container: Docker images are available at Docker hub: https://hub.docker.com/r/cumulusprod/spaceranger/tags Follow the instructions at the singularity page on running containers.</p> <p>[Tutorials] (https://www.10xgenomics.com/support/software/space-ranger/latest/tutorials) Job Submission Mode Space Ranger Cluster Mode</p>"},{"location":"software/apps-and-envs/alphafold/","title":"AlphaFold Documentation","text":"<p>AlphaFold is an artificial intelligence program developed by Google DeepMind, a subsidiary of Alphabet, which predicts protein structures with high accuracy. This documentation provides instructions for running AlphaFold2 and AlphaFold3 on the Midway3 HPC system.</p>"},{"location":"software/apps-and-envs/alphafold/#available-modules","title":"Available Modules","text":""},{"location":"software/apps-and-envs/alphafold/#alphafold-2","title":"AlphaFold 2","text":"<p>AlphaFold 2 is available as modules on Midway3. You can check the available versions using the following command: <pre><code>module avail alphafold\n</code></pre> Output: <pre><code>---------------------- /software/modulefiles----------------------------------\nalphafold/2.0.0(default)  alphafold/2.2.0  alphafold/2.3.2\n</code></pre></p> <p>The AlphaFold source code and running scripts (e.g., <code>run_alphafold.py</code>) can be found on the AlphaFold GitHub repository.</p> <p>The training datasets for different versions of AlphaFold are accessible under: - <code>/software/alphafold-data/</code> - <code>/software/alphafold-data-2.2/</code> - <code>/software/alphafold-data-2.3/</code></p>"},{"location":"software/apps-and-envs/alphafold/#alphafold-3","title":"AlphaFold 3","text":"<p>AlphaFold 3 on Midway3 uses a container-based approach with Singularity (or Apptainer) and requires different input arguments compared to AlphaFold 2. It supports advanced features like FlashAttention and improved accuracy for protein-ligand and protein-DNA interactions. See the example job script below for usage details.</p>"},{"location":"software/apps-and-envs/alphafold/#key-differences-between-alphafold-2-and-alphafold-3","title":"Key Differences Between AlphaFold 2 and AlphaFold 3","text":"Feature AlphaFold 2 AlphaFold 3 Input Format <code>.fasta</code> file <code>.json</code> file Execution Environment Python-based scripts Singularity container GPU Requirements Moderate GPU memory (e.g., V100) High GPU memory (e.g., 2 A100 GPUs) FlashAttention Support Not available Supported (<code>triton</code> or <code>xla</code>)"},{"location":"software/apps-and-envs/alphafold/#system-requirements","title":"System Requirements","text":""},{"location":"software/apps-and-envs/alphafold/#alphafold-2_1","title":"AlphaFold 2","text":"<ul> <li>GPU: V100 or higher (NVIDIA GPU with compute capability \u22658.0 recommended)</li> <li>CUDA: Version 11.3 or higher</li> <li>Memory: 32GB RAM minimum (64GB recommended for large proteins or multiple jobs)</li> </ul>"},{"location":"software/apps-and-envs/alphafold/#alphafold-3_1","title":"AlphaFold 3","text":"<ul> <li>GPU: A100 or higher recommended (80GB GPU RAM may be needed for very large inputs)</li> <li>CUDA: Version 12.3 or higher (CUDA 12.6 preferred for best accuracy; 12.2 may work, but not guaranteed)</li> <li>Memory: 32GB RAM minimum (more is better for large jobs and databases)</li> </ul> Why Container-Based Approach for AlphaFold 3? <p>AlphaFold 3 requires CUDA 12.3 or higher, but the system NVIDIA driver version is 12.2. By using a container, we bypassed the driver compatibility issue.</p> <p>This guidebook will be updated with a module-based usage method for AlphaFold 3 in the future, as the system CUDA version is updated.</p>"},{"location":"software/apps-and-envs/alphafold/#example-job-scripts","title":"Example Job Scripts","text":""},{"location":"software/apps-and-envs/alphafold/#alphafold-2-job-script","title":"AlphaFold 2 Job Script","text":"<p>The following example demonstrates how to run AlphaFold 2 on a GPU node with 2 GPUs and up to 16 CPU cores for multithreading on Midway3.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=alphafold2\n#SBATCH --account=[your-accountname]\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --time=04:00:00\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=16\n#SBATCH --gres=gpu:2\n#SBATCH --constraint=v100\n#SBATCH --mem=64G\n\nmodule load alphafold/2.3.2 cuda/11.3\n\ncd $SLURM_SUBMIT_DIR\n\nDOWNLOAD_DATA_DIR=/software/alphafold-data-2.3\n\npython run_alphafold.py \\\n  --data_dir=$DOWNLOAD_DATA_DIR  \\\n  --uniref90_database_path=$DOWNLOAD_DATA_DIR/uniref90/uniref90.fasta  \\\n  --mgnify_database_path=$DOWNLOAD_DATA_DIR/mgnify/mgy_clusters_2022_05.fa  \\\n  --bfd_database_path=$DOWNLOAD_DATA_DIR/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt  \\\n  --uniref30_database_path=$DOWNLOAD_DATA_DIR/uniref30/UniRef30_2021_03 \\\n  --pdb70_database_path=$DOWNLOAD_DATA_DIR/pdb70/pdb70  \\\n  --template_mmcif_dir=$DOWNLOAD_DATA_DIR/pdb_mmcif/mmcif_files  \\\n  --obsolete_pdbs_path=$DOWNLOAD_DATA_DIR/pdb_mmcif/obsolete.dat \\\n  --model_preset=monomer \\\n  --max_template_date=2022-1-1 \\\n  --db_preset=full_dbs \\\n  --use_gpu_relax=true \\\n  --output_dir=out_alphafold_2.1.1_multi-monomer \\\n  --fasta_paths=T1083.fasta,T1084.fasta\n</code></pre>"},{"location":"software/apps-and-envs/alphafold/#alphafold-3-job-script","title":"AlphaFold 3 Job Script","text":"<p>The following example demonstrates how to run AlphaFold 3 using a <code>.json</code> input file (e.g., <code>nipah_zmr.json</code>) on a GPU node with 2 A100 GPUs.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=alphafold3\n#SBATCH --account=[your-accountname]\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --time=04:00:00\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=16\n#SBATCH --gres=gpu:2\n#SBATCH --constraint=a100\n#SBATCH --mem=32G\n\nmodule load apptainer\n\ncd $SLURM_SUBMIT_DIR\n\n# Set the path to the AlphaFold 3 database directory\nDOWNLOAD_DATA_DIR=/software/alphafold3.0-el8-x86_64/databases  # Path to AlphaFold 3 database directory\n\n# Define bind paths\nexport BIND_PATHS=\"$DOWNLOAD_DATA_DIR,/software/alphafold3.0-el8-x86_64/params,/software/alphafold3.0-el8-x86_64/singularity,/tmp/$USER,/home/$USER,/scratch/midway3/$USER\"\n\n# Run the Singularity container\nsingularity exec --nv \\\n    -B \"$BIND_PATHS\" \\\n    --env CUDA_VISIBLE_DEVICES=0,1,NVIDIA_VISIBLE_DEVICES=0,1 \\\n    /software/alphafold3.0-el8-x86_64/alphafold3.sif \\\n    python /app/alphafold/run_alphafold.py \\\n    --json_path=/home/$USER/nipah_zmr.json \\\n    --db_dir=$DOWNLOAD_DATA_DIR \\\n    --output_dir=/scratch/midway3/$USER/alphafold3_output \\\n    --model_dir=/software/alphafold3.0-el8-x86_64/params \\\n    --flash_attention_implementation=triton \\\n    --run_data_pipeline=True \\\n    --run_inference=True \\\n    --jackhmmer_n_cpu=8 \\\n    --nhmmer_n_cpu=8\n</code></pre>"},{"location":"software/apps-and-envs/alphafold/#input-file-preparation","title":"Input File Preparation","text":""},{"location":"software/apps-and-envs/alphafold/#alphafold-2_2","title":"AlphaFold 2","text":"<ul> <li>Input format: <code>.fasta</code> file containing the protein sequence(s).</li> <li>Example:   <pre><code>&gt;T1083\nSEQUENCE1\n&gt;T1084\nSEQUENCE2\n</code></pre></li> </ul>"},{"location":"software/apps-and-envs/alphafold/#alphafold-3_2","title":"AlphaFold 3","text":"<ul> <li>Input format: <code>.json</code> file containing the protein sequence(s) and metadata.</li> <li>Example:   Download the example file <code>nipah_zmr.json</code> from this link and place it in your home directory (<code>/home/$USER</code>).</li> </ul>"},{"location":"software/apps-and-envs/alphafold/#troubleshooting","title":"Troubleshooting","text":""},{"location":"software/apps-and-envs/alphafold/#common-errors-and-solutions","title":"Common Errors and Solutions","text":"<ol> <li> <p>Error: <code>Unknown backend: 'gpu' requested, but no platforms that are instances of gpu are present.</code></p> <ul> <li>Solution: Ensure the job is running on a GPU-enabled node and that the <code>CUDA_VISIBLE_DEVICES</code> environment variable is set correctly.</li> </ul> </li> <li> <p>Error: <code>Failed to get mmCIF for &lt;PDB_ID&gt;.</code></p> <ul> <li>Solution: Verify that the database directory is accessible and contains the required files. Ensure proper permissions:  <pre><code>chmod 755 --recursive /software/alphafold3.0-el8-x86_64/databases\n</code></pre></li> </ul> </li> <li> <p>Error: <code>implementation='triton' for FlashAttention is unsupported on this GPU generation.</code></p> <ul> <li>Solution: Switch to the <code>xla</code> implementation:  <pre><code>--flash_attention_implementation=xla\n</code></pre></li> </ul> </li> <li> <p>Error: <code>CUDA version mismatch.</code></p> <ul> <li>Solution: Ensure the NVIDIA driver and CUDA versions are compatible with AlphaFold3. Update the driver if necessary. For instance, if <code>nvidia-smi</code> on the node shows  <pre><code>NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     \n</code></pre>  it means that the GPU driver version is 535.161.08, which was installed along with the CUDA toolkit version 12.2. If a version of AlphaFold3 relies on the CUDA toolkit 12.X (where X &gt; 2), make sure that the GPU driver 535.161.08 is also compatible with this CUDA 12.x version.</li> </ul> </li> </ol>"},{"location":"software/apps-and-envs/alphafold/#additional-notes","title":"Additional Notes","text":"<ul> <li>Resource Allocation: Adjust the <code>--gres=gpu</code> and <code>--mem</code> parameters in the job script based on the size of the input data.</li> <li>Output Directory: Results will be saved in the directory specified by the <code>--output_dir</code> parameter.</li> </ul> <p>For more information, visit the AlphaFold GitHub repository or contact the RCC support team.</p>"},{"location":"software/apps-and-envs/cryosparc/","title":"CryoSPARC","text":"<p>CryoSPARC (Cryo-EM Single Particle Ab-Initio Reconstruction and Classification) is a state-of-the-art software platform for processing cryo-electron microscopy (cryo-EM) data. It functions as a dispatcher for cryo-EM workloads across a cluster of servers and workstations. RCC provides full support for CryoSPARC on the Beagle3 cluster.</p>"},{"location":"software/apps-and-envs/cryosparc/#installation-and-setup","title":"Installation and Setup","text":"<p>To use CryoSPARC on Beagle3, you must first obtain a license from CryoSPARC and provide the license ID to RCC through either:</p> <ol> <li>This support form</li> <li>Email: help@rcc.uchicago.edu</li> </ol> <p>After receiving your license information, RCC will configure your account and provide:</p> <ol> <li>Account credentials and setup details</li> <li>A dedicated base port (typically in the range <code>39100-39500</code>)</li> <li>A designated host machine name (<code>beagle3-login3</code> or <code>beagle3-login4</code>)</li> </ol>"},{"location":"software/apps-and-envs/cryosparc/#getting-started","title":"Getting Started","text":"<p>CryoSPARC's graphical user interface can be accessed through:</p> <ol> <li>Your local machine's web browser (recommended for better performance)</li> <li>Thinlinc </li> </ol>"},{"location":"software/apps-and-envs/cryosparc/#initial-setup","title":"Initial Setup","text":"<p>Log into your assigned host machine (provided by RCC during account setup)     <pre><code>ssh [your-cnetid]@beagle3-[login3 or login4].rcc.uchicago.edu\n</code></pre></p> <p>Check CryoSPARC status at any time using:     <pre><code>cryosparcm status\n</code></pre></p> CryoSPARC Status <p>Start CryoSPARC if it's not already running:     <pre><code>cryosparcm start\n</code></pre></p> CryoSPARC Start"},{"location":"software/apps-and-envs/cryosparc/#accessing-the-gui","title":"Accessing the GUI","text":"<p>Open a web browser (preferably on your local machine for optimal performance)  and navigate to your assigned host machine and port. The exact host machine name and port are also specified in the <code>config.sh</code> file located in the <code>master</code> folder of your installation directory.</p> <p>Example URL</p> <p><code>http://beagle3-login4.rcc.local:39100/</code></p> <p>Important</p> <p>Always use the specific host machine name provided by RCC to avoid service disruptions.</p> Local Browser Access (Recommended) - Better performance, faster response times. Thinlinc Browser Access - Useful when local network restrictions prevent direct access. Open Firefox within Thinlinc session"},{"location":"software/apps-and-envs/cryosparc/#troubleshooting","title":"Troubleshooting","text":"<p>For comprehensive troubleshooting guidance, refer to the official CryoSPARC troubleshooting documentation. The following sections provide solutions to common issues.</p>"},{"location":"software/apps-and-envs/cryosparc/#socket-connection-error","title":"Socket Connection Error","text":"<p>Error message: <code>unix:///tmp/cryosparc-supervisor\u20136410667835282660811.sock refused connection (already shut down?)</code></p> <p>Solution:</p> <ol> <li> <p>Stop CryoSPARC: <pre><code>cryosparcm stop\n</code></pre></p> </li> <li> <p>Remove socket files: Delete the specific <code>.sock</code> file mentioned in the error message:     <pre><code>rm /tmp/cryosparc-supervisor\u20136410667835282660811.sock\n</code></pre></p> </li> <li> <p>Kill zombie processes: Find and terminate any lingering processes:     <pre><code># Find process IDs\nps -ax | grep \"supervisor\" | grep $USER \nps -ax | grep \"cryosparc\" | grep $USER \nps -ax | grep \"mongod\" | grep $USER \n\n# Kill each identified process\nkill &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Restart CryoSPARC: <pre><code>cryosparcm start\n</code></pre></p> </li> </ol>"},{"location":"software/apps-and-envs/cryosparc/#database-error","title":"Database Error","text":"<p>Error message:</p> <p><code>E STORAGE  [initandlisten] WiredTiger error (-31802) [1598020046:709343][4402:0x7f8f81a8fd40], file:sizeStorer.wt, WT_SESSION.open_cursor: unable to read root page from file:sizeStorer.wt: WT_ERROR: non-specific WiredTiger error</code></p> <p><pre><code>Starting cryoSPARC System master process..\nCryoSPARC is not already running.\ndatabase: ERROR (spawn error)\n</code></pre> Solution:</p> <ol> <li> <p>Create database backup: <pre><code>cp -rav db db_backup\n</code></pre></p> </li> <li> <p>Stop CryoSPARC: <pre><code>cryosparcm stop\n</code></pre></p> </li> <li> <p>Remove corrupted database: <pre><code>rm -rf db\n</code></pre></p> </li> <li> <p>Kill zombie processes: <pre><code># Find process IDs\nps -ax | grep \"supervisor\" | grep $USER \nps -ax | grep \"cryosparc\" | grep $USER \nps -ax | grep \"mongod\" | grep $USER \n# Kill each identified process\nkill &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Initialize new database: <pre><code>cryosparcm start\n</code></pre></p> </li> <li> <p>Stop CryoSPARC temporarily: <pre><code>cryosparcm stop\n</code></pre></p> </li> <li> <p>Restore database backup: <pre><code>cp -rav db_backup db\n</code></pre></p> </li> <li> <p>Repair database: Navigate to the <code>db</code> directory and run:     <pre><code>eval $(cryosparcm env)\nmongod --dbpath ./ --repair\n</code></pre></p> </li> <li> <p>Start CryoSPARC:     <pre><code>cryosparcm start\n</code></pre></p> </li> </ol>"},{"location":"software/apps-and-envs/gaussian/","title":"Gaussian","text":"<p>Gaussian is a general-purpose computational chemistry software package with focus on electronic structure modeling. Gaussian is developed and licensed by Gaussian, Inc.</p>"},{"location":"software/apps-and-envs/gaussian/#getting-access","title":"Getting access","text":"<p>Step 1 If you are not already an RCC user, your first step is to become one. If you are a Principal Investigator (PI), submit a PI Account Request. If you are a student, postdoc, staff member, etc., submit a General User Account Request.</p> <p>Step 2 To access Gaussian, you must be a member of the RCC's <code>gaussian</code> Unix group. You can check if you are already a member of the <code>gaussian</code> group by running <code>groups</code> in the terminal while connected to a Midway cluster login node. To join the <code>gaussian</code> group, submit a General User Account Request with \"Gaussian\" as the Principal Investigator account name. (Note that even PIs submit a General User Account Request to get access to Gaussian. This is different from Step 1, where PIs submit a PI Account Request to become an RCC user.)</p> <p>Once you are a member of the <code>gaussian</code> group, you will be able to run Gaussian programs. To check what versions of Gaussian are currently available on the Midway clusters, use SSH to log into Midway2 or Midway3 and run this command in your terminal:</p> <pre><code>$ module avail gaussian\n</code></pre> <p>The versions of Gaussian on Midway2 and Midway3 may be different; please check both ecosystems if you need a specific version of Gaussian.</p> <p>You can run Gaussian jobs in an <code>sinteractive</code> session, meaning you connect live to a compute node, or by using an <code>sbatch</code> script to send your job to a compute node. (Gaussian jobs only run on compute nodes, not login nodes.) See below for examples of each of these workflows.</p>"},{"location":"software/apps-and-envs/gaussian/#example-gaussian-job-with-sinteractive","title":"Example Gaussian job with <code>sinteractive</code>","text":"<p>You can start an <code>sinteractive</code> session on Midway3 by running this command in your terminal. Don't forget to replace <code>pi-drpepper</code> with your account (typically your PI's CNetID).</p> <pre><code>$ sinteractive --partition=caslake --account=pi-drpepper --nodes=1 --ntasks-per-node=8 --mem-per-cpu=16000 --time=00:30:00\n</code></pre> <p>Next, load Gaussian by running this command in your terminal. Substitute <code>16RevA.03</code> with whichever version of Gaussian you would like to use. (Remember you can see available versions of Gaussian by running <code>module avail gaussian</code> in your terminal.)</p> <pre><code>$ module load gaussian/16RevA.03\n</code></pre> <p>Now you can run Gaussian with the <code>g#</code> command. Match <code>#</code> to whatever version of Gaussian you have loaded: <code>g16</code> for <code>16RevA.03</code>, <code>g09</code> for <code>gaussian09</code>, etc. For example, this code uses <code>16RevA.03</code> to run a file called <code>your-input.com</code> and write the results to <code>your-output.out</code>:</p> <pre><code>$ g16 &lt; your-input.com &gt; your-output.out\n</code></pre> <p>If you need to make more complex specifications, use an <code>sbatch</code> file (see below) to submit your job to the RCC's Slurm workload manager, which will run the job on a compute node for you.</p>"},{"location":"software/apps-and-envs/gaussian/#example-gaussian-job-with-sbatch","title":"Example Gaussian job with <code>sbatch</code>","text":"<p>Here is an example input file, <code>water.com</code>:</p> <pre><code>%mem=16GB\n%nprocshared=8\n# HF/6-31G(d)\n\nwater energy\n\n0   1\nO  -0.464   0.177   0.0\nH  -0.464   1.137   0.0\nH   0.441  -0.143   0.0\n</code></pre> <p>Here is an example <code>sbatch</code> file, <code>water.sbatch</code>, that runs <code>water.com</code>:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=example_sbatch_gaussian\n#SBATCH --partition=caslake\n#SBATCH --time=00:30:00\n#SBATCH --account=rcc-staff # replace this with your PI account \n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=16000 # in Megabytes\n#SBATCH --error=example.err \n\nmodule load gaussian/16RevA.03\n\ng16 &lt; water.com &gt; $SLURM_JOB_ID.out\n\ntouch $SLURM_JOB_ID.txt \necho \"Job ID: $SLURM_JOB_ID\" &gt;&gt; $SLURM_JOB_ID.txt \necho \"Job name: $SLURM_JOB_NAME\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N tasks: $SLURM_ARRAY_TASK_COUNT\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N cores: $SLURM_CPUS_ON_NODE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"N threads per core: $SLURM_THREADS_PER_CORE\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Minimum memory required per CPU: $SLURM_MEM_PER_CPU\" &gt;&gt; $SLURM_JOB_ID.txt\necho \"Requested memory per GPU: $SLURM_MEM_PER_GPU\" &gt;&gt; $SLURM_JOB_ID.txt\n</code></pre> <p>Gaussian can consume a lot of memory, so include these additional flags in your <code>sbatch</code> file if you are running a large job:</p> <pre><code>#SBATCH \u2013exclusive # The job allocation can not share nodes with other running jobs \n#SBATCH \u2013mem=0 # Use the maximum available memory on the node\n</code></pre> <p>You can submit this example job by running this command in your terminal:</p> <pre><code>sbatch water.sbatch\n</code></pre> <p>For calculations that involve multiple steps (such as geometry optimization, single-point calculation, frequency analysis), it is recommended to generate and update checkpoints during individual steps (via the <code>%Chk</code> command). The checkpoint of the preceding steps will be loaded for the following steps (via the <code>%OldChk</code> command). This way, if the job crashes or is terminated due to time limit, you can resubmit the job at the suitable step to continue the calculation. For more details and guidelines, please refer to the Gaussian documentation.</p>"},{"location":"software/apps-and-envs/gaussian/#input-and-output","title":"Input and output","text":"<p>GaussianView is a graphical interface used with Gaussian. It aids in the creation of Gaussian input files, enables the user to run Gaussian calculations from a graphical interface without the need for using a command line instruction, and helps in the interpretation of Gaussian output. Users can use it to plot properties, animate vibrations, or visualize computed spectra.</p> <p>You can use GaussianView on Midway2 with:</p> <pre><code>module load gaussian/09RevB.01\n</code></pre> <p>However, GaussianView is not currently available for any of the versions of Gaussian on Midway3.</p> <p>To use GaussianView, you will need to run and X server on your computer and enable X forwarding when you log into the cluster. See our X11 forwarding documentation for details. Otherwise, users need to open a ThinLinc session to open the GaussianView GUI.</p> <p>Other options to prepare the molecular structure used in the input files include software packages such as Avogadro, a molecule editor and visualizer. Avogadro is also available on Midway2.</p> <p>Alternatively, users can use MolView (a web-based application), or ChemCraft (a cross-platform application). After generating the molecular structure from these packages, users put the atom coordinates into  the Gaussian input file, or use another tool to assemble a proper input file.</p> <p>Gaussian output can be visualized using Avogradro, VMD or OVITO. Uses can check the installed versions of these software packages on Midway2 and Midway3 via the <code>module avail</code> command.</p>"},{"location":"software/apps-and-envs/gaussian/#gpu-support","title":"GPU support","text":"<p>On Midway3, the module <code>gaussian/16RevC.02</code> supports GPU acceleration with NVIDIA Tesla A100 GPUs. To run Gaussian with GPU support, please refer to the Gaussian documentation.</p> <p>An example of the job script to use GPU is given below.</p> <pre><code>#!/bin/bash\n#SBATCH --account=rcc-staff   # replace this with your PI account \n#SBATCH -t 02:00:00\n#SBATCH --nodes=1\n#SBATCH --partition=gpu\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=32GB            # replace this with the memory on the CPU side\n#SBATCH --gres=gpu:1\n#SBATCH --constraint=a100\n\nmodule load gaussian/16RevC.02\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nexport MP_BIND=yes\n\n# form the MP_BLIST variable from the allocated threads\n#export MP_BLIST=0,1,2,3,4,5,6,7\n\nlast=$(( OMP_NUM_THREADS-1 ))\nexport MP_BLIST=`seq -s , 0 $last`\necho $MP_BLIST\n\n# set the scratch space for gaussian temp data, which is by default the submitting dir\n# export GAUSS_SCRDIR=/scratch/midway3/$USER\n\n# launch the run\ng16 &lt; input.txt &gt; output.txt\n</code></pre> <p>This job script requests 1 node, 1 task per node, 8 CPU cores for multithreading, and 32 GB RAM. It also request 1 GPU on the node.</p> <p>The input file <code>input.txt</code> should contain the following settings:</p> <pre><code>%cpu=0-7\n%gpucpu=0=0\n%mem=32GB\n</code></pre> <p>to indicate that the CPU cores with indices from 0 through 7 will be used for the calculation, and the GPU 0 will be driven by CPU core 0.</p>"},{"location":"software/apps-and-envs/gaussian/#additional-resources","title":"Additional resources","text":"<p>HPC Wiki: Gaussian Central Washington University: Running Gaussian on Linux North Dakota State University: Running Gaussian 16 on CCAST Clusters </p>"},{"location":"software/apps-and-envs/gromacs/","title":"GROMACS","text":"<p>GROMACS is a free and open-source software suite for high-performance molecular dynamics and output analysis.</p> <p>Keywords: <code>biology</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/gromacs/#available-modules","title":"Available modules","text":"<p>There are several GROMACS modules on Midway2 and Midway3 that you can check via <code>module avail gromacs</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\ngromacs/5.0.7-cuda+intelmpi-5.1+intel-16.0      \ngromacs/5.1.4-cuda-7.5+intelmpi-5.1+intel-16.0  \ngromacs/2019.2+intelmpi-2018.2.199+intel-18.0   \ngromacs/2019.3+intelmpi-2018.2.199+intel-18.0   \ngromacs/2021.1+intelmpi-2019.up7+intel-19.1.1   \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\ngromacs/2020.4(default)  gromacs/2021.5  gromacs/2022.4  gromacs/2022.4-colvars \n</code></pre> <p>You can then show the dependency of individual modules, for example, <pre><code>module show gromacs/2021.5\n</code></pre> which gives on Midway3 <pre><code>-------------------------------------------------------------------\n/software/modulefiles/gromacs/2021.5:\n\nmodule-whatis   {setup gromacs 2021.5 compiled with the system compiler}\nconflict        gromacs\nmodule          load gcc/7.4.0 openmpi/4.1.2+gcc-7.4.0 cuda/11.2 plumed/2.7.3\nprepend-path    PATH /software/gromacs-2021.5-el8-x86_64/bin\nprepend-path    LD_LIBRARY_PATH /software/gromacs-2021.5-el8-x86_64/lib64\nprepend-path    LIBRARY_PATH /software/gromacs-2021.5-el8-x86_64/lib64\nprepend-path    PKG_CONFIG_PATH /software/gromacs-2021.5-el8-x86_64/lib64/pkgconfig\nprepend-path    CPATH /software/gromacs-2021.5-el8-x86_64/include\nprepend-path    MANPATH /software/gromacs-2021.5-el8-x86_64/share/man\n</code></pre></p> <p>In this case you can see this module was compiled with <code>openmpi/4.1.2+gcc-7.4.0</code>, <code>cuda/11.2</code> and <code>plumed/2.7.3</code>. As a result, this version supports GPU acceleration and should be used on GPU nodes.</p> Note <p>GROMACS is under active development. You are encouraged to build the latest stable version from source code in your own space using the provided compilers.</p> <p>The GROMACS documentation contain useful information for improving performance of your specific calculations:</p> <p>https://manual.gromacs.org/documentation/current/user-guide/mdrun-performance.html</p>"},{"location":"software/apps-and-envs/gromacs/#example-job-script","title":"Example job script","text":"<p>An example batch script to run GROMACS for Midway3 is given as below <pre><code>!/bin/bash\n#SBATCH --job-name=gmx-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --constraint=v100\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=32\n\nmodule load gromacs/2021.5\n\ncd $SLURM_SUBMIT_DIR\n\nexport GMX_PATH=/software/gromacs-2021.5-el8-x86_64/bin\nsource $GMX_PATH/GMXRC\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nt=1000\n\nmpirun -np $n gmx_mpi mdrun -ntomp 1 -pin on -nb gpu -nsteps $t \\\n   -v -s init.tpr\n</code></pre> where <code>init.tpr</code> is an existing portable binary run input file.</p>"},{"location":"software/apps-and-envs/lammps/","title":"LAMMPS","text":"<p>LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) is a classical molecular dynamics code with a focus on materials modeling.</p> <p>Keywords: <code>materials science</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/lammps/#available-modules","title":"Available modules","text":"<p>There are several LAMMPS modules on Midway2 and Midway3 that you can check via <code>module avail lammps</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\nlammps/17Nov2016+intelmpi-5.1+intel-16.0\nlammps/23Jun2022+oneapi-2021  \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\nlammps/17Apr2024  lammps/20Sep2021-gpu       lammps/23Jun2022      lammps/24Mar2022      lammps/29Aug2024  \nlammps/20Sep2021  lammps/21Nov2023(default)  lammps/23Jun2022-gpu  lammps/24Mar2022-gpu  lammps/29Oct2020 \n</code></pre> <p>The <code>gpu</code> suffix indicates that this module support GPU acceleration and should run on a GPU node. You can then show the dependency of individual modules, for example, on Midway3 if you do <pre><code>module show lammps/21Nov2023\n</code></pre> you will get <pre><code>-------------------------------------------------------------------\n/software/modulefiles/lammps/21Nov2023:\n\nmodule-whatis   {setup lammps 21Nov2023 compiled with the system compiler}\nconflict        lammps\nmodule          load intelmpi/2021.5+intel-2022.0 mkl/2022.0 cuda/11.5\nprepend-path    PATH /software/lammps-21Nov2023-el8-x86_64/bin\n</code></pre></p> Note <p>LAMMPS is under active development. You are encouraged to build the latest stable version from source code in your own space using the provided compilers.</p> <p>In this case you can see this module was compiled with <code>intelmpi/2021.5+intel-2022.0</code> and <code>mkl/2022.0</code>. After loading the module, you can run <pre><code>lmp -h\n</code></pre> to see the features that are supported by the executable <code>lmp</code>.</p> <p>There are several LAMMPS binaries in the folder <code>/software/lammps-21Nov2023-el8-x86_64/bin</code>. The README file therein explains the difference between the binaries and how to build LAMMPS from source.</p>"},{"location":"software/apps-and-envs/lammps/#example-job-scripts","title":"Example job scripts","text":"<p>An example batch script to run LAMMPS is given as below <pre><code>#!/bin/bash\n#SBATCH --job-name=lmp-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=caslake\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=16\n\nmodule load lammps/21Nov2023\n\nulimit -l unlimited\n\ncd $SLURM_SUBMIT_DIR\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nmpirun -np $n lmp_cpu -in in.txt\n</code></pre></p> <p>The following script illustrates how to run the LAMMPS binary built with the GPU package <code>lmp_gpu</code></p> <pre><code>#!/bin/bash\n#SBATCH --job-name=lmp-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n#SBATCH --gres=gpu:2\n#SBATCH --constraint=v100\n\nmodule load lammps/21Nov2023\n\nulimit -l unlimited\n\ncd $SLURM_SUBMIT_DIR\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nmpirun -np $n lmp_gpu -in in.txt -sf gpu -pk gpu 2\n</code></pre> <p>The following script illustrates how to run the LAMMPS binary built with the KOKKOS package <code>lmp_kokkos_cuda</code> using 2 MPI processes on 2 CPU cores using 2 GPUs.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=lmp-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=2\n#SBATCH --gres=gpu:2\n#SBATCH --constraint=v100\n\nmodule load lammps/21Nov2023\n\nulimit -l unlimited\n\ncd $SLURM_SUBMIT_DIR\n\nntasks_per_node=$SLURM_NTASKS_PER_NODE\nnumnodes=$SLURM_JOB_NUM_NODES\nn=$(( ntasks_per_node * numnodes ))\n\nmpirun -np $n lmp_kokkos_cuda -in in.txt -k on g 2 -sf kk -pk kokkos neigh half newton on\n</code></pre>"},{"location":"software/apps-and-envs/lammps/#build-lammps-from-source","title":"Build LAMMPS from source","text":"<p>Since LAMMPS is under active development, it might be beneficial for you to build LAMMPS from source to get the new features, improvements, and bugfixes. </p> <p>Below is an example to illustrate how you build LAMMPS from source using the Intel oneAPI toolchain with GPU support for A100 GPUs on Midway3/Beagle3.</p> <pre><code>module load oneapi/2023.1 mkl/2023.1 cmake 3.26\ngit clone https://github.com/lammps/lammps.git\ncd lammps\ngit checkout tags/stable_29Aug2024 -b stable_29Aug2024\nmkdir build\ncd build\ncmake -C ../cmake/presets/basic.cmake \\\n      -D PKG_CLASS2=on -D PKG_AMOBEA=on -D PKG_ASPHERE=on -D PKG_REPLICA=on -DPKG_FEP=on \\\n      -D PKG_GPU=on -D GPU_API=cuda -D GPU_ARCH=sm_80 -D BUILD_MPI=yes -D BUILD_OMP=on \\\n      -D PKG_KOKKOS=on -D Kokkos_ARCH_PASCAL60=off -D Kokkos_ARCH_NATIVE=yes \\\n      -D Kokkos_ARCH_AMPERE80=ON -D Kokkos_ENABLE_CUDA=yes -D Kokkos_ENABLE_OPENMP=yes \\\n      -D CMAKE_CXX_COMPILER=`which mpicxx` -D MPI_C_COMPILER=`which mpicc` \\\n      -DFFT=MKL -DFFTW3_INCLUDE_DIR=$MKLROOT/include/fftw -DFFT_KOKKOS=CUFFT \\\n      ../cmake\nmake -j4\n</code></pre> <p>Note the GPU architecture (more specifically, compute capability) is defined for the KOKKOS package <code>Kokkos_ARCH_AMPERE80=ON</code>. The GPU package is by default compiled into to support a wide range of GPU architectures including <code>sm_80</code>.</p>"},{"location":"software/apps-and-envs/mathematica/","title":"Mathematica","text":"<p>Mathematica is powerful and intuitive computation software.  It is capable of geometric, audio, graphical, and raw data analysis.  The embedded Wolfram Language is an incredibly powerful scripting tool for doing sybolic math analysis and granting command line style access to the plethora of algorithms within the software.  Mathematica has a GUI and CLI that can be used.</p>"},{"location":"software/apps-and-envs/mathematica/#getting-started","title":"Getting Started","text":"<p>To gain access to Mathematica, a Mathematica module must be loaded with the command:</p> <pre><code>module load mathematica\n</code></pre> <p>A full list of available Mathematica versions can be obtained by calling the command:</p> <pre><code>module avail mathematica\n</code></pre>"},{"location":"software/apps-and-envs/mathematica/#using-mathematicas-graphical-interface","title":"Using Mathematica\u2019s Graphical Interface","text":"<p>To use Mathematica\u2019s GUI interface on Midway, we recommend connecting to Midway via ThinLinc. </p> <p>Note that once connected via ThinLinc, you will be accessing a Midway login node.  In order to run Mathematica with its GUI interface on a compute node, obtain a terminal in the ThinLinc desktop and issue the sinteractive command.  This will deliver you to a compute node.  From there, you can launch Mathematica with the commands:</p> <pre><code>module load mathematica\nmathematica\n</code></pre> <p>and have access to the GUI interface.</p>"},{"location":"software/apps-and-envs/mathematica/#using-mathematicas-textual-interface","title":"Using Mathematica\u2019s Textual Interface","text":"<p>Once a Mathematica software module has been loaded, Mathematica\u2019s command line interface can be started with the command <code>math</code>.</p> <pre><code>$ module load mathematica\n$ math\nMathematica 8.0 for Linux x86 (64-bit)\nCopyright 1988-2011 Wolfram Research, Inc.\n\nIn[1]:= a=1;\n\nIn[2]:= b=2;\n\nIn[3]:= a+b\n\nOut[3]= 3\n\nIn[4]:= Quit[];\n</code></pre> <p>More information about using the command line interface to Mathematica is available here: http://reference.wolfram.com/language/tutorial/UsingATextBasedInterface.html</p>"},{"location":"software/apps-and-envs/mathematica/#running-mathematica-jobs-with-slurm","title":"Running Mathematica Jobs with SLURM","text":"<p>To submit Mathematica jobs to Midway\u2019s resource scheduler, SLURM, the Mathematica commands to be executed must be containined in a single .m script.  The .m script will then be passed to the <code>math</code> command in an sbatch file.  For example:</p> <p><code>math-simple.m</code> is a basic Mathematica script that computes the sum of A and B:</p> <pre><code>A = Sum[i, {i,1,100}]\nB = Mean[{25, 36, 22, 16, 8, 42}]\nAnswer = A + B\nQuit[];\n</code></pre> <p>This script can be submited to SLURM with <code>math-simple.sbatch</code> which will send the job to a compute node:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=math-simple\n#SBATCH --output=math-simple.out\n#SBATCH --error=math-simple.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:05:00\n#SBATCH --ntasks=1\n\nmodule load mathematica\n\nmath -run &lt; math-simple.m\n</code></pre> <p>To run this example, download both files to a directory on Midway.  Then, enter the following command to submit the job to the scheduler:</p> <pre><code>sbatch math-simple.sbatch\n</code></pre> <p>Output from this example can be found in the file named math-simple.out which will be created in the same directory.</p>"},{"location":"software/apps-and-envs/mathematica/#using-multiple-cpus-in-mathematica","title":"Using Multiple CPUs in Mathematica","text":"<p>Mathematica can be run in parallel using the built in <code>Parallel</code> commands or by utilizing parallel API.  Parallel Mathematica jobs are limited to one node, but can utilize all CPU cores on the node if allocated.  A parallel Mathematica script must either be submitted to a node that was requested with the <code>exclusive</code> flag or the script must specify the number of processors allocated.  As an example of the latter, the following Mathematica script would be appropriate for a SLURM request of 1 node with 8 tasks per node.</p>"},{"location":"software/apps-and-envs/mathematica/#sample-parallel-job-submission","title":"Sample Parallel Job Submission","text":"<p>SBATCH script:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mathematica_example\n#SBATCH --output=mathematica_example.out\n#SBATCH --error=mathematica_example.err\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n\nmodule load mathematica\n\nmath -run &lt; ./sample-parallel.m\n</code></pre> <p>Mathematica script:</p> <pre><code>(*Limits Mathematica to requested resources*)\nUnprotect[$ProcessorCount];$ProcessorCount = 8;\n\n(*Prints the machine name that each kernel is running on*)\nPrint[ParallelEvaluate[$MachineName]];\n\n(*Prints all Mersenne PRime numbers less than 2000*)\nPrint[Parallelize[Select[Range[2000],PrimeQ[2^#-1]&amp;]]];\n</code></pre>"},{"location":"software/apps-and-envs/matlab/","title":"MATLAB","text":"<p>RCC provides the Matlab programming environment on all Midway compute resources.  Most Matlab toolboxes are also available (see: https://itservices.uchicago.edu/page/matlab-tah-toolboxes).  When running compute- or memory-intensive Matlab jobs on Midway, it is important to run on compute nodes, and not on the login nodes.</p> <p>Note</p> <p>Compute- and memory-intensive jobs running on the login nodes are subject to termination without warning by RCC system administrators as this impacts the performance of the login nodes and ability for other users to work.</p>"},{"location":"software/apps-and-envs/matlab/#getting-started","title":"Getting Started","text":"<p>To gain access to Matlab, a Matlab module must be loaded with the command:</p> <pre><code>module load matlab\n</code></pre> <p>A full list of the available Matlab versions can be obtained by issuing the command:</p> <pre><code>module avail matlab\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#using-matlabs-textual-interface","title":"Using Matlab\u2019s Textual Interface","text":"<p>On Midway, Matlab can be launched at the terminal with the commands:</p> <pre><code>module load matlab\nmatlab\n</code></pre> <p>This will launch Matlab\u2019s textual interface. We recommend running Matlab on a compute node as opposed to a login node. </p>"},{"location":"software/apps-and-envs/matlab/#using-matlabs-gui-interface","title":"Using Matlab\u2019s GUI Interface","text":"<p>To use Matlab\u2019s GUI interface on Midway, we reccomend connecting to Midway via ThinLinc. </p> <p>Note that once connected via ThinLinc, you will be accessing a Midway login node.  In order to run Matlab with its GUI interface on a compute node, obtain a terminal in the ThinLinc desktop and issue the sinteractive command.  This will deliver you to a compute node.  From there, you can launch Matlab with the command:</p> <pre><code>module load matlab\nmatlab\n</code></pre> <p>and have access to the GUI interface.</p>"},{"location":"software/apps-and-envs/matlab/#running-matlab-jobs-with-slurm","title":"Running Matlab Jobs with SLURM","text":"<p>To submit Matlab jobs to Midway\u2019s resource scheduler, SLURM, the Matlab commands to be executed must be containined in a single .m script.</p> <p><code>matlab_simple.m</code> is a basic Matlab script that computes and prints a 10x10 magic square</p> <p><code>matlab_simple.sbatch</code> is a submission script that submits Matlab program to the default queue</p> <p>To run this example, download both files to a directory on Midway.  Then, enter the following command to submit the program matlab_simple.m to the scheduler:</p> <pre><code>sbatch matlab_simple.sbatch\n</code></pre> <p>Output from this example can be found in the file named matlab.out which will be created in the same directory.</p>"},{"location":"software/apps-and-envs/matlab/#matlab-parallel","title":"Matlab Parallel","text":"<p>To run MATLAB effectively using parallel computing techniques requires a few basic concepts which can be optimized and expanded upon.  The MATLAB Parallel Computing Toolbox User\u2019s Guide is the official documentation and should be referred to for further details, examples and explanations.  Here, we provide some Midway-specific considerations that RCC users should be aware of.</p> <p>RCC reccomends MATLAB 2014b for parallel matlab computing as it relaxes the restriction on number of workers available through the PCT.</p> <p>NOTE: At this time, RCC does not support the Matlab Distributed Compute Server (MDCS).  As such, parallel Matlab jobs are limited to a single node with the \u201clocal\u201d pool through use of the Parallel Compute Toolbox (PCT). </p>"},{"location":"software/apps-and-envs/matlab/#basic-pct-operation","title":"Basic PCT Operation","text":"<p>The most basic level of parallelization in Matlab is achieved through use of a <code>parfor</code> loop in place of a <code>for</code> loop.  The iterations of a <code>parfor</code> loop are distributed to the workers in the active matlabpool and computed concurrently.  For this reason, care must be taken to ensure that each iteration of the parfor loop is independent of every other.</p> <p>The overall procedure for leveraging parfor in your Matlab script is as follows:</p> <ol> <li> <p>Create a local matlabpool</p> </li> <li> <p>Call <code>parfor</code> in place of <code>for</code> in your Matlab scripts and functions</p> </li> </ol> <p>A simple Matlab script that uses parfor can be downloaded here: <code>matlab_parfor.m</code> and is shown below.</p> <pre><code>% start the matlabpool with maximum available workers\n% control how many workers by setting ntasks in your sbatch script\npc = parcluster('local')\nparpool(pc, str2num(getenv('SLURM_CPUS_ON_NODE')))\n\n% run a parfor loop, distributing the iterations to the SLURM_CPUS_ON_NODE workers\nparfor i = 1:100\n\n        ones(10,10)\n\nend\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#submitting-a-pct-matlab-job-to-slurm","title":"Submitting a PCT Matlab Job to SLURM","text":"<p>Compute intensive jobs that will consume non-trivial amounts of CPU and/or memory resources should not be run on Midway\u2019s login nodes.  Instead, the job should be submitted to the scheduler and run on a compute node.  A sample submission script for the above example Matlab sample is provided here: <code>matlab_parfor.sbatch</code> and is shown below.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=whatever\n#SBATCH --output=matlab_parfor.out\n#SBATCH --error=matlab_parfor.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1\n#SBATCH --ntasks=16\n\nmodule load matlab/2014b\n\nmatlab -nodisplay &lt; matlab_parfor.m\n</code></pre>"},{"location":"software/apps-and-envs/matlab/#running-multiple-pct-matlab-jobs","title":"Running Multiple PCT Matlab Jobs","text":"<p>Specific care must be taken when running multiple PCT jobs on Midway.  When you submit multiple jobs that are all using PCT for parallelization, the multiple matlabpools that get created have the ability to interfere with one another which can lead to errors and early termination of your scripts.</p> <p>The Matlab PCT requires a temporary \u201cJob Storage Location\u201d where is stores information about the Matlab pool that is in use.  This is simply a directory on the filesystem that Matlab writes various files to in order to coordinate the parallelization of the matlabpool.  By default, this information is stored in /home/YourUsername/.matlab/ (the default \u201cJob Storage Location\u201d).  When submitting multiple jobs to SLURM that will all use the PCT, all of the jobs will attempt to use this default location for storing job information thereby creating a race condition where one job modifies the files that were put in place by another.  Clearly, this situation must be avoided.</p> <p>The solution is to have each of your jobs that will use the PCT set a unique location for storing job information.  To do this, a temporary directory must be created before launching matlab in your submission script and then the matlabpool must be created to explicitly use this unique temporary directory.  An example sbatch script <code>matlab_multi.sbatch</code> to do this is shown below:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=whatever\n#SBATCH --output=matlab_parfor.out\n#SBATCH --error=matlab_parfor.err\n#SBATCH --partition=sandyb\n#SBATCH --time=00:10:00\n#SBATCH --nodes=1\n#SBATCH --ntasks=16\n\nmodule load matlab/2014b\n\n# Create a temporary directory on scratch\nmkdir -p $SCRATCH/$SLURM_JOB_ID\n\n# Kick off matlab\nmatlab -nodisplay &lt; multi_parfor.m \n\n# Cleanup local work directory\nrm -rf $SCRATCH/$SLURM_JOB_ID\n</code></pre> <p>And the corresponding Matlab script <code>multi_parfor.m</code> shown here:</p> <pre><code>% create a local cluster object\npc = parcluster('local')\n\n% explicitly set the JobStorageLocation to the temp directory that was created in your sbatch script\npc.JobStorageLocation = strcat(getenv('SCRATCH'),'/', getenv('SLURM_JOB_ID'))\n\n% start the matlabpool with maximum available workers\n% control how many workers by setting ntasks in your sbatch script\nparpool(pc, str2num(getenv('SLURM_CPUS_ON_NODE')))\n\n% run a parallel for loop\nparfor i = 1:100\n    ones(10,10)\nend\n</code></pre>"},{"location":"software/apps-and-envs/namd/","title":"NAMD","text":"<p>NAMD  is a parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems.</p> <p>Keywords: <code>biology</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/namd/#available-modules","title":"Available modules","text":"<p>There are several NAMD modules on Midway2 and Midway3 that you can check via <code>module avail namd</code>:</p> Midway2Midway3 <pre><code>---------------------------- /software/modulefiles2 ----------------------------\nnamd/2.11+intelmpi-5.1+intel-16.0 \nnamd/2.12+intelmpi-5.1+intel-16.0\nnamd/2.13+intelmpi-5.1+intel-16.0\nnamd/2.14+intelmpi-5.1+intel-16.0   \n</code></pre> <pre><code>---------------------------- /software/modulefiles -----------------------------\nnamd/2.14(default)\nnamd/2.14+intel-2022.0\nnamd/2.14+intel-2022.0+cuda-11.5\nnamd/2.14+intel-2022.0+cuda-11.5+multi\nnamd/2.14+intel-2022.0+multi\nnamd/3.0b3-multicore-cuda\nnamd/3.0b5-netlrts-smp-cuda\nnamd/3.0b5-verbs-smp-cuda\n</code></pre> <p>The <code>multi</code> suffix indicates that the module can run across multiple nodes. The <code>cuda-11.5</code> indicates that the module support GPU acceleration via CUDA. You can then show the dependency of individual modules, for example, on Midway3 if you do <pre><code>module show namd/2.14+intel-2022.0+multi\n</code></pre> you will get <pre><code>-------------------------------------------------------------------\n/software/modulefiles/namd/2.14+intel-2022.0+multi:\n\nmodule-whatis   {setup namd 2.14 multiple-node compiled with intel-2022.0}\nconflict        namd\nmodule          load intelmpi/2021.5+intel-2022.0\nprepend-path    PATH /software/namd-2.14-el8-x86_64+intel-2022.0/bin-multi\nsetenv          FI_PROVIDER mlx\nsetenv          NAMD_HOME /software/namd-2.14-el8-x86_64+intel-2022.0/bin-multi\nsetenv          CONV_RSH ssh\n</code></pre></p> <p>In this case you can see this module was compiled with <code>intelmpi/2021.5+intel-2022.0</code>. </p>"},{"location":"software/apps-and-envs/namd/#example-job-scripts","title":"Example job scripts","text":"<p>An example batch script to run NAMD 2.14 for Midway3 with multiple nodes and GPU acceleration is given as below <pre><code>#!/bin/bash\n#SBATCH --job-name=\"test-namd\"\n#SBATCH --account=pi-[cnetid]\n#SBATCH -t 06:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=2             # 2 nodes\n#SBATCH --ntasks-per-node=2   # 2 processes per node\n#SBATCH --cpus-per-task=2     # 2 threads mapping to 2 cores per node\n#SBATCH --gres=gpu:2          # 2 GPUs per node\n#SBATCH --constraint=v100\n\nmodule load namd/2.14+intel-2022.0+cuda-11.5+multi\n\nulimit -l unlimited\n\n# calculate total processes (P) and cpus per task\nP=$(( SLURM_NTASKS_PER_NODE * SLURM_NNODES ))\nCPUSPERPE=$SLURM_CPUS_PER_TASK\n\n# using 4 processes, 2 worker threads per process (8 PEs total) using PEs 0,2,4,6 for communication\nmpirun -np $P $NAMD_HOME/namd2 +ppn $CPUSPERPE +pemap 1,3,5,7 +commap 0,2,4,6 +devices 0,1 +ignoresharing +isomalloc_sync input.namd\n</code></pre></p> <p>The following script shows how to run NAMD 2.14 for a replica exchange simulation for 2 replicas, each on a node, using 1 GPU.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=\"test-namd\"\n#SBATCH --account=pi-[cnetid]\n#SBATCH -t 06:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=2             # 2 nodes\n#SBATCH --ntasks-per-node=1   # 1 process per node\n#SBATCH --cpus-per-task=4     # 4 threads mapping to 4 cores per node\n#SBATCH --gres=gpu:1          # 1 GPU per node\n#SBATCH --constraint=v100\n\nmodule load namd/2.14+intel-2022.0+cuda-11.5+mult\n\nulimit -l unlimited\n\n# calculate total processing elements (PE)\nPPN=$SLURM_CPUS_PER_TASK\nP=$(( SLURM_NTASKS_PER_NODE * SLURM_NNODES ))\n\n# create separate folders for the output of M=2 replicas\nmkdir -p output\n(cd output; mkdir -p {0..1})\n\n# run a simulation with M=2 replicas\nmpirun -np $P $NAMD_HOME/namd2 +ppn $PPN +replicas 2 apoa1.namd +stdout output/%d/mysum.%d.log\n</code></pre> <p>The following script shows how to run NAMD 3.0, which is a single-node, multithreading, GPU resident version.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=\"test-namd\"\n#SBATCH --account=pi-[cnetid]\n#SBATCH -t 06:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=1             # 1 node\n#SBATCH --ntasks-per-node=1   # 1 process per node\n#SBATCH --cpus-per-task=4     # 4 threads mapping to 4 cores per node\n#SBATCH --gres=gpu:2          # 2 GPUs per node\n#SBATCH --constraint=v100\n\nmodule load namd/3.0b3-multicore-cuda\n\n# calculate total processes (P) and procs per node (PPN)\nPPN=$(( $SLURM_CPUS_PER_TASK * $SLURM_NTASKS_PER_NODE ))\nP=$(( $PPN * $SLURM_NNODES ))\n\n$NAMD_HOME/namd3 +p $PPN +devices 0,1 --CUDASOAIntegrate on +setcpuaffinity input.namd\n</code></pre> <p>The following script shows how to run NAMD 3.0 for a replica exchange simulation on a single node, for 2 replicas each on a GPU.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=\"test-namd\"\n#SBATCH --account=pi-[cnetid]\n#SBATCH -t 06:00:00\n#SBATCH --partition=gpu\n#SBATCH --nodes=1             # 1 node\n#SBATCH --ntasks-per-node=1   # 1 process per node\n#SBATCH --cpus-per-task=4     # 4 threads mapping to 4 cores per node\n#SBATCH --gres=gpu:2          # 2 GPUs per node, 1 for each replica\n#SBATCH --constraint=v100\n\nmodule load namd/3.0b5-netlrts-smp-cuda\n\n# Generate NAMD nodelist\necho \"group main\" &gt; nodelist.$SLURM_JOBID\nfor n in `echo $SLURM_NODELIST | scontrol show hostnames`; do\n  echo \"host $n\" &gt;&gt; nodelist.$SLURM_JOBID\ndone\n\nNODELIST=nodelist.$SLURM_JOBID\n\nulimit -l unlimited\n\n# calculate total processing elements (PE)\nPPN=$SLURM_CPUS_PER_TASK\n\n# create separate folders for the output of M=2 replicas\nmkdir -p output\n(cd output; mkdir -p {0..1})\n\n# run a simulation with M=2 replicas\n$NAMD_HOME/charmrun $NAMD_HOME/namd3 ++local +p $PPN +replicas 2 +devicesperreplica 1 +ignoresharing apoa1.namd +stdout output/%d/mysum.%d.log\n</code></pre>"},{"location":"software/apps-and-envs/nwchem/","title":"NWChem","text":"<p>NWChem is an open source software package for performing high-performance computational chemistry calculations. The software contains tools that are scalable both in their ability to efficiently treat large scientific problems, and in their use of available computing resources from high-performance parallel supercomputers to conventional workstation clusters.</p> <p>Check out the NWChem documentation for more information: https://nwchemgit.github.io/index.html</p> <p>Keywords: <code>quantum chemistry</code>, <code>chemistry</code></p>"},{"location":"software/apps-and-envs/nwchem/#available-modules","title":"Available modules","text":"<p>You can check the avaiable <code>nwchem</code> module(s) installed via <code>module avail nwchem</code>:</p> Midway3 <pre><code>---------------------------- /software/modulefiles -----------------------------\nnwchem/7.2.2\n</code></pre> <p>You can use <code>module show</code> to see the dependencies and environment variables set by a specified <code>nwchem</code> module, for example, <code>module show nwchem/7.2.2</code>:</p> <pre><code>-------------------------------------------------------------------\n/software/modulefiles/nwchem/7.2.2:\n\nmodule-whatis   {setup nwchem 7.2.2 compiled with the system compiler}\nconflict        nwchem\nmodule          load oneapi/2023.1 mkl/2023.1\nprepend-path    PATH /software/nwchem-7.2.2-el8-x86_64/bin\nprepend-path    LD_LIBRARY_PATH /software/nwchem-7.2.2-el8-x86_64/lib\nprepend-path    LIBRARY_PATH /software/nwchem-7.2.2-el8-x86_64/lib\n-------------------------------------------------------------------\n</code></pre>"},{"location":"software/apps-and-envs/nwchem/#example-job-script","title":"Example job script","text":"<p>An example batch script to run NWChem for Midway3 is given as below <pre><code>#!/bin/bash\n#SBATCH --job-name=nwchem-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=8\n#SBATCH --mem=64GB\n\nmodule load nwchem/7.2.2\n\nulimit -l unlimited\n\ncd $SLURM_SUBMIT_DIR\n\nnodes=$SLURM_NNODES\nppn=$SLURM_NTASKS_PER_NODE\nn=$(( ppn * nodes ))\n\nmpirun -n $n nwchem input.nw\n</code></pre></p> <p>An example input file <code>input.nw</code> can be as follows: <pre><code>start h2o \ntitle \"Water in 6-31g basis set\" \n\ngeometry units au  \n  O      0.00000000    0.00000000    0.00000000  \n  H      0.00000000    1.43042809   -1.10715266  \n  H      0.00000000   -1.43042809   -1.10715266 \nend  \nbasis  \n  H library 6-31g  \n  O library 6-31g  \nend\ntask scf\n</code></pre></p>"},{"location":"software/apps-and-envs/nwchem/#build-nwchem-from-source","title":"Build NWChem from source","text":"<p>Since NWChem is under active development, it might be beneficial for you to build NWChem from source to get the new features, improvements, and bugfixes. </p> <p>Below is an example to illustrate how you build NWChem from source using the Intel oneAPI toolchain on Midway3/Beagle3.</p> <pre><code>module load oneapi/2023.1 mkl/2023.1 python/anaconda-2021.5 cmake 3.26\ncd /your/own/space\ngit clone https://github.com/nwchemgit/nwchem.git\ncd nwchem\ngit checkout tags/v7.2.2-release -b v7.2.2\nexport NWCHEM_TOP=/your/own/space/nwchem\nexport NWCHEM_TARGET=LINUX64\nexport NWCHEM_MODULES=\"all python\"\nexport USE_MPI=y\nexport USE_MPIF=y\nexport USE_MPIF4=y\nexport USE_SCALAPACK=y\nexport SCALAPACK=\"-L$MKLROOT/lib/intel64 -lmkl_scalapack_ilp64 -lmkl_intel_ilp64 -lmkl_core -lmkl_sequential -lmkl_blacs_intelmpi_ilp64 -lpthread -lm\"\nexport SCALAPACK_SIZE=8\nexport SCALAPACK_LIB=\"$SCALAPACK\"\nexport BLAS_SIZE=8\nexport BLASOPT=\"-L$MKLROOT/lib/intel64 -lmkl_intel_ilp64 -lmkl_core -lmkl_sequential -lmkl_core -liomp5 -lpthread -ldmapp -lm\"\nexport LAPACK_LIB=\"-L$MKLROOT/lib/intel64 -lmkl_intel_ilp64 -lmkl_core -lmkl_sequential -lmkl_core -liomp5 -lpthread -ldmapp -lm\"\nexport PYTHONVERSION=3.8\nexport PYTHONLIBTYPE=so\nexport CC=mpiicc\nexport FC=mpiifort\nmake nwchem_config\nmake\n</code></pre>"},{"location":"software/apps-and-envs/openmm/","title":"OpenMM","text":"<p>OpenMM is an open-source high-performance toolkit for molecular simulation. You can use it as an application, a library, or a flexible programming environment.</p> <p>Keywords: <code>biology</code>, <code>physics</code>, <code>chemistry</code>, <code>molecular dynamics</code></p>"},{"location":"software/apps-and-envs/openmm/#available-modules","title":"Available modules","text":"<p>There are several OpenMM modules on Midway3 that you can check via <code>module avail opemm</code>:</p> Midway3 <pre><code>---------------------------- /software/modulefiles -----------------------------\nopenmm/7.5.1  openmm/8.1.0(default)\n</code></pre> Note <p>OpenMM is under active development. You are encouraged to build the latest stable version from source code in your own space using the provided compilers.</p> Note <p>You can also install OpenMM into your conda environment. See http://docs.openmm.org/7.0.0/userguide/application.html for more information <pre><code>module load python/miniforge-25.3.0\nconda create -n your-env python=3.8\nsource activate your-env\nconda install -c conda-forge openmm cudatoolkit=11.5\n</code></pre></p> <p>The OpenMM documentation contain useful information for improving performance of your specific calculations:</p> <p>https://openmm.org/documentation</p>"},{"location":"software/apps-and-envs/openmm/#example-job-script","title":"Example job script","text":"<p>The following is an example batch script for running OpenMM on Midway3. <pre><code>!/bin/bash\n#SBATCH --job-name=openmm-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --partition=gpu\n#SBATCH --gres=gpu:1\n#SBATCH --constraint=v100\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n\nmodule load openmm\n\ncd $SLURM_SUBMIT_DIR\n\npython run_openmm.py\n</code></pre> where <code>run_openmm.py</code> is a python script that sets up the system.</p> <p>Example python scripts can be found at https://github.com/openmm/openmm/blob/master/examples/. Below is an example script that reads in a protein PDB structure, selects a force field, defines a system, specifies a time integrator, performs energy minimization, sets up the output log and snapshots and finally runs the MD simulation. You can use this script as <code>run_openmm.py</code> in the job script above.</p> <pre><code>from openmm.app import *\nfrom openmm import *\nfrom openmm.unit import *\nfrom sys import stdout\n\npdb = PDBFile('input.pdb')\nforcefield = ForceField('amber14-all.xml', 'amber14/tip3pfb.xml')\nsystem = forcefield.createSystem(pdb.topology, nonbondedMethod=PME, nonbondedCutoff=1*nanometer, constraints=HBonds)\nintegrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.004*picoseconds)\n\n# Select a platform for GPU acceleration: \n# CUDA backend might fail due to an incompatible version of the GPU driver on the compute nodes than the OpenMM compiled PTX\nplatform_name = ''\ntry:\n    platform_name = 'CUDA'\n    simulation = Simulation(pdb.topology, system, integrator,\n                            openmm.Platform.getPlatformByName(platform_name))\nexcept OpenMMException as e:\n    platform_name = 'OpenCL'\n    simulation = Simulation(pdb.topology, system, integrator,\n                            openmm.Platform.getPlatformByName(platform_name))\nexcept Exception:\n    platform_name = 'CPU'\n    simulation = Simulation(pdb.topology, system, integrator)\n\nprint(f'Running simulation on the {platform_name} backend')\n\nsimulation.context.setPositions(pdb.positions)\nsimulation.minimizeEnergy()\nsimulation.reporters.append(PDBReporter('output.pdb', 1000))\nsimulation.reporters.append(StateDataReporter(stdout, 1000, step=True, potentialEnergy=True, temperature=True))\nsimulation.step(10000)\n</code></pre>"},{"location":"software/apps-and-envs/openpose/","title":"OpenPose","text":"<p>OpenPose is available on Midway3 as a container. You can find the singularity file, named <code>openpose-v2_v0.1.sif</code>, under the directory <code>/project/rcc/shared/container</code>. </p> <p>To get started with a minimal working example, you'll want to follow these steps:</p> <p>First, you'll need to launch a GPU node on Midway3. Once you've done that, run the following commands:</p> <p>Go to your Midway3 scratch or project directory: </p> <p><code>cd /scratch/midway3/$USER/containers</code></p> <p>or</p> <p><code>cd /project/drpepper/containers</code></p> <p>Copy the OpenPose container to your  Midway3 scratch or project directory:</p> <p><code>cp /project/rcc/shared/container/openpose-v2_v0.1.sif ./</code></p> <p>Load the <code>apptainer</code> module:</p> <p><code>module load apptainer</code></p> <p>Then load the OpenPose container: </p> <p><code>apptainer shell -B /projects -B /scratch --nv ./openpose-v2_v0.1.sif</code></p> <p>After entering the container, you need to create a directory for your results:</p> <p><code>mkdir -p /scratch/midway3/$USER/poses</code></p> <p>Next, navigate to the OpenPose folder and execute the example:</p> <p><code>cd /openpose</code></p> <pre><code>./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_video /scratch/midway3/$USER/result.avi --write_json /scratch/midway3/$USER/poses --display 0\n</code></pre> <p>Once the process is complete, check the <code>result.avi</code> file created in your scratch folder. </p>"},{"location":"software/apps-and-envs/orca/","title":"ORCA","text":"<p>ORCA is a general-purpose quantum chemistry package that supports a wide variety of methods such as density functional theory, many-body perturbation and coupled cluster. ORCA is free of charge, but not open source.</p> <p>Check out the ORCA manual for more information: https://www.faccts.de/docs/orca/6.0/manual/</p> <p>Keywords: <code>quantum chemistry</code>, <code>chemistry</code></p>"},{"location":"software/apps-and-envs/orca/#available-modules","title":"Available modules","text":"<p>There are several ORCA modules on Midway3 that you can check via <code>module avail orca</code>:</p> Midway3 <pre><code>---------------------------- /software/modulefiles -----------------------------\norca/4.1  orca/4.2.1  orca/5.0.2(default)  orca/6.0.1  \norca/4.2  orca/5.0.0  orca/5.0.4\n</code></pre> <p>You can use <code>module show</code> to see the dependencies and environment variables set by a specified <code>orca</code> module, for example, <code>module show orca/6.0.1</code>:</p> <pre><code>-------------------------------------------------------------------\n/software/modulefiles/orca/6.0.1:\n\nmodule-whatis   {setup orca 6.0.1 compiled with the system compiler}\nconflict        orca\nmodule          load openmpi/4.1.2+gcc-10.2.0\nprepend-path    PATH /software/orca-6.0.1-el8-x86_64/bin\nsetenv          ORCA_DIR /software/orca-6.0.1-el8-x86_64/bin\n-------------------------------------------------------------------\n</code></pre>"},{"location":"software/apps-and-envs/orca/#example-job-script","title":"Example job script","text":"<p>An example batch script to run ORCA for Midway3 is given as below <pre><code>#!/bin/bash\n#SBATCH --job-name=orca-bench\n#SBATCH --account=pi-[cnetid]\n#SBATCH --time=01:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n#SBATCH --mem=64GB\n\nmodule load orca/6.0.1\n\nulimit -l unlimited\n\ncd $SLURM_SUBMIT_DIR\n\n# the environment variable ORCA_DIR may be set by the orca module loaded\n$ORCA_DIR/orca input.txt &gt; output.log\n</code></pre></p> <p>Note that ORCA supports MPI parallelization with a compatible version of OpenMPI. For the given example, <code>orca/6.0.1</code> is compatible with OpenMPI 4.1.x. Here the binary <code>orca</code> will launch the 8 MPI processes as specified in the <code>%pal</code> section in the input script <code>input.txt</code>. Below is a simple input script that performs a geometry optimization calculation with the Hartree-Fock method with the DEF2-SVP basis set using 8 MPI procs. <pre><code>%pal\n    nprocs 8\nend\n!HF DEF2-SVP\n%scf\n   maxiter 500\nend\n* xyz 0 1\nO   0.0000   0.0000   0.0626\nH  -0.7920   0.0000  -0.4973\nH   0.7920   0.0000  -0.4973\n*\n</code></pre></p>"},{"location":"software/apps-and-envs/perl/","title":"Perl","text":"<p>Perl is available as a software module. No additional perl modules have been installed. Installing local modules using local::lib with cpanm is the preferred method. Here is an example to install and test Math::CDF:</p> <pre><code>module load perl\neval $(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)\ncpanm Math::CDF\nperl -e \"require Math::CDF\"\n</code></pre> <p>To have the appropriate environment available during login, it is recommended to put these lines in the $HOME/.bashrc:</p> <pre><code>module load perl\n[ $SHLVL -eq 1 ] &amp;&amp; eval \"$(perl -I$HOME/perl5/lib/perl5 -Mlocal::lib)\"\n</code></pre> <p>Additional details on local::lib can be in the local::lib documentation.</p>"},{"location":"software/apps-and-envs/python/","title":"Python and Anaconda","text":""},{"location":"software/apps-and-envs/python/#getting-started","title":"Getting Started","text":"<p>Different versions of Python on Midway are offered as modules. To check the full list of Python modules use the <code>module avail python</code> command.</p> <p>The command <code>module load python</code> will load the default module: an Anaconda distribution of Python. Note that there are multiple different Anaconda distributions available.  </p> <ul> <li>Audience: Researchers, students, and staff using Python on Midway clusters.</li> <li>Scope: Standard Python modules, Miniforge, uv, Mamba, Jupyter, plotting, and more.</li> <li>Tip: For best results, read through the recommendations and best practices before starting a new project.</li> </ul> <p>toc</p>"},{"location":"software/apps-and-envs/python/#2-recommendations","title":"2. Recommendations","text":""},{"location":"software/apps-and-envs/python/#21-python-distribution-recommendations","title":"2.1. Python distribution recommendations","text":"<p>Choosing the right Python distribution is essential for reproducibility, ease of use, and compatibility with Midway resources. The table below summarizes the main options and when to use each.</p> Distribution Module Name/Version Best for Notes Standard Python (recommended) <code>python/3.11.9</code>, <code>python/3.8.0</code>, <code>python/2.7</code> (Midway3)<code>python/3.9.18</code> (Midway2) Most research, production, reproducibility Minimal, clean installs. Use for scripts, pipelines, and most research. Miniforge (conda/mamba) <code>python/miniforge-25.3.0</code> Scientific computing, data science Flexible, includes mamba for fast env/package management. Anaconda <code>python/anaconda-2022.05</code> (Midway3)<code>python/anaconda3-2021.05</code> (Midway2) Legacy, teaching, compatibility needs Not recommended for research due to license restrictions and inode/storage issues. <p>Quick advice:</p> <ul> <li>Use Standard Python for most research, scripting, and production workflows. It ensures a clean, reproducible environment.</li> <li>Use Miniforge if you need many scientific/data science packages or want to manage environments with conda/mamba.</li> <li>Use Anaconda only if required for teaching, legacy workflows, or compatibility needs. For research, prefer Standard Python or Miniforge. Anaconda is available as <code>python/anaconda-2022.05</code> on Midway3 and <code>python/anaconda-2021.05</code> on Midway2.</li> </ul> <p>Important: Anaconda Licensing and Inode Usage Issues</p> <p>Anaconda has implemented commercial license restrictions for organizations with over 200 employees, affecting many academic institutions. Additionally, a full Anaconda installation can exceed 3GB in size and create over 100,000 small files, which quickly exhausts inode quotas. On Midway clusters, home directories typically have strict inode quotas (around 30,000), and a single Anaconda installation can consume most or all of this quota, preventing you from creating additional files.</p> <p>To see available versions: <pre><code>module avail python\n</code></pre></p> <p>To load a module: <pre><code>module load python/3.11.9       # Standard Python (recommended)\nmodule load python/miniforge-25.3.0  # Miniforge (conda/mamba)\n</code></pre></p> <ul> <li>For most users, start with Standard Python. If you need conda-style environments or many scientific packages, switch to Miniforge.</li> <li>Both Standard Python and Miniforge are fully supported and optimized for Midway clusters.</li> </ul> <p>Why Miniforge over Anaconda?</p> <p>Miniforge is strongly preferred over Anaconda for research computing on Midway clusters for several reasons: - No license restrictions for any use, unlike Anaconda's commercial restrictions - Significantly fewer files and inodes - Anaconda installations can exceed 3GB and create over 100,000 small files - Smaller disk footprint - Requires less storage space in your quota - Faster package installation with Mamba support - Uses conda-forge by default for more up-to-date scientific packages - Better performance on HPC environments with lower overhead</p> <p>Managing Inode Usage with Conda Environments</p> <p>If you use any conda-based distribution (Miniforge, Anaconda, etc.):</p> <ol> <li>Install environments in <code>/scratch/midway3/$USER/conda_envs</code> rather than your home directory</li> <li>Run <code>conda clean --all</code> regularly to remove unused package caches</li> <li>Limit the number of environments you create and maintain</li> <li>Use <code>df -i</code> to check your current inode usage</li> <li>Consider Python virtual environments (venv) for smaller projects</li> </ol>"},{"location":"software/apps-and-envs/python/#managing-storage-and-cache","title":"Managing Storage and Cache","text":""},{"location":"software/apps-and-envs/python/#condamamba-cache-management","title":"Conda/Mamba Cache Management","text":"<p>By default, conda/mamba caches downloaded packages under <code>~/.conda/pkgs</code>, which can rapidly exhaust your home directory's inode and space quotas on shared systems.</p> <p>Options to control the cache:</p> <ol> <li>Temporary cache (recommended on Midway)</li> <li>Minimizes inode usage; cache lives in a temporary location and is cleaned up automatically.</li> <li>Our Python modules honor <code>USE_CONDA_CACHE=0</code> when set before loading the module.</li> <li> <p>Example:      <pre><code># Set before loading the Python module\nexport USE_CONDA_CACHE=0\nmodule load python/miniforge-25.3.0\n</code></pre></p> </li> <li> <p>Persistent cache (optional, for repeated installs)</p> </li> <li>Keeps packages between sessions to speed up repeated environment solves/installs.</li> <li>Set a cache directory in project or scratch space; avoid <code>$HOME</code>.</li> <li>You can either set <code>USE_CONDA_CACHE=1</code> (module convenience; must be supported by the modulefile) and/or explicitly point conda to a path using <code>CONDA_PKGS_DIRS</code> or <code>.condarc</code>:      <pre><code># Choose a persistent location (recommended)\nexport CONDA_PKGS_DIRS=/project/PI_NAME/USER/conda/pkgs   # or /scratch/midway3/$USER/conda/pkgs\n# Persist via conda config (optional)\nconda config --add pkgs_dirs /project/PI_NAME/USER/conda/pkgs\nconda config --show pkgs_dirs\n</code></pre></li> <li>If your modulefile supports the toggle, you can also do:      <pre><code>export USE_CONDA_CACHE=1\nmodule load python/miniforge-25.3.0\n</code></pre></li> <li>Recommendation: Use project or scratch; do not keep caches in your home directory.</li> </ol>"},{"location":"software/apps-and-envs/python/#uv-package-manager","title":"UV Package Manager","text":"<p>See uv docs: https://docs.astral.sh/uv/</p> <p>uv is a modern, fast alternative to pip for package management (available on both Midway2 and Midway3):</p> <pre><code># Load modules\nmodule load python/miniforge-25.3.0  # or other Python version\nmodule load uv\n\n# Create virtual environment (faster than venv)\nuv venv myenv\n\n# Activate\nsource myenv/bin/activate\n\n# Install packages (much faster than pip)\nuv pip install numpy pandas\n</code></pre> <p>UV cache: temporary vs persistent</p> <ul> <li>Temporary cache reduces inode usage and is a good default on shared clusters.</li> <li>Persistent cache speeds up repeated installs across nodes/sessions. If you want this, either:</li> <li>Use our module toggle <code>USE_UV_CACHE=1</code> before <code>module load uv</code> (if supported by the modulefile), or</li> <li>Set an explicit path with <code>UV_CACHE_DIR</code> to project/scratch (preferred):     <pre><code>export UV_CACHE_DIR=/project/PI_NAME/USER/uv/cache   # or /scratch/midway3/$USER/uv/cache\n</code></pre></li> <li>To minimize cache entirely for throwaway installs, you can disable caching:   <pre><code>export UV_NO_CACHE=1\n</code></pre></li> <li>Note: <code>UV_NO_CACHE</code> is an official uv environment variable and does not require a modulefile. See: https://docs.astral.sh/uv/reference/environment/#uv_no_cache</li> </ul> <p>Compiled packages on Midway2</p> <p>On Midway2, packages with native extensions (e.g., NumPy/SciPy) may require a newer GCC toolchain (e.g., errors like \"NumPy requires GCC &gt;= 9.3\"). If you encounter this, either load an appropriate GCC module before installing, or prefer installing these packages via conda/mamba environments instead of <code>uv pip</code>.</p>"},{"location":"software/apps-and-envs/python/#3-best-practices","title":"3. Best Practices","text":""},{"location":"software/apps-and-envs/python/#31-environment-management","title":"3.1. Environment management","text":"<p>Once you load a Python distribution, you can list all available public environments with: <pre><code>conda env list  \n</code></pre> To activate an environment, run: <pre><code>source activate &lt;ENV NAME&gt;\n</code></pre> where <code>&lt;ENV NAME&gt;</code> is the name of the environment for a public environment, or the full path to the environment, if you are using a personal one. You can deactivate an environment with:  <pre><code>conda deactivate\n</code></pre></p> <p>Danger</p> <p>Why use <code>source activate</code> instead of <code>conda activate</code> (or <code>mamba activate</code>)?</p> <p><code>conda activate</code>/<code>mamba activate</code> require <code>conda init</code>, which edits your shell startup files (e.g., <code>~/.bashrc</code>, <code>~/.bash_profile</code>). Those edits can interfere with the module environment, non-interactive shells (batch jobs), and remote desktop sessions, and generally degrade the user experience on Midway. Using <code>source activate</code> (with the full env path or a symlinked name) avoids modifying startup files and works reliably across login, batch, and ThinLinc sessions.</p> <p>Do not run <code>conda init</code></p> <p>Never run <code>conda init</code> on Midway. It modifies your shell startup scripts and can break module behavior, non-interactive shells, and ThinLinc sessions. Use <code>source activate</code> instead of <code>conda activate</code>.</p>"},{"location":"software/apps-and-envs/python/#managing-environments","title":"Managing Environments","text":"<p>With each Anaconda distribution, we have a small selection of widely used environments. Many, such as Tensorflow or DeepLabCut should be loaded through their modules (i.e., <code>module load tensorflow</code>), which automate the loading of other relevant libraries that are available as modules.</p> Midway2Midway3 <p>Store environments in project space, not home directory: <pre><code># Create environment in project space\nconda create --prefix=/project2/PI_NAME/USER/envs/myenv python=3.9\n\n# Or with uv (recommended for faster creation)\nmodule load uv\ncd /project2/PI_NAME/USER/envs\nuv venv myenv\n</code></pre></p> <p>Store environments in project space, not home directory: <pre><code># Create environment in project space\nconda create --prefix=/project/PI_NAME/USER/envs/myenv python=3.11\n\n# Or with uv (recommended for faster creation)\nmodule load uv\ncd /project/PI_NAME/USER/envs\nuv venv myenv\n</code></pre></p>"},{"location":"software/apps-and-envs/python/#2-environment-activation","title":"2. Environment Activation","text":"<p>For conda environments:</p> Midway2Midway3 <pre><code># Direct activation (long path)\nsource activate /project2/PI_NAME/USER/envs/myenv\n\n# Or create symlink for convenience\nln -s /project2/PI_NAME/USER/envs/myenv ~/.conda/envs/myenv\nsource activate myenv\n</code></pre> <pre><code># Direct activation (long path)\nsource activate /project/PI_NAME/USER/envs/myenv\n\n# Or create symlink for convenience\nln -s /project/PI_NAME/USER/envs/myenv ~/.conda/envs/myenv\nsource activate myenv\n</code></pre> <p>For uv environments:</p> Midway2Midway3 <pre><code>source /project2/PI_NAME/USER/envs/myenv/bin/activate\n</code></pre> <pre><code>source /project/PI_NAME/USER/envs/myenv/bin/activate\n</code></pre>"},{"location":"software/apps-and-envs/python/#3-environment-documentation","title":"3. Environment Documentation","text":"<p>Always document your environment:</p> <pre><code># For conda environments\nconda env export --from-history &gt; environment.yml\n\n# For uv environments\nuv pip freeze &gt; requirements.txt\n</code></pre>"},{"location":"software/apps-and-envs/python/#4-storage-management-tips","title":"4. Storage Management Tips","text":"<ol> <li> <p>Clean Unused Packages: <pre><code>mamba clean --all  # Remove unused package cache\n# or\nconda clean --all  \n</code></pre></p> </li> <li> <p>Use Project Space:</p> </li> </ol> Midway2Midway3 <pre><code># Set default env location\nexport CONDA_ENVS_PATH=/project2/PI_NAME/USER/envs\n</code></pre> <pre><code># Set default env location\nexport CONDA_ENVS_PATH=/project/PI_NAME/USER/envs\n</code></pre> <ol> <li> <p>Minimize Environment Size: <pre><code># Only specify needed packages\nmamba create -n myenv python=3.11 numpy pandas\n</code></pre></p> </li> <li> <p>Share Common Environments:</p> </li> </ol> Midway2Midway3 <pre><code># Create read-only group environment\nconda create --prefix=/project2/PI_NAME/shared_envs/analysis python=3.9\nchmod -R a-w /project2/PI_NAME/shared_envs/analysis\n</code></pre> <pre><code># Create read-only group environment\nconda create --prefix=/project/PI_NAME/shared_envs/analysis python=3.11\nchmod -R a-w /project/PI_NAME/shared_envs/analysis\n</code></pre>"},{"location":"software/apps-and-envs/python/#cloning-and-backing-up-environments","title":"Cloning and Backing Up Environments","text":"<p>If you want to copy an existing environment to modify it: <pre><code>conda create --prefix=/path/to/new/environment --clone &lt;EXISTING ENVIRONMENT&gt;\n</code></pre> If you want to make a clean environment, you can do that with <pre><code>conda create --prefix=/path/to/new/environment python=&lt;PYTHON VERSION NUMBER&gt;\n</code></pre></p> <p>To backup an environment to a YAML file: <pre><code># Minimal spec (portable): only packages you explicitly installed\nconda env export --from-history &gt; environment.yml\n\n# Full lockfile (exact builds; best reproducibility on the same platform)\nconda env export &gt; environment-full.yml\n</code></pre></p> <p>To recreate from a YAML file: <pre><code># Using minimal spec (resolver may choose newer builds)\nconda env create --prefix=/path/to/new/environment -f environment.yml\n\n# Using full lockfile (recreate exact builds when available)\nconda env create --prefix=/path/to/new/environment -f environment-full.yml\n</code></pre> Once your environment is set up how you want, especially if it is in your scratch space, you may want to create a backup of the environment into a YAML file. You do that after activating the environment with <code>conda env export &gt; environment.yml</code>. That YAML file can then be used to recreate the environment with <code>conda env create --prefix=/path/to/new/environment -f environment.yml</code>.</p> <p>Note</p> <p>Anaconda may sometimes cause issues with ThinLinc. If you are experiencing frequent, spontaneous disconnections from ThinLinc, remove any sections involving \"conda\" or \"anaconda\" from the file <code>~/.bashrc</code> (in your home directory).</p>"},{"location":"software/apps-and-envs/python/#managing-packages","title":"Managing Packages","text":""},{"location":"software/apps-and-envs/python/#default-domain-specific-environments","title":"Default domain-specific environments","text":"<p>The <code>python/miniforge-25.3.0</code> module comes with several pre-configured domain-specific environments. Each environment is optimized for a specific research domain. Here\u2019s a quick comparison:</p> Environment Activation command Best for Core packages / Tools sci <code>source activate sci</code> Scientific computing, data analysis numpy, scipy, pandas, matplotlib, seaborn, scikit-learn, JupyterLab, ipython, h5py, psutil ml <code>source activate ml</code> Deep learning, ML research tensorflow, pytorch, scikit-learn, keras, xgboost, lightgbm, matplotlib, seaborn bio <code>source activate bio</code> Genomics, bioinformatics biopython, samtools, bcftools, bedtools, fastqc, cutadapt, multiqc, pandas, scikit-bio geo <code>source activate geo</code> GIS, earth science gdal, rasterio, geopandas, cartopy, xarray, netcdf4, matplotlib, pyproj hpc <code>source activate hpc</code> Parallel/distributed computing mpi4py, dask, dask-jobqueue, joblib, ipyparallel, numpy, pandas <p>All environments include: - Python 3.x - Mamba for fast package management - Pip for additional package installation - Common development tools</p> <p>Choosing your environment</p> <p>Select the environment that matches your research domain to get started quickly. You can always install extra packages or create a custom environment based on these templates.</p>"},{"location":"software/apps-and-envs/python/#using-python","title":"Using Python","text":"<p>On Midway, <code>python</code> can be launched, after loading a desired module, at the terminal with the command:</p> <pre><code>python\n</code></pre> <p>To leave the launched interactive shell, use:</p> <p><pre><code>exit()\n</code></pre> or <pre><code>quit()\n</code></pre></p> <p>If you already have a python script, use this command to run it:</p> <pre><code>python your_script.py\n</code></pre>"},{"location":"software/apps-and-envs/python/#python-interactive-plotting","title":"Python Interactive Plotting","text":"<p>For interactive plotting, it is necessary to set the matplotlib backend to a graphical backend. Here is an example:</p> <pre><code>#!/usr/bin/env python\n!!! tip \"Quick Overview: Interactive Plotting\"\n    For interactive plotting on Midway, set matplotlib to a GUI backend. Prefer `QtAgg` (Qt5) or `TkAgg` when available. In Jupyter, you can also use `%matplotlib widget` or `%matplotlib inline` for non-GUI rendering.\n\nplt.plot([1,2,3,4])\nplt.ylabel('some numbers')\nplt.show()\n</code></pre> <pre><code>```python\n#!/usr/bin/env python\nimport matplotlib\nmatplotlib.use('QtAgg')  # or 'TkAgg' if Qt is unavailable\nimport matplotlib.pyplot as plt\nplt.plot([1, 2, 3, 4])\nplt.ylabel('some numbers')\nplt.show()\n```\n</code></pre> <pre><code>display -alpha off &lt;image&gt;\n</code></pre>"},{"location":"software/apps-and-envs/python/#running-jupyter-notebooks","title":"Running Jupyter Notebooks","text":"<p>Jupyter Notebook is a useful tool for python users because it provides interactive web-based computing. You can launch Jupyter Notebooks on Midway, open it in the browser on your local machine and have all the computation work done on Midway. If you want to perform heavy compute, you will need to start an interactive session before launching Jupyter notebook, otherwise you may use one of the login nodes.</p> <p>The steps to launch Jupyter are as follows:</p> <p>Step 1: Load the desired Python module. This can be done on a login node, or on a compute node via an interactive job or a batch job.</p> <p>Step 2: Determine the IP address of the host you are on. Whether you are on a login node or a compute node, you can use this command to get your IP address:</p> <p><pre><code>HOST_IP=`/sbin/ip route get 8.8.8.8 | awk '{print $7;exit}'`\necho $HOST_IP\n</code></pre> which can be either <code>128.135.x.y</code> (an external address), or <code>10.50.x.y</code> (on-campus address).</p> <p>Step 3: Launch Jupyter with:</p> Midway2Midway3 <p><pre><code>jupyter-notebook --no-browser --ip=$HOST_IP --port=15021\n</code></pre> or <pre><code>jupyter-lab --no-browser --ip=$HOST_IP --port=15021\n</code></pre></p> <p><pre><code>jupyter-notebook --no-browser --ip=$HOST_IP --port=15021\n</code></pre> or <pre><code>jupyter-lab --no-browser --ip=$HOST_IP --port=15021\n</code></pre></p> <p>where 15021 is an arbitrary port number rather than 8888. If there is a problem with the port already in use, your browser will complain. In that case, please try the another port with the flag <code>--port=&lt;port number&gt;</code>, or use the command <code>shuf</code>  to get a random number for the port: <pre><code>PORT_NUM=$(shuf -i15001-30000 -n1)\n</code></pre> and launch the Notebook server as earlier <pre><code>jupyter-notebook --no-browser --ip=$HOST_IP --port=$PORT_NUM\n</code></pre></p> <p>which will give you two URLs with a token, one with the external address <code>128.135.x.y</code>, and another with the on-campus address <code>10.50.x.y</code>, or  with your local host <code>127.0.0.*</code>.  The on-campus address <code>10.50.x.y</code> is only valid when you are connecting to Midway2 or Midway3 via VPN. The URLs would be something like</p> <p><pre><code>http://128.135.167.77:15021/?token=9c9b7fb3885a5b6896c959c8a945773b8860c6e2e0bad629\n</code></pre> or <pre><code>http://10.50.260.16:15021/?token=9c9b7fb3885a5b6896c959c8a945773b8860c6e2e0bad629\n</code></pre> or <pre><code>http://127.0.0.1:15021/?token=9c9b7fb3885a5b6896c959c8a945773b8860c6e2e0bad629\n</code></pre></p> <p>If you launch Jupyter Notebook on a compute node, the URLs with <code>10.50.x.y</code> and <code>127.0.0.1</code> are likely to be returned.</p> <p>If you do not specify <code>--no-browser --ip=</code>, the web browser will be launched on the node and the URL returned cannot be used on your local machine.</p> <p>Steps 1 through 3 can be done with a batch job as well. An example job script for launching Jupyter Notebook is given as below.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=jupyter-launch\n#SBATCH --account=pi-[cnetid]\n#SBATCH --output=output-%J.txt\n#SBATCH --error=error-%J.txt\n#SBATCH --time=04:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --mem=8GB\n\nmodule load python/anaconda-2021.05\n\ncd $SLURM_SUBMIT_DIR\n\nHOST_IP=`/sbin/ip route get 8.8.8.8 | awk '{print $7;exit}'`\nPORT_NUM=$(shuf -i15001-30000 -n1)\njupyter-notebook --no-browser --ip=$HOST_IP --port=$PORT_NUM\n</code></pre> <p>After submitting the job script and the job gets running with a job ID assigned, you can check the output log <code>output-[jobID].txt</code> to obtain the URLs.</p> <p>Step 4: Open a web browser on your local machine with the returned URLs.</p> <p>If you are using on-campus network or VPN, you can copy-paste (or <code>Ctrl</code> + click) the URL with the external address, or the URL with the on-campus address into the browser's address bar.</p> <p>Without VPN, you need to use SSH tunneling to connect to the Jupyter server launched on the Midway2 (or Midway3) login or compute nodes in Step 3 from your local machine. To do that, open another terminal window on your local machine and run</p> <p><pre><code>ssh -N -f -L 15021:&lt;HOST_IP&gt;:15021 &lt;your-CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre> where <code>HOST_IP</code> is the external IP address of the login node obtained from Step 2, and 15021 is the port number used in Step 3.</p> <p>This command will create an SSH connection from your local machine to Midway login or compute nodes and forward the 15021 port to your local host at port 15021. The port number should be consistent across all the steps (15021 in this example). You can find out the meaning for the arguments used in this command at explainshell.com.</p> <p>After successfully logging with 2FA as usual, you will be able to open the URL <code>http://127.0.0.1:15021/?token=....</code>, or equivalently, <code>localhost:15021/?token=....</code> in the browser on your local machine.</p> <p>Step 5: To kill Jupyter, go back to the first terminal window where you launch Jupyter Notebook and press <code>Ctrl+c</code> and then confirm with <code>y</code> that you want to stop it.</p>"},{"location":"software/apps-and-envs/python/#running-jupyterlab","title":"Running JupyterLab","text":"<p>JupyterLab is the next-generation IDE-like counterpart of Jupyter Notebook with more advanced features for data science, scientific computing, computational journalism, and machine learning. It has a modular structure that allows you to create and execute multiple documents in different tabs in the same window.</p>"},{"location":"software/apps-and-envs/r/","title":"R and RStudio","text":"<p>R is a powerful tool for quantitative research and data analysis across various fields. This document describes how to use R on the Midway clusters.</p>"},{"location":"software/apps-and-envs/r/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Available R Modules</li> <li>Using R for High-Performance Computing (HPC)</li> <li>Installing R Packages</li> <li>Using the renv Package for Reproducibility</li> <li>Best Practices</li> <li>FAQ</li> <li>Troubleshooting</li> </ul>"},{"location":"software/apps-and-envs/r/#introduction","title":"Introduction","text":"<p>R is a powerful tool for quantitative research and data analysis across a variety of fields. On the Midway clusters, R is available as centrally maintained modules, supporting both interactive and batch (HPC) workflows. This guide covers best practices for installing, configuring, and running R, including reproducibility and performance tips for both Midway2 and Midway3.</p>"},{"location":"software/apps-and-envs/r/#available-r-modules","title":"Available R Modules","text":"<p>To see the list of available R modules: <pre><code>module avail R\n</code></pre></p> <p>To check available RStudio IDE modules: <pre><code>module avail rstudio\n</code></pre></p> <p>When using RStudio, it is recommended to connect to the RCC cluster via ThinLinc for a smoother experience.</p> Midway3Midway2 <p>Available R Versions:</p> <ul> <li><code>R/3.6.3</code></li> <li><code>R/4.0.3</code></li> <li><code>R/4.1.0</code></li> <li><code>R/4.2.0</code></li> <li><code>R/4.2.1</code></li> <li><code>R/4.2.1-no-openblas</code> (built with default BLAS; no OpenBLAS/MKL acceleration)</li> <li><code>R/4.2.2</code></li> <li><code>R/4.2.3</code></li> <li><code>R/4.3.1</code></li> <li><code>R/4.4.1</code> (default)</li> <li><code>R/4.4.1+oneapi-2024.2.0</code> (Intel oneAPI build, see below)</li> <li><code>R/4.4.2+gcc-13.2.0</code> (built with GCC 13.2.0, see below)</li> </ul> Build Details (click to expand) <ul> <li>Most R modules are built with the system GCC compiler (<code>8.4.1</code>).</li> <li><code>R/4.2.1-no-openblas</code> is built with the default BLAS (no OpenBLAS or MKL), which may result in slower linear algebra performance.</li> <li><code>R/4.4.1+oneapi-2024.2.0</code> is built with Intel oneAPI 2024.2.0 and linked to Intel's Math Kernel Library (MKL). This provides maximum performance for matrix and linear algebra operations, leveraging the latest Intel hardware/software optimizations. The module automatically loads <code>oneapi/2024.2</code> and sets all relevant paths and environment variables for you. Use this if you need high-performance math.</li> <li><code>R/4.4.2+gcc-13.2.0</code> is built with GCC 13.2.0. Use this version if your R library requires a newer GCC toolchain (for example, the <code>arrow</code> package or other modern C++-dependent libraries).</li> </ul> <p>Geospatial Meta-Module: - There is a meta-module for geospatial applications: <code>gis/R-4.2.1</code>. Loading this module will automatically load <code>R/4.2.1</code> along with all required geospatial libraries (<code>GDAL</code>, <code>GEOS</code>, <code>PROJ</code>, <code>SQLite</code>, <code>udunits</code>) for spatial data analysis. This is the recommended setup for users working with spatial or GIS data on Midway3.</p> <p>AMD Node Module: - On Midway3 AMD nodes, there is a special module <code>R/4.3.2 (default)</code> built with the AMD Optimizing C/C++ Compiler (<code>aocc-4.1</code>). This module is found under <code>/software/modulefiles-amd</code> and is optimized for AMD hardware. Use this version for best performance on AMD compute nodes.</p> <p>Available R Versions:</p> <ul> <li><code>R/2.15</code></li> <li><code>R/3.0</code></li> <li><code>R/3.2</code></li> <li><code>R/3.3</code></li> <li><code>R/3.3+intel-16.0</code> (built with Intel 16 compiler)</li> <li><code>R/3.4</code></li> <li><code>R/3.4.1</code></li> <li><code>R/3.4.3</code></li> <li><code>R/3.5.1</code></li> <li><code>R/3.6.1</code></li> <li><code>R/3.6.3-no-openblas</code></li> <li><code>R/4.0.0</code></li> <li><code>R/4.0.4</code></li> <li><code>R/4.1.0</code></li> <li><code>R/4.1.0-no-openblas</code></li> <li><code>R/4.2.0</code></li> </ul> Build Details (click to expand) <ul> <li>Most R modules are built with the system GCC compiler (<code>10.2.0</code> for recent versions; older modules may use earlier GCC or Intel compilers).</li> <li><code>R/3.3+intel-16.0</code> is built with the Intel 16 compiler.</li> <li><code>R/3.6.3-no-openblas</code> and <code>R/4.1.0-no-openblas</code> use the default BLAS (no OpenBLAS), which may reduce linear algebra performance.</li> <li>Most modern modules (<code>R/4.1.0</code>, <code>R/4.2.0</code>) are built with <code>gcc/10.2.0</code>.</li> <li>All modules are linked to OpenBLAS for improved matrix and linear algebra performance unless otherwise noted.</li> <li>For exact dependencies and environment, use <code>ml show R/&lt;version&gt;</code>.</li> </ul>"},{"location":"software/apps-and-envs/r/#spatial-packages","title":"Spatial Packages","text":"<p>The <code>sf</code> package in R provides tools for handling spatial data using simple features. For more information, visit the sf Package on CRAN. The <code>terra</code> and <code>raster</code> packages are also installed.</p> <p>Midway2 Environment:</p> <ul> <li>Dependencies: GDAL 2.4.1, udunits 2.2</li> <li>R Version: 4.2.0</li> </ul> <p>Midway3 Environment:</p> <ul> <li>Dependencies: GDAL 3.3.3, udunits 2.2, GEOS 3.9.1, GCC 10.2.0, SQLite 3.36.0</li> <li>R Versions: 4.2.1 and 4.3.1</li> </ul> <p>Before using or installing <code>sf</code> on Midway3, load the necessary modules:</p> Midway2Midway3 <pre><code>module load gdal/2.4.1 udunits/2.2 R/4.2.0\n</code></pre> <pre><code>module load gdal/3.3.3 udunits/2.2 geos/3.9.1 gcc/10.2.0 sqlite/3.36.0 R/4.3.1\n</code></pre>"},{"location":"software/apps-and-envs/r/#using-r-for-high-performance-computing-hpc","title":"Using R for High-Performance Computing (HPC)","text":"<p>You can run R scripts in batch mode using SLURM. Example job script: <pre><code>#!/bin/bash\n#SBATCH --job-name=my_r_job\n#SBATCH --account=[your-accountname]\n#SBATCH --partition=compute\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=16G\n#SBATCH --time=02:00:00\n\nmodule load R/4.3.1\nRscript my_script.R\n</code></pre></p> Parallel R with MPI (Rmpi) <p>The <code>Rmpi</code> package is not pre-installed in system R modules. You must install it in your own R user library, and Rmpi must be compiled against the same MPI implementation and version you will use at runtime.</p> <p>Example SLURM Batch Script for Rmpi Job: <pre><code>#!/bin/bash\n#SBATCH --job-name=my_rmpi_job\n#SBATCH --account=[your-accountname]\n#SBATCH --partition=compute\n#SBATCH --nodes=1\n#SBATCH --ntasks=4\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=16G\n#SBATCH --time=02:00:00\n\nmodule load R/4.3.1 openmpi/5.0.2  # Example: use any available OpenMPI version\nmpirun -np 4 Rscript my_rmpi_script.R\n</code></pre></p> <p>Step-by-step instructions: 1. Load R and OpenMPI modules before installing Rmpi: <pre><code>module load R/4.3.1 openmpi/5.0.2  # Example: use any available OpenMPI version\nR\n</code></pre> 2. Install Rmpi from within R: <pre><code>install.packages(\"Rmpi\", type = \"source\")\n</code></pre>     You may be prompted for MPI library paths; the correct <code>openmpi</code> module must be loaded for detection. 3. Check installation: <pre><code>library(Rmpi)\nmpi.universe.size()\n</code></pre> 4. Important: Always load the same <code>openmpi</code> module before running your parallel R jobs as you did when installing Rmpi.</p> <p>Other OpenMPI Versions</p> <p>To see all installed OpenMPI versions, run: <pre><code>module avail openmpi\n</code></pre></p> <p>Version Compatibility</p> <ul> <li>The <code>openmpi</code> version must match between installation and job execution.</li> <li>If you change R or MPI module versions, reinstall <code>Rmpi</code> to match.</li> </ul>"},{"location":"software/apps-and-envs/r/#installing-r-packages","title":"Installing R Packages","text":"<p>R packages can be distributed as source code or compiled binaries. Source packages must be compiled before installation, typically requiring the GNU Compiler Collection (GCC). Here\u2019s how to get started with R package installation on our HPC clusters.</p>"},{"location":"software/apps-and-envs/r/#check-gcc-version","title":"Check GCC Version","text":"<p>To ensure compatibility, verify the version of GCC (g++) on your system:</p> <pre><code>$ g++ --version\ng++ (GCC) 8.5.0 20210514 (Red Hat 8.5.0-10)\nCopyright (C) 2018 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"software/apps-and-envs/r/#before-you-install","title":"Before You Install","text":"<ol> <li> <p>Check disk space:    Ensure you have enough disk space using the <code>quota</code> command:    <pre><code>$ quota\n</code></pre></p> </li> <li> <p>Load necessary modules:    For packages like <code>ncdf4</code> and <code>hdf5r</code>, load the required modules before starting R:    <pre><code>$ module load hdf5 netcdf\n</code></pre>    For more information on working with netCDF files in R, you can check out this resource: NetCDF with R. </p> </li> </ol>"},{"location":"software/apps-and-envs/r/#installing-packages","title":"Installing Packages","text":"<p>To install R packages, use the <code>install.packages</code> function within an R session:</p> <pre><code>install.packages(\"packageName\")\n</code></pre> <p>For multiple packages:</p> <pre><code>install.packages(c(\"package1\", \"package2\"))\n</code></pre>"},{"location":"software/apps-and-envs/r/#using-the-renv-r-package-to-create-a-personal-r-project-environment","title":"Using the <code>renv</code> R Package to Create a Personal R Project Environment","text":"<p>The <code>renv</code> package in R helps manage project-specific libraries, ensuring consistent package versions across projects. Here\u2019s a step-by-step guide to set up and use <code>renv</code> for your project located at <code>/project/pi-cnetid/rproject/</code> on the Midway cluster.</p>"},{"location":"software/apps-and-envs/r/#step-1-load-necessary-modules","title":"Step 1: Load Necessary Modules","text":"<p>Before starting, ensure you have the necessary modules loaded. You can load the R module appropriate for your project:</p> <pre><code>module load R/4.3.1\n</code></pre>"},{"location":"software/apps-and-envs/r/#step-2-set-up-the-project-directory","title":"Step 2: Set Up the Project Directory","text":"<p>Navigate to your project directory:</p> <pre><code>cd /project/pi-cnetid/rproject/\n</code></pre>"},{"location":"software/apps-and-envs/r/#step-3-initialize-renv-in-your-project","title":"Step 3: Initialize <code>renv</code> in Your Project","text":"<p>Start R and initialize <code>renv</code> in your project directory:</p> <pre><code>R\n</code></pre> <p>Inside the R session, run:</p> <pre><code># Install renv if not already installed\ninstall.packages(\"renv\")\n\n# Initialize renv in the project directory\nrenv::init()\n</code></pre> <p>This command will set up a new project-specific library in the <code>renv</code> subdirectory of your project directory and create an <code>renv.lock</code> file to record the state of your library.</p>"},{"location":"software/apps-and-envs/r/#step-4-install-packages-within-the-renv-environment","title":"Step 4: Install Packages within the <code>renv</code> Environment","text":"<p>With <code>renv</code> initialized, install any necessary packages:</p> <pre><code># Install required packages\nrenv::install(\"dplyr\")\nrenv::install(\"ggplot2\")\n# Add more packages as needed\n</code></pre>"},{"location":"software/apps-and-envs/r/#step-5-snapshot-the-current-state-of-your-library","title":"Step 5: Snapshot the Current State of Your Library","text":"<p>After installing the necessary packages, snapshot the current state of your library to <code>renv.lock</code>:</p> <pre><code>renv::snapshot()\n</code></pre> <p>This records the exact versions of the packages you have installed, allowing you to recreate the environment later.</p>"},{"location":"software/apps-and-envs/r/#step-6-restore-library-from-renvlock-optional","title":"Step 6: Restore Library from <code>renv.lock</code> (Optional)","text":"<p>If you need to recreate the environment on another system or after a system change, you can restore the library:</p> <pre><code>renv::restore()\n</code></pre> <p>This command reads the <code>renv.lock</code> file and installs the specified package versions.</p>"},{"location":"software/apps-and-envs/r/#step-7-using-the-project","title":"Step 7: Using the Project","text":"<p>Whenever you start working on your project, load the <code>renv</code> environment:</p> <pre><code># Activate the renv environment\nrenv::activate()\n</code></pre> <p>This ensures that all package installations and library paths are managed by <code>renv</code>.</p>"},{"location":"software/apps-and-envs/r/#example-workflow","title":"Example Workflow","text":"<p>Here\u2019s a complete example workflow from the terminal to R session:</p> <ol> <li> <p>Load R Module:    <pre><code>module load R/4.3.1\ncd /project/pi-cnetid/rproject/\n</code></pre></p> </li> <li> <p>Start R and Initialize <code>renv</code>:    <pre><code>R\n</code></pre></p> </li> <li> <p>Within R Session:    <pre><code>install.packages(\"renv\")\nrenv::init()\nrenv::install(\"dplyr\")\nrenv::install(\"ggplot2\")\nrenv::snapshot()\nq()  # Quit R session\n</code></pre></p> </li> <li> <p>Future Sessions:    <pre><code>renv::activate()\n</code></pre></p> </li> </ol> <p>By following these steps, you can set up and manage a project-specific R environment on the Midway cluster, ensuring consistency and reproducibility for your R projects.</p>"},{"location":"software/apps-and-envs/r/#best-practices","title":"Best Practices","text":""},{"location":"software/apps-and-envs/r/#r-modules","title":"R modules","text":"<ul> <li>Uses centrally maintained, optimized, and regularly updated R installations provided by HPC admins.</li> <li>Usually highly optimized (OpenBLAS).</li> <li>Integrates with system-wide libraries and supports <code>renv</code> for reproducibility.</li> <li>Recommended for most HPC users, especially for performance-critical or collaborative work.</li> </ul>"},{"location":"software/apps-and-envs/r/#r-via-conda","title":"R via Conda","text":"<ul> <li>Allows creation of isolated environments and user-space installation of R and dependencies.</li> <li>Performance Caveat: Conda R often does not use the highly optimized BLAS/LAPACK libraries available on the cluster, which can result in slower performance for linear algebra-intensive tasks.</li> <li>Use Conda R only if you need a specific version or package unavailable in system modules, or require full environment isolation.</li> <li>If using Conda R, you can still use <code>install.packages()</code> or <code>renv</code> within the environment, but be aware of possible compatibility and performance trade-offs.</li> </ul> Feature/Aspect R Module (Midway) Conda R BLAS/LAPACK Optimization Usually highly optimized (OpenBLAS) Often default/less optimized BLAS Performance Best for heavy computation May be slower for matrix operations Integration Well-integrated with system libraries Isolated, may miss system optimizations Reproducibility Use with <code>renv</code> or modules Use with <code>renv</code> or Conda YAML Use Case Recommended for most HPC users For custom/isolated needs only"},{"location":"software/apps-and-envs/r/#faq","title":"FAQ","text":"<ol> <li> <p>How can I delete all R packages and start over?    If you need to reset your R environment, delete all R packages and related files:    <pre><code>$ rm -rf ~/R ~/.R ~/.rstudio* ~/.Rhistory ~/.Rprofile ~/.RData\n</code></pre></p> </li> <li> <p>How can I show the location where R packages are installed?    <pre><code>.libPaths()\nSys.getenv(\"R_LIBS_USER\")\n</code></pre></p> </li> <li> <p>How can I list the installed packages:    <pre><code>installed.packages()\n</code></pre></p> </li> <li> <p>How can I list the default packages?    <pre><code>getOption(\"defaultPackages\")\n</code></pre></p> </li> <li> <p>How can I remove a package?    <pre><code>remove.packages(\"packageName\")\n</code></pre></p> </li> <li> <p>How do I delete all R packages and start over?    <pre><code>rm -rf ~/R ~/.R ~/.rstudio* ~/.Rhistory ~/.Rprofile ~/.RData\n</code></pre></p> </li> </ol>"},{"location":"software/apps-and-envs/r/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Package installation fails due to missing system libraries Load the necessary modules (e.g., <code>module load hdf5 netcdf</code>) before starting R R cannot find installed packages Check your <code>.libPaths()</code> in R and ensure you are using the correct environment/module R job runs slowly Use the system R module for optimized BLAS/LAPACK performance. Avoid Conda R for heavy computations unless necessary Permissions or disk quota exceeded Check your disk space with <code>quota</code> and clean up files if needed."},{"location":"software/apps-and-envs/singularity/","title":"Singularity","text":"<p>Singularity is a widely-adopted container runtime that implements a unique security model to mitigate privilege escalation risks and provides a platform to capture a complete application environment into a single file (SIF).</p>"},{"location":"software/apps-and-envs/singularity/#available-modules","title":"Available Modules","text":"<p>Singularity is available on and Midway3 that you can check via <code>module avail singularity</code>. It is recommended to load the latest version of <code>singularity</code> to have bugfixes and new features.</p> <pre><code>module load singularity/3.9.2\n</code></pre> <p>Since March 2022, Singularity has become a Linux Foundation project and renamed to Apptainer. You can load a version of Apptainer on Midway3: <pre><code>module load apptainer\n</code></pre> Apptainer and Singularity commands are highly compatible with each other. Apptainer also provides a <code>singularity</code>command to ensure that no changes needed in workflows that invoke the command.</p> <p>You can pull container Singularity and Docker container images from external sources to your spaces on the login nodes: <pre><code>singularity pull ubuntu.sif docker://ubuntu:latest\n</code></pre> and execute them on the compute nodes. You can bind and mount the paths on Midway to the containers at run time.</p> <p>There are instructions to use Singularity on Midway3 given here.</p>"},{"location":"software/apps-and-envs/singularity/#example-job-script","title":"Example job script","text":"<p>Suppose that you have pulled the image from the Internet (e.g. Docker Hub) to your folder on Midway3. In practice, you may want to bind mount the folders outside the container (e.g. where your input data is located and where output data is to be stored) with those inside the container. The following batch script illustrates a simple use case.</p> <p><pre><code>#!/bin/bash\n#SBATCH --job-name=test-singularity\n#SBATCH --nodes=1\n#SBATCH --time=05:00:00\n#SBATCH --account=pi-&lt;group&gt;\n#SBATCH --partition=caslake\n\nmodule load singularity/3.9.2\n\nsingularity exec --bind /path/outside/image/:/path/inside/image/ \\\n                 --bind $PWD:/run/user \\\n                 your_image.sif your_script.py arg1 arg2\n</code></pre> In this example, <code>/path/outside/image/</code> is the path in your Midway3 directory, e.g. <code>/project/[pi-cnetid]/your-folder/</code> and <code>/path/inside/image/</code> is the path inside the container, e.g. <code>/tmp/</code>. <code>$PWD</code> is the present working directory (on Midway3) and <code>/run/user</code> is the one present inside the container. The python script when executed inside the container will read input from <code>/path/inside/image</code> and generate output to <code>/run/user/</code>.</p>"},{"location":"software/apps-and-envs/singularity/#known-issues","title":"Known issues","text":"<p>By default, Singularity uses the <code>/tmp</code> directory on the local machine (whichever node or login node you are working on) to dump temporary and cache files generated during the build process. After a container is built, these are usually deleted. For containers with a large total size (more than a few GB), you may encounter an error <code>no space left on device</code></p> <p>If you encounter this issue, then it most likely means that <code>/tmp</code> got filled up on the machine you're using. To get around this issue, create <code>faketmp</code> and <code>fakecache</code> directories, and redirect Singularity's default temporary output to <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> <pre><code>export SINGULARITY_CACHEDIR=$SCRATCH/$USER/container/fakecache\nexport SINGULARITY_TMPDIR=$SCRATCH/$USER/container/faketmp\n</code></pre></p> <p>Apptainer builds need access to local storage rather than NFS storage. <pre><code>export APPTAINER_CACHEDIR=/tmp/$USER\nexport APPATINER_TMPDIR=/tmp/$USER\n</code></pre></p> <p>You can delete everything in the <code>faketmp</code> and <code>fakecache</code> directories after creation of your container.</p>"},{"location":"software/apps-and-envs/spark/","title":"Spark","text":"<p>Apache Spark is a fast and general engine for large-scale data processing.  It has a Scala, Java, and Python API and can be run either on either a single node or multi-node configuration. For both cases, it is recommended to have exclusive access of the node in Slurm.</p>"},{"location":"software/apps-and-envs/spark/#single-node-examples","title":"Single Node Examples","text":"<p>Here is the SparkPi and pi.py examples from the Spark distribution running on a single node:</p> <p>sbatch script <code>spark-single-node.sbatch</code></p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=spark\n# Exclusive mode is recommended for all spark jobs\n#SBATCH --exclusive\n#SBATCH --nodes=1\n#SBATCH --time=10\n\nmodule load spark\n\n# This syntax tells spark to use all cpu cores on the node.\nexport MASTER=\"local[*]\"\n\n# This is a scala example\nrun-example SparkPi\n\n# This is a python example. \n# For production jobs, you'll probably want to have a python module loaded.\n# This will use the system python if you don't have a python module loaded.\nspark-submit --master $MASTER $SPARK_HOME/examples/src/main/python/pi.py\n</code></pre>"},{"location":"software/apps-and-envs/spark/#multi-node-examples","title":"Multi-node Examples","text":"<p>For multi-node Spark jobs, a helper script was written to launch the master and work tasks in the slurm allocation. Here are the same examples as above, but with Spark running on multiple nodes:</p> <p>sbatch script <code>spark-multi-node.sbatch</code></p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=spark-multi-node\n# Exclusive mode is recommended for all spark jobs\n#SBATCH --exclusive\n#SBATCH --nodes=4\n#SBATCH --time=10\n\nmodule load spark\n\n# This command starts the spark workers on the allocated nodes\nstart-spark-slurm.sh\n\n# This syntax tells the spark workers where the master is\nexport MASTER=spark://$HOSTNAME:7077\n\n# This is a scala example\nrun-example SparkPi\n\n# This is a python example.\n# For production jobs, you'll probably want to have a python module loaded.\n# This will use the system python if you don't have a python module loaded.\nspark-submit --master $MASTER $SPARK_HOME/examples/src/main/python/pi.py\n</code></pre>"},{"location":"software/apps-and-envs/stata/","title":"Stata","text":"<p>Stata is a powerful statistical software package that is widely used in scientific computing. RCC users are licensed to use Stata on all RCC resources. Stata can be used interactively or as a submitted script. Please note that if you would like to run it interactively, you must still run it on a compute node, in order to keep the login nodes free for other users. Stata can be run in parallel on up to 16 nodes.</p> <p>NOTE: Stata examples in this document are adapted from a Princeton tutorial. You may find it useful if you are new to Stata or want a refresher.</p>"},{"location":"software/apps-and-envs/stata/#getting-started","title":"Getting Started","text":"<p>If you need to use the Stata GUI, connect to Midway with ThinLinc.</p> <p>Obtain an interactive session on a compute node. This is necessary so that your computation doesn\u2019t interrupt other users on the login node. Now, load Stata:</p> <pre><code>sinteractive\nmodule load stata\nxstata\n</code></pre> <p>This will open up a Stata window. The middle pane has a text box to enter commands at the bottom, and a box for command results on top. On the left there\u2019s a box called \u201cReview\u201d that shows your command history. The right-hand box contains information about variables in the currently-loaded data set.</p> <p>One way Stata can be used is as a fancy desktop calculator. Type the following code into the command box:</p> <pre><code>display 2+2\n</code></pre> <p>Stata can do much more if data is loaded into it. The following code loads census data that ships with Stata, prints a description of the data, then creates a graph of life expectancy over GNP:</p> <pre><code>sysuse lifeexp\ndescribe\ngraph twoway scatter lexp gnppc\n</code></pre>"},{"location":"software/apps-and-envs/stata/#running-stata-from-the-command-line","title":"Running Stata from the command line","text":"<p>This is very similar to running graphically; the command-line interface is equivalent to the \u201cResults\u201d pane in the graphical interface. Again, please use a compute node if you are running computationally-intensive calculations:</p> <pre><code>sinteractive\nmodule load stata\nstata\n</code></pre>"},{"location":"software/apps-and-envs/stata/#running-stata-jobs-with-slurm","title":"Running Stata Jobs with SLURM","text":"<p>You can also submit Stata jobs to SLURM, the scheduler. A Stata script is called a \u201cdo-file,\u201d which contains a list of Stata commands that the interpreter will execute. You can write a do-file in any text editor, or in the Stata GUI\u2019s do-file editor: click \u201cDo-File Editor\u201d\u201d in the \u201cWindow\u201d menu. If your do-file is named \u201cexample.do,\u201d you can run it with either of the following commands:</p> <pre><code>stata &lt; example.do\nstata -b do example.do\n</code></pre> <p>Here is a very simple do-file, which computes a regression on the sample data set from above:</p> <pre><code>version 13 // current version of Stata, this is optional but recommended.\n\nsysuse lifeexp\ngen loggnppc = log(gnppc)\nregress lexp loggnppc\n</code></pre> <p>Here is a submission script that submits the Stata program to the default queue on Midway:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=stataEx\n#SBATCH --output=stata_example.out\n#SBATCH --error=stata_example.err\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=1\n\nmodule load stata\n\nstata -b stata_example.do\n</code></pre> <p><code>stata_example.do</code> is our example do-file, and <code>stata_example.sbatch</code> is the submission script.</p> <p>To run this example, download both files to a directory on Midway.  Enter the following command to submit the program to the scheduler:</p> <pre><code>sbatch stata_example.sbatch\n</code></pre> <p>Output from this example can be found in the file named <code>stata_example.log</code>, which will be created automatically in your current directory.</p>"},{"location":"software/apps-and-envs/stata/#running-parallel-stata-jobs","title":"Running Parallel Stata Jobs","text":"<p>The parallel version of Stata, Stata/MP, can speed up computations and make effective use of RCC\u2019s resources. When running Stata/MP, you are limited to 16 cores and 5000 variables. Run an interactive Stata/MP session:</p> <pre><code>sinteractive\nmodule load stata\nstata-mp\n# or, for the graphical interface:\nxstata-mp\n</code></pre> <p>Here is a sample do-file that would benefit from parallelization. It runs bootstrap estimation on another data set that ships with Stata.</p> <pre><code>version 13\n\nsysuse auto\nexpand 10000\nbootstrap: logistic foreign price-gear_ratio\n</code></pre> <p>Here is a submission script that will run the above do-file with Stata/MP:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=stataMP\n#SBATCH --output=stata_parallel.out\n#SBATCH --error=stata_parallel.err\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=16\n\nmodule load stata\nstata-mp -b stata_parallel.do\n</code></pre> <p>Download <code>stata_parallel.do</code> and <code>stata_parallel.sbatch</code> to Midway, then run the program with:</p> <pre><code>sbatch stata_parallel.sbatch\n</code></pre>"},{"location":"software/apps-and-envs/tf-and-torch/","title":"Tensorflow and PyTorch","text":"<p>To use Tensorflow or PyTorch on Midway's GPU nodes, you may use an existing installation of either package provided as an Anaconda environment (see Python and Jupyter Notebook page), or install them into your own personal environment. </p> <p>Importantly, you must use an existing installation of CUDA and/or CuDNN, which you will first load via <code>module load cuda/&lt;version&gt;</code> or <code>module load cudnn/&lt;version&gt;</code> (which automatically loads cuda).</p> <p>Versions, versions, versions</p> <p>As of March 2023, we find the combination of module versions <code>python/anaconda-2021.05</code>, <code>cuda/11.2</code>, and <code>cudnn/11.2</code> to be the most stable. If wish to use newer versions of Python or CUDA, be sure to check the version compatibility as a first troubleshooting step when checking GPU engagement. </p> <p>With the CUDA module/s loaded, and being connected to a GPU node, you should be able to import either Tensorflow and PyTorch and check GPU engagment with the following steps: </p>"},{"location":"software/apps-and-envs/tf-and-torch/#gpu-enagement","title":"GPU Enagement","text":"<p>Here are a few quick tips on how to make sure you're actually using a GPU.</p>"},{"location":"software/apps-and-envs/tf-and-torch/#checking-in-terminal","title":"Checking in terminal","text":"<p>Before you even run your script, it can be useful to check to ensure that there are GPUs allocated to your jobs on the compute nodes.</p> <p>NVIDIA has a built in System Management Interface that makes this simple with one command: <pre><code> nvidia-smi\n</code></pre></p> <p>You should see details about the device, if it is detected.</p>"},{"location":"software/apps-and-envs/tf-and-torch/#tensorflow","title":"Tensorflow","text":"<p>Here's how to check if tensorflow sees your GPU/s. <pre><code>import tensorflow as tf\n</code></pre> The one-liner: <pre><code>print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n</code></pre> For more info: <pre><code>gpus = tf.config.experimental.list_physical_devices('GPU')\ntf.config.experimental.get_device_details(gpus[0])\n</code></pre></p>"},{"location":"software/apps-and-envs/tf-and-torch/#pytorch","title":"PyTorch","text":"<p>And here's how to check with PyTorch <pre><code>import torch\ntorch.cuda.device_count()\ntorch.cuda.get_device_name()\n</code></pre></p>"},{"location":"software/apps-and-envs/scode/api/","title":"<code>scode</code> Command-Line Tool \u2013 API Reference","text":"<p>This document provides a full API reference for <code>scode</code>, a command-line tool to manage and deploy VS Code Server environments on HPC clusters. This is intended for advanced users who want to understand all available subcommands, arguments, and behaviors.</p>"},{"location":"software/apps-and-envs/scode/api/#command-overview","title":"Command Overview","text":"<pre><code>scode &lt;command&gt; [subcommand] [options]\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#global-architecture","title":"Global Architecture","text":"<ul> <li>All VS Code environments and installations are managed under <code>~/.scode</code>.</li> <li><code>scode</code> uses SLURM (<code>sbatch</code>, <code>squeue</code>, <code>scancel</code>) to launch and manage VS Code Server jobs internally.</li> <li>Extensions are stored in environments under <code>~/.scode/envs</code>. A <code>default</code> environment is automatically created and activated when running commands that requires an active environment.</li> </ul>"},{"location":"software/apps-and-envs/scode/api/#commands-and-arguments","title":"Commands and Arguments","text":""},{"location":"software/apps-and-envs/scode/api/#serve-web-serve","title":"<code>serve-web</code> / <code>serve</code>","text":"<p>Launch a web-based VS Code Server using SLURM.</p> <pre><code>scode serve-web [--version &lt;version&gt;] [--env &lt;env&gt;] [--port &lt;port&gt;]\n[--port-range &lt;range&gt;] [--setup-command &lt;command&gt;] [--setup-script &lt;script&gt;] [--sbatch-file &lt;file&gt;] -- [sbatch args]\n</code></pre> <p>Arguments:</p> <ul> <li><code>--version</code>: Specific VS Code version to launch (default: <code>latest</code>)</li> <li><code>--env</code>: Environment name to activate or create (default: <code>default</code>)</li> <li><code>--port</code>: Port to bind the VS Code server. By default, <code>scode</code> will use a random port selected from the port range <code>49152-65535</code>. If both <code>--port</code> and <code>--port-range</code> are specified, <code>--port</code> will take precedence.</li> <li><code>--port-range</code>: Specify a range of ports to use, for example, <code>--port-range 3000-3100</code> (default: <code>49152-65535</code>)</li> <li><code>--setup-command</code>: Command to run before starting the VS Code server. This can be used to set up the environment, install dependencies, or perform any necessary pre-launch tasks. For example, <code>--setup-command \"module load python/anaconda-2023.09\"</code>.</li> <li><code>--setup-script</code>: Path to a custom setup script to run before starting the VS Code server.</li> <li><code>--sbatch-file</code>: Path to a custom SBATCH script file to use instead of the default. The SBATCH directives in this file will be used to configure the job submission, and the commands in the file will be executed before starting the VS Code server.</li> <li><code>--local</code>: Skip sbatch submission and launch the server directly as a subprocess in the current shell. Primarily intended for running inside compute nodes already allocated (e.g. via Open OnDemand). Also useful for debugging VS Code server behavior on login nodes or within <code>sinteractive</code> sessions.</li> <li><code>--</code>: All remaining arguments after the <code>--</code> separator are passed directly to <code>sbatch</code></li> </ul> <p>Example:</p> <pre><code>scode serve-web --version latest --env default -- --account rcc --time 01:00:00 --partition caslake\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#jobs","title":"<code>jobs</code>","text":"<p>Manage and inspect running server jobs.</p>"},{"location":"software/apps-and-envs/scode/api/#jobs-listlsl","title":"<code>jobs list/ls/l</code>","text":"<p>List active jobs:</p> <pre><code>scode jobs list\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#jobs-status-job_id","title":"<code>jobs status &lt;job_id&gt;</code>","text":"<p>Show detailed status and SSH tunnel instructions for a specific job:</p> <pre><code>scode jobs status 30317404\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#create","title":"<code>create</code>","text":"<p>Create a new environment.</p> <pre><code>scode create &lt;env_name&gt;\n</code></pre> <p>A <code>default</code> environment is created automatically when running commands that require an active environment.</p>"},{"location":"software/apps-and-envs/scode/api/#list-ls-l","title":"<code>list</code> / <code>ls</code> / <code>l</code>","text":"<p>List environments.</p> <pre><code>scode list\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#activate","title":"<code>activate</code>","text":"<p>Activate a named environment.</p> <pre><code>scode activate &lt;env_name&gt;\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#remove-rm-uninstall","title":"<code>remove</code> / <code>rm</code> / <code>uninstall</code>","text":"<p>Remove a named environment.</p> <pre><code>scode remove &lt;env_name&gt;\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#ext","title":"<code>ext</code>","text":"<p>Manage extensions.</p>"},{"location":"software/apps-and-envs/scode/api/#ext-install","title":"<code>ext install</code>","text":"<p>Install extensions by ID or from file.</p> <pre><code>scode ext install &lt;extension_id&gt;... [--env &lt;env&gt;] [--cli-version &lt;version&gt;] [--force]\nscode ext install --file/-f extensions.txt [--env &lt;env&gt;] [--cli-version &lt;version&gt;] [--force]\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#ext-listlsl","title":"<code>ext list/ls/l</code>","text":"<p>List installed extensions.</p> <pre><code>scode ext list [--env &lt;env&gt;] [--cli-version &lt;version&gt;]\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#ext-update","title":"<code>ext update</code>","text":"<p>Update all extensions.</p> <pre><code>scode ext update [--env &lt;env&gt;] [--cli-version &lt;version&gt;]\n</code></pre>"},{"location":"software/apps-and-envs/scode/api/#ext-uninstallrmremove","title":"<code>ext uninstall/rm/remove</code>","text":"<p>Remove one or more extensions.</p> <pre><code>scode ext uninstall &lt;extension_id&gt;... [--env &lt;env&gt;] [--cli-version &lt;version&gt;]\n</code></pre> <p>Notes:</p> <ul> <li>Extensions are installed in the environment directory under <code>~/.scode/envs/&lt;quality&gt;/&lt;env_name&gt;/extensions</code>.</li> <li>If you are serving a non-latest version of VS Code by specifying <code>--version</code> with <code>scode serve-web</code>, you may need to specify a matching <code>--cli-version</code> when installing extensions to ensure compatibility.</li> </ul>"},{"location":"software/apps-and-envs/scode/api/#download","title":"<code>download</code>","text":"<p>Manage VS Code versions. The <code>download</code> command is primarily designed for system administrators to download and cache VS Code tarballs.</p> <p>Users can also use this command to download specific versions of the VS Code Server for troubleshooting. Set the <code>SCODE_ARCHIVE_DIR</code> environment variable to specify a local directory for downloads.</p> <pre><code>scode download [options] [version]\n</code></pre> <p>Arguments:</p> <ul> <li><code>--target/-t [cli|web]</code>: Download CLI or Web version (defaults to both)</li> <li><code>--list/-l</code>: List available versions from upstream</li> <li><code>--latest/-n N</code>: Download latest N releases</li> <li><code>--versions/-v</code>: List locally downloaded versions</li> <li><code>--cleanup/-c</code>: Remove corrupt or incomplete downloads</li> </ul> <p>Examples:</p> <pre><code>scode download --list\nscode download --latest 1\nscode download 1.80.0 --target web\n</code></pre>"},{"location":"software/apps-and-envs/scode/environments/","title":"Managing <code>scode</code> Environments","text":"<p>This guide covers everything you need to create, switch between, and manage <code>scode</code> environments. These are lightweight, isolated workspaces stored in <code>~/.scode/envs/</code>, containing your VS\u202fCode Server extensions, user data, and cached assets.</p>"},{"location":"software/apps-and-envs/scode/environments/#1-what-is-an-scode-environment","title":"1\u202f\u202fWhat is an <code>scode</code> environment?","text":"<p>An <code>scode</code> environment is a directory at <code>~/.scode/envs/&lt;quality&gt;/&lt;name&gt;/</code> that contains:</p> <ul> <li>an <code>extensions/</code> folder for VS\u202fCode Server extensions</li> <li>a <code>data/</code> folder for user settings and server logs</li> </ul> <p>You can think of it as the VS\u202fCode equivalent of a Conda environment: create as many as you like, each with its own extensions and settings.</p> <p>In the environment path:</p> <ul> <li><code>&lt;quality&gt;</code> is either <code>stable</code> or <code>insiders</code> (currently, <code>scode</code> only support the <code>stable</code> version of VS Code).</li> <li><code>&lt;name&gt;</code> is the name for the scode environment, when you run a scode command that require a working <code>scode</code> environment (e.g., <code>scode serve</code> or <code>scode ext</code>), a default environment with the name <code>default</code> will be automatically created and activated.</li> </ul> <p>The <code>default</code> environment should be sufficient for most use cases. Custom environments, however, can help isolate extension sets. They are ideal for troubleshooting conflicts or separating projects by programming languages.</p>"},{"location":"software/apps-and-envs/scode/environments/#2-creating-your-first-scode-environment","title":"2\u202f\u202fCreating your first <code>scode</code> environment","text":"<pre><code># Create an custom `scode` env and have it activated globally\nscode create myenv\nscode activate myenv\n\n# Install extensions into the activated environment\nscode ext install ms-python.python ms-toolsai.jupyter\n\n# Launch VS\u202fCode Server using that env\nscode serve-web -- --account &lt;pi-account&gt; --time 01:00:00\n</code></pre> <ol> <li><code>scode create &lt;env_name&gt;</code> initializes a new environment under <code>~/.scode/envs/stable/&lt;env_name&gt;/</code>.</li> <li><code>scode activate &lt;env_name&gt;</code> sets it as the global default (persisted in <code>~/.scode/env-stable</code>).</li> <li><code>scode ext install \u2026</code> installs the specified extensions to the activated environment.</li> <li><code>scode serve-web</code> will launch the server with the extensions and user settings from the activated environment.</li> </ol>"},{"location":"software/apps-and-envs/scode/environments/#3-command-reference","title":"3\u202f\u202fCommand reference","text":""},{"location":"software/apps-and-envs/scode/environments/#31-scode-create","title":"3.1\u202f\u202f<code>scode create</code>","text":"<ul> <li>Usage: <code>scode create &lt;env_name&gt;</code></li> <li>Purpose: Create a fresh <code>scode</code> environment.</li> <li> <p>Behavior:</p> <ul> <li>Directory <code>~/.scode/envs/stable/&lt;env_name&gt;/</code> is created (quality defaults to stable).</li> <li>No VS\u202fCode binaries are installed yet. That happens lazily on first <code>serve-web</code>.</li> <li>Errors out if <code>&lt;env_name&gt;</code> already exists.</li> </ul> </li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#32-scode-activate","title":"3.2\u202f\u202f<code>scode activate</code>","text":"<ul> <li>Usage: <code>scode activate &lt;env_name&gt;</code></li> <li>Purpose: Activate and use an <code>scode</code> env globally.</li> <li> <p>Behavior:</p> <ul> <li>A plaintext file <code>~/.scode/env-&lt;quality&gt;</code> stores the environment  selection.</li> <li>Subsequent <code>scode</code> commands inherit this env unless an explicit <code>--env</code> overrides it.</li> </ul> </li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#33-scode-list","title":"3.3\u202f\u202f<code>scode list</code>","text":"<ul> <li>Usage: <code>scode list</code></li> <li> <p>Output example:</p> <pre><code>Local stable channel environments:\n   myenv\n*  default\n</code></pre> <p>An asterick <code>*</code> indicates the currently active environment.</p> </li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#34-scode-remove","title":"3.4\u202f\u202f<code>scode remove</code>","text":"<ul> <li>Usage: <code>scode remove &lt;env_name&gt;</code></li> <li>Purpose: Removes an <code>scode</code> env with all associated extensions and user data</li> <li>Behavior:<ul> <li>Recursively deletes the env directory.</li> <li>If an active environment is removed, the next available environment will be activated automatically.</li> </ul> </li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#4-using-environments-with-serve-web","title":"4\u202f\u202fUsing environments with <code>serve-web</code>","text":"<p>Both of the following examples starts a VS Code server with the <code>myenv</code> <code>scode</code> environment.</p> <ol> <li> <p>Inline: pass <code>--env &lt;name&gt;</code> every time</p> <pre><code>scode serve-web --env myenv -- --time 02:00:00 --account &lt;pi-account&gt;\n</code></pre> </li> <li> <p>Activate: permanently sets an environment as global default</p> <pre><code>scode activate myenv\nscode serve-web -- --time 02:00:00 --account &lt;pi-account&gt;\n</code></pre> </li> </ol> <p>Tip</p> <p>If you omit both <code>--env</code> and <code>activate</code>, <code>scode</code> falls back to the implicit <code>default</code> environment (created and activated on first use).</p>"},{"location":"software/apps-and-envs/scode/environments/#5-versioning-and-compatibility","title":"5\u202f\u202fVersioning and Compatibility","text":""},{"location":"software/apps-and-envs/scode/environments/#51-environment-isolation","title":"5.1\u202f\u202fEnvironment Isolation","text":"<p>Each <code>scode</code> environment is fully isolated. This means:</p> <ul> <li>Extensions, settings, and user data installed in one environment do not affect any other.</li> <li>All content lives under <code>~/.scode/envs/&lt;quality&gt;/&lt;name&gt;/</code>, keeping environments self-contained and reproducible.</li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#52-vs-code-version-decoupling","title":"5.2\u202f\u202fVS Code Version Decoupling","text":"<p><code>scode</code> environments are not bound to specific versions of VS Code. You can serve any environment with any supported VS Code version using:</p> <pre><code>scode serve-web --version &lt;vscode_version&gt; -- --account &lt;pi-account&gt;\n</code></pre> <p><code>scode</code> periodically downloads new VS Code builds into <code>$SCODE_ARCHIVE_DIR</code>. When you launch an environment, it locates the specified version from this archive, extracts it to <code>~/.scode/versions/&lt;quality&gt;/&lt;vscode_version&gt;</code>, and serves it from there.</p> <p>By default, the <code>--version</code> argument for <code>scode serve-web</code> is set to <code>latest</code>. This means <code>scode</code> will automatically pull and use the most recent VS Code version from the archive. This is the recommended behavior for most users.</p> <p>To view all VS Code versions currently available on the Midway cluster:</p> <pre><code>scode download --versions\n</code></pre> <p>This version decoupling gives you the flexibility to:</p> <ul> <li>Easily opt in or out of the latest VS Code versions.</li> <li>Test your environment across multiple editor versions.</li> <li>Ensure long-term reproducibility by explicitly pinning a specific VS Code version.</li> </ul>"},{"location":"software/apps-and-envs/scode/environments/#53-extension-compatibility","title":"5.3\u202f\u202fExtension Compatibility","text":"<p>While environments and VS Code versions are decoupled, extensions are typically tightly coupled to the VS Code version they were built for. Refer to the Extensions documentation for best practices.</p>"},{"location":"software/apps-and-envs/scode/environments/#7-troubleshooting","title":"7\u202f\u202fTroubleshooting","text":"<ol> <li> <p>Extensions missing after installation?</p> <p>Always verify that you're working in the correct environment by running <code>scode list</code>. Use the <code>--env</code> option to explicitly target a specific environment when installing extensions or serving VS Code. If you have created or switched to a new environment, you must re-install your extensions there.</p> </li> <li> <p>Disk quota exceeded in <code>$HOME</code>?</p> <p>This often occurs when too many environments or cached tarballs accumulate. Remove unused environments to free up space.</p> <p>Alternatively, you can move the <code>~/.scode</code> directory to <code>/scratch</code> and create a symbolic link back to your home directory:</p> <pre><code>mv ~/.scode /scratch/midway3/$USER/.scode\nln -s /scratch/midway3/$USER/.scode ~/.scode\n</code></pre> <p>This approach helps keep your home directory within quota limits.</p> </li> </ol>"},{"location":"software/apps-and-envs/scode/extensions/","title":"Managing Extensions in <code>scode</code>","text":"<p>This guide explains how to manage Visual Studio Code extensions in server-based VS Code environments launched with <code>scode</code>. Extensions are critical for productivity, and there are multiple ways to install them depending on your workflow.</p>"},{"location":"software/apps-and-envs/scode/extensions/#option-1-install-extensions-via-cli-recommended","title":"Option 1: Install Extensions via CLI (Recommended)","text":"<p>The easiest way to install extensions for the VS Code Server is via the <code>scode</code> CLI from a login node:</p> <pre><code>scode ext install ms-python.python ms-toolsai.jupyter\n</code></pre> <p>You can use the <code>--env</code> option to specify the environment name (e.g., <code>default</code>).</p> <p>To list environments or identify the current environment:</p> <pre><code>scode list\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#option-2-porting-extensions-from-an-existing-vs-code-installation","title":"Option 2: Porting Extensions from an Existing VS Code Installation","text":"<p>If you already have a working VS Code installation on your local machine, you can export and re-import them to your <code>scode</code> environment.</p>"},{"location":"software/apps-and-envs/scode/extensions/#step-1-export-locally","title":"Step 1: Export locally","text":"<p>On your local machine:</p> <pre><code>code --list-extensions &gt; extensions.txt\n</code></pre> <p>An example <code>extensions.txt</code> file might look like this:</p> <pre><code>ms-python.python\nms-toolsai.jupyter\nms-vscode.cpptools\n...\n</code></pre> <p>If you are using VS Code Insiders:</p> <pre><code>code-insiders --list-extensions &gt; extensions.txt\n</code></pre> <p>If you need specific versions of extensions, you can use <code>--show-versions</code> to include extension version numbers:</p> <pre><code>code --list-extensions --show-versions &gt; extensions.txt\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#step-2-upload-to-the-cluster","title":"Step 2: Upload to the cluster","text":"<p>You can manually copy the contents of <code>extensions.txt</code> to the Midway cluster using clipboard and <code>nano</code>.</p> <p>Alternatively, you can also use <code>scp</code> to copy the <code>extensions.txt</code> to your home directory:</p> <pre><code>scp extensions.txt &lt;yourusername&gt;@midway3.rcc.uchicago.edu:~\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#step-3-installing-extensions-from-a-text-file","title":"Step 3: Installing extensions from a text file","text":"<p>Running this command on a login node will install all extensions listed in the file, essentially replicating your local VS Code environment.</p> <pre><code>scode ext install -f extensions.txt\n</code></pre> <p>Note</p> <p>It is possible to create an <code>extensions.txt</code> manually. Extensions IDs such as <code>ms-python.python</code> and <code>ms-toolsai.jupyter</code> can be found on the VS Code Extension Marketplace.</p>"},{"location":"software/apps-and-envs/scode/extensions/#option-3-install-extensions-manually-via-the-vs-code-web-ui","title":"Option 3: Install Extensions Manually via the VS Code Web UI","text":"<p>This method is not recommended due to its complexity, but it can work as an expedient way for installing one or two extensions on the fly.</p>"},{"location":"software/apps-and-envs/scode/extensions/#step-1-download-the-extension-vsix-to-your-local-machine","title":"Step 1: Download the Extension (<code>.vsix</code>) To Your Local Machine","text":"<p>From a running <code>scode</code> session (if you already have the VS Code Server Web UI started with <code>scode</code>)</p> <ol> <li>Open your VS Code Web UI in the browser</li> <li>Go to the Extensions Panel</li> <li>Search for the desired extension</li> <li>Click the \"Install\" button. VS Code will complain that an internet error prevented a successful installation</li> <li>Click \"Try Downloading Manually...\" to download the <code>.VSIXPackage</code> file to your local machine</li> </ol> <p></p> <p>From your local machine (If you haven't had the Web UI set up with <code>scode</code>)</p> <ol> <li>Open the VS Code application on your local machine</li> <li>[Optional] Connect to the Midway cluster via SSH</li> <li>Go to the Extensions Panel (left sidebar)</li> <li>Search for the desired extension (e.g., <code>Python</code>, <code>Jupyter</code>)</li> <li>Right-click the extension and select \"Download VSIX\" to save the <code>.VSIXPackage</code> file locally</li> </ol> <p></p>"},{"location":"software/apps-and-envs/scode/extensions/#step-2-installing-the-vsix-file","title":"Step 2: Installing the <code>.vsix</code> file","text":"<p>Warning</p> <p>VS Code saves extension files as <code>.VSIXPackage</code> by default. You MUST rename the extension to <code>.vsix</code> in lowercase to make it installable from the Web UI.</p> <ol> <li>Open your VS Code Web UI in the browser</li> <li>Rename the <code>.VSIXPackage</code> file extension to <code>.vsix</code></li> <li>Go to the Extensions Panel (left sidebar)</li> <li>Click the three-dot menu (\u22ee) in the top-right corner of the panel</li> <li>Choose \"Install from VSIX...\"</li> <li>Click \"Show Local\" on the top right of the file selector</li> <li>Select the <code>.vsix</code> file from your local machine and wait for the installation to complete</li> </ol> <p></p>"},{"location":"software/apps-and-envs/scode/extensions/#extension-compatibility","title":"Extension Compatibility","text":"<p>While environments and VS Code versions are decoupled, extensions are typically tightly coupled to the VS Code version they were built for. This means:</p> <ul> <li>Extensions are compiled against specific versions of VS Code and may fail to load or behave incorrectly if used with an incompatible version.</li> <li>If you're always serving the latest VS Code version, extensions installed with <code>scode ext install</code> will generally work as expected.</li> <li> <p>If you're serving an older VS Code version, always install extensions with:</p> <pre><code>scode ext install --cli-version &lt;vscode_version&gt; &lt;extensions&gt;\n</code></pre> <p>This ensures version alignment between the extension and the editor runtime.</p> </li> <li> <p>If you are downgrading your VS Code version, it is recommended to uninstall and re-install all existing extensions before serving.</p> </li> </ul>"},{"location":"software/apps-and-envs/scode/extensions/#command-references","title":"Command references","text":""},{"location":"software/apps-and-envs/scode/extensions/#list-installed-extensions","title":"List installed extensions","text":"<pre><code>scode ext list\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#update-all-extensions","title":"Update all extensions","text":"<p>You can run the <code>update</code> command periodically to keep your extensions up to date:</p> <pre><code>scode ext update\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#uninstall-extensions","title":"Uninstall extensions","text":"<pre><code>scode ext uninstall ms-python.python ms-toolsai.jupyter\n</code></pre>"},{"location":"software/apps-and-envs/scode/extensions/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Extensions not appearing after installation?</p> <p>Always verify that you're working in the correct environment by running <code>scode list</code>. Use the <code>--env</code> option to explicitly target a specific environment when installing extensions or serving VS Code.</p> <p>If you installed new extensions while the VS Code server is running, you may need to run \u201cReload Window\u201d from the VS Code command palette or restart the <code>scode</code> job for the changes to take effect.</p> </li> <li> <p>Extension compatibility issues with older VS Code versions?</p> <p>If you are serving a non-latest version of VS Code using the <code>--version</code> flag with <code>scode serve-web</code>, make sure to use a matching <code>--cli-version</code> when installing extensions with <code>scode ext install</code>.</p> <p>It's generally recommended to use the latest available version of the VS Code Server unless it is absolutely necessary to use an older version.</p> </li> <li> <p>Need more help?</p> <ul> <li>Built\u2011in help: <code>scode --help</code> and <code>scode ext --help</code>.</li> <li>Refer to SCode API Documentation for more details.</li> </ul> </li> </ol>"},{"location":"software/apps-and-envs/scode/main/","title":"Getting Started with <code>scode</code>","text":"<p>To support the growing demand for interactive development on Midway, RCC provides <code>scode</code>: a command-line utility that allows users to securely launch, manage, and access Visual Studio Code (VS Code) web sessions running entirely on compute nodes from their browser.</p> <p><code>scode</code> addresses the challenge of setting up a VS Code session on compute nodes, which lack direct Internet access due to security considerations. It enables users to interactively develop, debug, and optimize HPC applications without the overhead of repeatedly submitting batch jobs, streamlining workflows such as model training, data analysis, and code prototyping.</p> <p></p> <p>This guide provides a minimal and reliable workflow to help you get started with a VS Code Web session, monitor its status, and connect securely from your local machine.</p> <p>To install extensions, see the Extension Installation Guide. For more information on using <code>scode</code>, please refer to the SCode API Documentation.</p>"},{"location":"software/apps-and-envs/scode/main/#quick-start","title":"\ud83d\ude80 Quick Start","text":"Step Description Command / Action Run On Step 1 Load <code>scode</code> &amp; install necessary extensions <code>module load scode</code> <code>scode ext install ms-python.python ms-toolsai.jupyter</code> \ud83d\udd10 Login Node Step 2 Launch VS Code Server <code>scode serve-web -- --account &lt;pi-account&gt; --time 01:00:00 --mem 16G</code> \ud83d\udd10 Login Node Step 3 Check job status &amp; get connection info <code>scode jobs status &lt;job_id&gt;</code> \ud83d\udd10 Login Node Step 4 Create SSH tunnel from your local machine Follow the SSH command printed in Step 3 \ud83d\udcbb Local Machine Step 5 Access VS Code in your browser Open the web link provided in Step 3 \ud83d\udcbb Local Machine Step 6 End the session <code>scancel &lt;job_id&gt;</code> \ud83d\udd10 Login Node"},{"location":"software/apps-and-envs/scode/main/#step-1-setting-up-scode","title":"Step 1: Setting Up <code>scode</code>","text":""},{"location":"software/apps-and-envs/scode/main/#step-11-loading-the-scode-module","title":"Step 1.1: Loading the <code>scode</code> Module","text":"<p>In order to run the <code>scode</code> command, first load the <code>scode</code> module from a login node:</p> <pre><code>module load scode\n</code></pre> <p>This will activate the <code>scode</code> command in your environment. You can add this command to your <code>~/.bashrc</code> or <code>~/.bash_profile</code> for automatically loading <code>scode</code> in future sessions.</p> <pre><code>echo \"module load scode\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc # Reload the shell configuration\n</code></pre> What is a <code>.bashrc</code> file? <p>The <code>.bashrc</code> file is your personal script that automatically configures your environment every time you open a new terminal.</p> File Name Scope When It\u2019s Executed Common Use Cases <code>/etc/bash.bashrc</code> System-wide For every user\u2019s interactive, non-login shell Set default aliases and functions for all users on the system. <code>~/.bashrc</code> User-specific For a user\u2019s interactive, non-login shells The main file for personal aliases, functions, and prompt customizations. <code>~/.bash_profile</code> User-specific For a user\u2019s login shell Set environment variables and run commands that only need to happen once per session. <code>~/.profile</code> User-specific Fallback for <code>~/.bash_profile</code> A more generic version that can be used by other shells, not just Bash. <p>For your day-to-day terminal customizations like aliases and prompt settings, <code>~/.bashrc</code> is the correct file to edit.</p>"},{"location":"software/apps-and-envs/scode/main/#step-12-bashrc-environment-setup","title":"Step 1.2: <code>~/.bashrc</code> Environment Setup","text":"<p>To use <code>scode</code> and other tools effectively in VS Code Server, It is recommended to have your environment correctly initialized by modifying your <code>~/.bashrc</code>.</p> <pre><code># ~/.bashrc\nexport MY_VAR=\"HelloWorld\"\nmodule load python/anaconda-2023.09\n</code></pre> <p>This will ensure that necessary environment variables and system modules such as <code>python</code>, <code>cuda</code> and <code>java</code> are available in both the terminal and within VS Code extensions.</p> <p>Tip</p> <p>VS Code Server automatically sources <code>~/.bashrc</code> at startup. A properly set up <code>~/.bashrc</code> can help:</p> <ul> <li> <p>VS Code <code>Python</code> extension to detect and use the correct <code>Python</code> versions.</p> </li> <li> <p>The integrated terminal to use your configured modules and environment variables.</p> </li> </ul>"},{"location":"software/apps-and-envs/scode/main/#step-13-install-necessary-vs-code-extensions","title":"Step 1.3: Install Necessary VS Code Extensions","text":"<p>To take full advantage of language features in VS Code (e.g., autocompletion, linting, Jupyter notebook support), you can install the relevant extensions using <code>scode</code> before starting the server.</p> <p>For instance, for Python developments, run the following command on the login node:</p> <pre><code>scode ext install ms-python.python ms-toolsai.jupyter\n</code></pre> <p>For more details, see the Extension Installation Guide.</p>"},{"location":"software/apps-and-envs/scode/main/#step-2-launch-a-vs-code-server","title":"Step 2: Launch a VS Code Server","text":"<p>Once the module is loaded, you can submit a job to start a VS Code Web server. Run the following command from a login node:</p> <pre><code>scode serve-web -- --account &lt;pi-account&gt; --time 01:00:00 --partition caslake --mem 16G\n</code></pre> <ul> <li><code>&lt;pi-account&gt;</code>: Replace this with the name of your Principal Investigator (PI) or course account. This account will be used to provision compute nodes in the specified partition.</li> <li>To view the accounts you are associated with and check available allocations, use <code>groups</code>, <code>accounts list</code> and <code>accounts balance</code>. Refer to the documentation for <code>groups</code> and <code>accounts</code> commandline utilities for more details.</li> <li>Additional slurm options can be added to the <code>scode serve-web</code> command after the standalone <code>--</code> separator. Refer to Slurm User Guide and Sbatch Documentation for more details on job submission options.</li> </ul> <p>This command will:</p> <ul> <li>Submit a SLURM job to run the VS Code Web server</li> <li>Prepare the environment and server installation automatically</li> <li>Return the job ID and logging paths</li> </ul> <p>Example output:</p> <pre><code>Submitting SBATCH to serve VS Code environment.\n\nSubmitted batch job 30317404\n\nsbatch: Verify job submission ...\nsbatch: Using a shared partition ...\nsbatch: Partition: caslake\nsbatch: QOS-Flag: caslake\nsbatch: Account: &lt;pi-account&gt;\nsbatch: Verification: ***PASSED***\n\nSBATCH job /home/&lt;yourusername&gt;/.scode/sbatches/scode-web_20250409_101953.sbatch submitted successfully.\nOutput will be directed to /home/&lt;yourusername&gt;/.scode/logs/scode-web_30317404.out.\nErrors will be directed to /home/&lt;yourusername&gt;/.scode/logs/scode-web_30317404.err.\nVS Code server is starting with Slurm Job ID 30317404.\nUse `scode jobs status 30317404` to check the status of the server.\nUse `scancel 30317404` to cancel the server job.\n</code></pre>"},{"location":"software/apps-and-envs/scode/main/#step-3-check-job-status","title":"Step 3: Check Job Status","text":"<p>To view active VS Code Server jobs, run the following command on the login node:</p> <pre><code>scode jobs list\n</code></pre> <p>To check the status of a specific job and retrieve connection details, use the job ID returned from the previous step:</p> <pre><code>scode jobs status 30317404\n</code></pre> <p>If the job is running, you will receive detailed connection instructions.</p> <p>Example output:</p> <pre><code>VS Code job 30317404 is running on 1 nodes: midway3-0024\nPrimary node: 10.50.250.24\nEnvironment: /home/&lt;yourusername&gt;/.scode/envs/stable/default\n\n\nTo connect to the VS Code Web GUI you need to create an SSH tunnel from your local machine to the primary node above. This can be done with the following command to be run on your local machine (e.g., PowerShell in Windows):\n\n    ssh -L 8000:10.50.250.24:61028 &lt;yourusername&gt;@midway3.rcc.uchicago.edu\n\nOnce the tunnel is created, you may access the VS Code Web GUI by entering the following address in your browser:\n\n    http://localhost:8000/?tkn=f1c72d89-4a5e-43d2-ae1b-9b8237dce021\n\nServer outputs are being written to /home/&lt;yourusername&gt;/.scode/logs/scode-web_30317404.out.\nServer errors are being written to /home/&lt;yourusername&gt;/.scode/logs/scode-web_30317404.err.\nYou may use `squeue -j 30317404` to see more information about this job, or cancel it with `scancel 30317404`.\n</code></pre> <p>In this output:</p> <ul> <li><code>8000</code> is a port on your local machine. All traffic to this port will be forwarded to the remote VS Code Web server with SSH tunnel. You can change this port if it is already in use.</li> <li><code>61028</code> is the port on the compute node where the VS Code Web server is running, which is randomly assigned by SCode.</li> <li>When running <code>scode jobs status 30317404</code>, scode will automatically fill in <code>&lt;yourusername&gt;</code> and the ssh endpoint for you (in this example, <code>midway3.rcc.uchicago.edu</code>), so that you can directly copy and run the tunnelling command in your local terminal.</li> </ul>"},{"location":"software/apps-and-envs/scode/main/#step-4-create-an-ssh-tunnel-from-your-local-machine","title":"Step 4: Create an SSH Tunnel from Your Local Machine","text":"<p>On your local machine, open another terminal, and run the SSH command shown in the job status output. For example:</p> <pre><code>ssh -L 8000:10.50.250.24:61028 &lt;yourusername&gt;@midway3.rcc.uchicago.edu\n</code></pre> <p>This command creates a secure channel between port <code>8000</code> on your local computer and the remote VS Code Web server running inside the cluster.</p> <ul> <li>Be sure to use the IP address and port number from your actual job output.</li> <li>Use a different local port if <code>8000</code> is already in use.</li> </ul> <p>Keep this terminal open while you are working inside the VS Code Web session. Closing the tunnel will interrupt your connection.</p>"},{"location":"software/apps-and-envs/scode/main/#step-5-access-vs-code-in-your-browser","title":"Step 5: Access VS Code In Your Browser","text":"<p>Once the SSH tunnel is active, open up a browser session on your local machine and follow the link from <code>scode jobs status</code>:</p> <pre><code>http://localhost:8000/?tkn=f1c72d89-4a5e-43d2-ae1b-9b8237dce021\n</code></pre> <p>Modify port <code>8000</code> if you used a different local port in Step 4.</p> <p>You will be redirected to a fully functional VS Code Web interface running on the cluster, within your compute environment.</p>"},{"location":"software/apps-and-envs/scode/main/#step-6-ending-the-session","title":"Step 6: Ending the Session","text":"<p>When you are done:</p> <ul> <li>Close the browser tab (to avoid dangling temp files in your home directory)</li> <li>Cancel the SLURM job:</li> </ul> <pre><code>scancel 30317404\n</code></pre> <p>If not manually cancelled, the job will terminate when the time limit expires.</p> <p>Now you can close the SSH tunnel terminal as well.</p>"},{"location":"software/apps-and-envs/scode/main/#troubleshooting","title":"Troubleshooting","text":"<ol> <li> <p>Why won\u2019t my SSH tunnel connect?</p> <ul> <li>Are you running the SSH command on your local machine?     The <code>ssh -L \u2026</code> command must be executed from your local computer, not inside the cluster.</li> <li>Connection refused errors:     If you see <code>channel x: open failed: connect failed: Connection refused</code>, try cancel and relaunch the VS\u202fCode Server job, then re-run the SSH tunnel command with the updated host/port from <code>scode jobs status &lt;job_id&gt;</code>.</li> </ul> </li> <li> <p>What if port 8000 is already in use?</p> <ul> <li> <p>Local port conflict:     By default, we forward <code>localhost:8000</code> \u2192 remote VS\u202fCode port. If <code>8000</code> is busy, choose another free port:     <code>ssh -L 9000:10.50.250.24:61028 &lt;yourusername&gt;@midway3.rcc.uchicago.edu</code></p> </li> <li> <p>Remember to update the browser URL to <code>http://localhost:9000/?tkn=\u2026</code>.</p> </li> </ul> </li> <li> <p>I see <code>ECONNREFUSED 127.0.0.1:9999</code> in the logs. Should I worry?</p> <ul> <li>No. <code>scode</code> uses a dummy <code>HTTP_PROXY</code> to bypass the VS Code Server update check. It prevents the server from hanging while looking for updates. You can safely ignore those warnings.</li> </ul> </li> <li> <p>Server details aren\u2019t shown when I run <code>scode jobs status</code> yet.</p> <ul> <li>Startup delay: The SBATCH job may still be booting.</li> <li>What to do: Wait 10\u201330\u202fseconds and rerun <code>scode jobs status &lt;job_id&gt;</code>, then inspect the Slurm output log at <code>~/.scode/logs/scode-web_&lt;job_id&gt;.out</code> for progress messages.</li> </ul> </li> <li> <p>Where can I get more help?</p> <ul> <li>Built\u2011in help: <code>scode --help</code> and <code>scode &lt;command&gt; --help</code>.</li> <li>Refer to SCode API Documentation for more details.</li> </ul> </li> </ol>"},{"location":"software/apps-and-envs/scode/python/","title":"Configuring Python for\u202f<code>scode</code>","text":"<p>This companion guide explains how to get a rock\u2011solid Python workflow inside a VS\u202fCode Web session launched with scode. You\u2019ll learn:</p> <ol> <li>Which VS\u202fCode extensions to install (and how to install them in one shot).</li> <li>How to load Python (and any supporting toolchains like CUDA or Java) before the server starts so they\u2019re visible to both VS\u202fCode integrated terminals and Jupyter kernels.</li> <li>How the VS\u202fCode Python extension discovers interpreters, and what that means for:<ul> <li>plain\u00a0<code>.py</code> files, and</li> <li>Jupyter notebooks.</li> </ul> </li> <li>Tips for refreshing kernels and troubleshooting interpreter\u2011detection quirks.</li> </ol>"},{"location":"software/apps-and-envs/scode/python/#quick-start","title":"\ud83d\ude80 Quick\u202fStart","text":"<pre><code># On the login node\nmodule load scode   # activate scode\nscode ext install ms-python.python ms-toolsai.jupyter # Install essential extensions\n\n# Launch a 2\u2011hour session with 16\u202fGB RAM and pre\u2011loaded Anaconda\n# Remove Anaconda module loading if you already have it loaded in your ~/.bashrc\nscode serve-web \\\n  --setup-command \"module load python/anaconda-2023.09 &amp;&amp; source activate base\" \\\n  -- --account &lt;pi-account&gt; --time 02:00:00 --mem 16G\n</code></pre>"},{"location":"software/apps-and-envs/scode/python/#1-installing-python-extensions","title":"1\u202f\u202fInstalling Python Extensions","text":"<p>Run this on the login node after <code>module load scode</code> but before launching the server.</p> <pre><code>scode ext install ms-python.python ms-toolsai.jupyter\n</code></pre> <p>These extensions provide essential support for Python development and interactive notebooks:</p> <ul> <li><code>ms-python.python</code> adds language features like IntelliSense, linting, debugging, and environment management for Python.</li> <li><code>ms-toolsai.jupyter</code> enables support for running Jupyter notebooks within the editor, including code execution and rich outputs.</li> </ul> <p>More extensions be found on the VS Code Extension Marketplace.</p> <p>Extensions are cached in <code>~/.scode/envs/stable/&lt;env&gt;/extensions/</code> by default, so subsequent sessions will start with the extensions you have previously installed.</p> <p>Make sure to periodically run <code>scode ext update</code> to keep your extensions up to date.</p>"},{"location":"software/apps-and-envs/scode/python/#2-environment-setup-tips","title":"2\u202f\u202fEnvironment Setup\u202f&amp; Tips","text":"<p>Jupyter kernels started within VS Code Web inherits the shell environment of the VS Code Server. So it is recommended to have the Python environment configured before starting the VS Code server with <code>scode</code>.</p> <p>Two reliable patterns keep Python (and friends like CUDA or\u202fJava) on the PATH for both VS Code\u202fintegrated terminals and Jupyter kernels:</p>"},{"location":"software/apps-and-envs/scode/python/#21-persistent-environment-setup-via-bashrc-recommended","title":"2.1\u202f\u202fPersistent Environment Setup via\u00a0<code>~/.bashrc</code> (Recommended)","text":"<p>Add your module\u2011load and activation commands to <code>~/.bashrc</code> so they run for every interactive shell (including <code>scode</code> jobs):</p> <pre><code># ~/.bashrc\nmodule load python/anaconda-2023.09\n\n# Optional extras your notebooks might need:\nmodule load cuda/12.6\nmodule load java/17.0.10 # Required by PyArrow\n\n# Conda base env on PATH so VS Code sees *all* `conda env list` interpreters\nsource activate base\n</code></pre>"},{"location":"software/apps-and-envs/scode/python/#22-perjob-tweaks-with-setup-command","title":"2.2\u202f\u202fPer\u2011job Tweaks with\u00a0<code>--setup-command</code>","text":"<p>If you need occasional, per\u2011session tweaks without touching your <code>~/.bashrc</code>, pass a setup command directly to <code>scode</code>:</p> <pre><code>scode serve-web \\\n  --setup-command \"module load python/anaconda-2023.09 &amp;&amp; source activate base\" \\\n  -- --account &lt;pi-account&gt; --time 01:00:00 --mem 16G\n</code></pre> <p>This runs just before the VS\u00a0Code Server starts, ensuring both the server and any kernels it spawns see the right environment.</p> <p>Why so early?</p> <p>Jupyter kernels are spawned as subprocesses of the VS\u202fCode server. If you load modules after the server starts, kernels won\u2019t inherit them. We have to restart the server (the whole job) to pick up changes.</p>"},{"location":"software/apps-and-envs/scode/python/#3-choosing-an-interpreter-and-how-vs-code-finds-them","title":"3\u202f\u202fChoosing An Interpreter (and How VS\u202fCode Finds Them)","text":"<p>According to Microsoft\u2019s search order, the Python extension probes these locations on the server host:</p> Search location Typical Midway scenarios Make sure\u2026 Virtual envs in the workspace or\u202f<code>$HOME</code>  (created via <code>python -m venv venv</code>, <code>pipenv</code>, etc.) Project\u2011specific venv under your repo  Venvs created in <code>/scratch</code> and symlinked under <code>$HOME</code> The folder contains <code>bin/python</code> and lives inside the workspace or\u202f<code>$HOME</code> Conda envs from\u00a0<code>conda env list</code> Anaconda module on Midway (<code>python/anaconda-*</code>) You loaded the module and activated <code>base</code>, so <code>conda</code> is on PATH Sub\u2011folders of\u00a0<code>python.venvPath</code> Central directory of many virtual envs Set <code>\"python.venvPath\": \"/path/to/venvs\"</code> in Settings (JSON)"},{"location":"software/apps-and-envs/scode/python/#31-plain-py-files","title":"3.1\u202f\u202fPlain\u00a0<code>.py</code> Files","text":"<p>VS Code Command Palette (<code>Ctrl+Shift+P</code>) \u2192 Python: Select Interpreter \u2192 pick any interpreter the VS Code Python extension found (or browse to one).</p> <p>You can also click and open the interpreter selector in the far-right corner of the bottom status bar when a <code>.py</code> file is opened.</p> <p>See Microsoft VS Code Python documentation for detailed instructions on selecting Python interpreters for <code>.py</code> files.</p>"},{"location":"software/apps-and-envs/scode/python/#32-jupyter-notebooks","title":"3.2\u202f\u202fJupyter Notebooks","text":"<p>The kernel\u2011picker lists only interpreters VS\u202fCode already knows about. You can\u2019t type an arbitrary path. Ensure the desired venv/Conda env is discoverable according to the table above before opening the notebook, then choose it in the top\u2011right Select Kernel dropdown.</p>"},{"location":"software/apps-and-envs/scode/python/#4-refreshing-environments-kernels","title":"4\u202f\u202fRefreshing Environments &amp; Kernels","text":""},{"location":"software/apps-and-envs/scode/python/#41-running-py-in-integrated-terminals","title":"4.1\u202f\u202fRunning <code>.py</code> in Integrated Terminals","text":"<p>Changes to your shell environment (e.g., your <code>~/.bashrc</code>) are picked up by newly reopened integrated terminals immediately. There's no need to restart the VS\u202fCode Server.</p> Change you made What to do... Edited <code>~/.bashrc</code> or added <code>module load \u2026</code> lines Run <code>source ~/.bashrc</code>, or reopen a terminal tab to get the updated environment Created a new venv/Conda env inside the running job Activate it in the terminal (e.g. <code>source venv/bin/activate</code>) Installed new Python packages into the active env Ready to use immediately"},{"location":"software/apps-and-envs/scode/python/#42-jupyter-notebooks","title":"4.2\u202f\u202fJupyter Notebooks","text":"<p>Notebook kernels are spawned by the VS\u202fCode Server process and inherit its environment at startup. To pick up environment changes such as an updated <code>~/.bashrc</code>, you must either refresh VS\u202fCode\u2019s environment list or restart the entire server job.</p> Change you made What to do... Edited <code>~/.bashrc</code> or added <code>module load \u2026</code> lines Terminate the VS\u202fCode Server job (<code>scancel \u2026</code>) and relaunch Created a new venv/Conda env inside the running job Python: Refresh Environment List or reload the VS\u202fCode window Installed new Python packages into the active env Restart the notebook kernel"},{"location":"software/apps-and-envs/scode/python/#5-troubleshooting","title":"5\u202f\u202fTroubleshooting","text":"<ol> <li> <p>Why is my Python version not listed?</p> <ul> <li>Run <code>which python</code> in an integrated terminal: is it the one you expect?</li> <li>Check that the venv contains a <code>bin/python</code> and isn\u2019t empty.</li> <li>Verify <code>conda env list</code> shows your env (if using Conda).</li> </ul> </li> <li> <p>Notebook kernel stuck on \u201cStarting\u201d?</p> <ul> <li>The env might miss <code>ipykernel</code>; run <code>python -m pip install ipykernel</code>.</li> <li>Double\u2011check that the env\u2019s <code>python</code> is executable on the compute node.</li> </ul> </li> <li> <p>Modules (e.g., CUDA) missing inside notebook but present in terminal?</p> <ul> <li>You probably loaded them after launching the server. Pre\u2011load in <code>~/.bashrc</code> and restart the job.</li> </ul> </li> <li> <p>Still lost?</p> <ul> <li>View VS\u202fCode\u2019s Python and Jupyter output channels (<code>\u2318/Ctrl+Shift +U</code>).</li> <li>Refer to the Microsoft VS Code Python documentation for more details.</li> </ul> </li> </ol>"},{"location":"ssh/advance/","title":"Advanced SSH options","text":"<ul> <li> <p>File sharing: </p> <p>Sharing files within the RCC clusters ecosystem using the command line and understanding file/folder permissions and data privacy. </p> </li> <li> <p>Helpful SSH arguments (X11 forwarding, etc.) </p> </li> <li>Advanced access control via ACL</li> </ul>"},{"location":"ssh/advance/#x11-forwarding","title":"X11 forwarding","text":"<p>X11 forwarding is a mechanism that allows you to forward a remote application's display (from clusters) to your local machine (client). To enable X11 forwarding when connecting to an RCC cluster system through SSH, the <code>-Y</code> flag should be included, for example:      <pre><code>ssh -Y &lt;CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre></p> Note for macOS users <p>The program XQuartz is required to enable trusted X11 forwarding on a Mac.</p>"},{"location":"ssh/advance/#file-permissions-and-ownership","title":"File permissions and ownership","text":"<p>Linux divides file permissions into read (<code>r</code>), write (<code>w</code>), and execute (<code>x</code>) permission categories. </p> Letter Name More detail <code>r</code> read Read permission allows to view or copy file contents to an external directory. <code>w</code> write In addition to all of the <code>r</code>, write permission allows modification of file content. <code>x</code> execute Execute permission allows us to run/execute files in the directory. <p>These three permissions are defined for each of the three owner types typically referred to as User (<code>u</code>), Group (<code>g</code>), and Others (<code>o</code>). </p> Letter Name More detail <code>u</code> user User is a single user who owns the file. <code>g</code> group Group is a collection of users who can access the file. <code>o</code> other Consists of all the users on the system. <p>Note</p> <p>Only the file owner or a directory can change its permissions or the group name to one of their groups.</p> <p>For example, here, we want to check the file access permissions of <code>myfile.dat</code>, by running the <code>ls -l</code> command: </p> <p><pre><code>$ ls -l myfile.dat\n</code></pre> we get:  <pre><code>-rw-r--r-- 1 jdoe pi-drpepper 8444 Feb 20 12:49 myfile.dat\n</code></pre> Here is how we interpret the symbols on the left. First, we break it into four parts:  <code>-</code> <code>rw-</code> <code>r--</code> <code>r--</code> </p> <p><code>- (part 0)</code> <code>rw- (part 1)</code> <code>r-- (part 2)</code> <code>r-- (part 3)</code> </p> <ul> <li><code>rw- (part 1)</code> means the file owner (<code>jdoe</code>) can read and modify (write) this file. </li> <li><code>r-- (part 2)</code> means the group members of <code>pi-drpepper</code> can only read this file but not modify it. </li> <li><code>r-- (part 3)</code> means others who are not even part of the group also can read this file. </li> </ul> <p> </p>"},{"location":"ssh/advance/#data-sharing","title":"Data sharing","text":"<p>To set up user permissions to a folder recursively, you can run the following command in the absolute mode, providing three permission bits for the User (7), Group (5), and Others (5):  <pre><code>$ chmod -R 755 myfolder\n</code></pre> where 7=4+2+1 (<code>rwx</code> for User), 5=4+0+1 (<code>r-x</code> for Group), and 5=4+0+1 (<code>r-x</code> for Others). This is equivalent to the following command in a symbolic mode:  <pre><code>$ chmod -R u=rwx,go=rx myfolder\n</code></pre> where, unlike the absolute mode, users can override (<code>=</code>), add (<code>+</code>), or remove (<code>-</code>) all or selected permissions for the owner (<code>u</code>), group (<code>g</code>), or others (<code>o</code>).</p> <p>Summary of the default file system permission of the most commonly used directories on RCC clusters:</p> Directory Permissions Permissions bits <code>$HOME</code> drwx------ <code>700</code> \u2013 Accessible only to the owner <code>$SCRATCH</code> drwx------ <code>700</code> \u2013 Accessible only to the owner <code>/project/drpepper</code> drwxrws--- <code>770</code> \u2013 Read/write for the project group <code>/project2/drpepper</code> drwxrws--- <code>770</code> \u2013 Read/write for the project group <code>/dali/drpepper</code> drwxrws--- <code>770</code> \u2013 Read/write for the project group <p>When new files or directories are created, the <code>umask</code> influences the default permissions of those files and directories.  The default value of <code>umask</code> is set to <code>0002</code>, which means that newly created files will have permissions of 664 (<code>-rw-r--r--</code>) and newly created directories will have permissions of 775 (<code>drwxrwxr-x</code>). </p> <p>In your home directory, the group owner will be set to your personal user group, the same as your CNetID, so you will still be the only user to access your files and directories. </p> <p>Note that in the project directories, the group owner will be the same as the directory owner, and the default permission of 2775 (<code>drwxrwsr-x</code>, read <code>d</code> <code>rwx</code> <code>rws</code> <code>r-x</code>). Here, the extra bit <code>2</code> will replace group permission <code>x</code> with <code>s</code> to enable users to execute the folder/files with the same permissions as the group owner. </p> <p>Here is an example of what this means in practice:</p> <pre><code>$ ls -ld $HOME \ndrwx------ 108 jdoe jdoe 32768 2013-01-15 10:51 /home/jdoe\n</code></pre> <pre><code>$ ls -ld /project/drpepper\ndrwxrws---  3 drpepper      pi-drpepper 32768 2013-01-15 10:48 /project/drpepper\n</code></pre> <p>Let's check this with an example. Using <code>touch</code>, we create two identical files, one in our home and the other under <code>drpepper</code>'s project directory.  <pre><code>$ touch $HOME/newfile /project/drpepper/newfile\n</code></pre></p> <p>Now, let's compare the permissions of these two files:  <pre><code>$ ls -l /project/rcc/newfile $HOME/newfile\n-rw-rw-r-- 1 jdoe jdoe          0 2023-01-01 00:00 /home/jdoe/newfile\n-rw-rw-r-- 1 jdoe pi-drpepper 0 2023-01-01 00:00 /project/drpepper/newfile\n</code></pre></p> <p>Both files are readable and writable by the group owner due to the default <code>umask</code>, but the group owners differ due to the sticky bit being set on <code>/project/drpepper</code>. This applies only to newly created files and directories. The ownership and permission may change if files or directories are moved from elsewhere.</p> <p>To change the permission of a directory, you can use <code>chgrp -R</code>: </p> <p><pre><code>$ chgrp -R pi-drpepper myfolder\n</code></pre> This will overwrite the group permissions of all of the files and folders under <code>myfolder</code> directory.  <pre><code>$ ls -l myfolder\n-rwxrwxr-x 1 jdoe pi-drpepper 0 Feb 20 12:49 myfile.dat\n-rwxrwxr-x 1 jdoe pi-drpepper 0 Feb 20 12:51 myfile2.dat\n</code></pre></p> <p>Warning</p> <p>If you need our help to overwrite the file permission of a directory, please reach out to us. Remember, the account owner can ask for this only for files under <code>/home</code> and <code>/scratch</code>; only PIs can request this for files under their group-shared directories. </p>"},{"location":"ssh/advance/#advanced-access-control-via-acl","title":"Advanced access control via ACL","text":"<p>Note</p> <p>ACL is only available on Midway2.</p> <p>Access control list (ACL) provides an additional, more flexible permission mechanism for file systems. It is designed to assist with UNIX file permissions. ACL allows you to give permissions to any disk resource for any user or group. For more information, please visit the ACL manual here.</p> <p>The default Linux file permission management covered in the previous section only supports the permissions at the owner/group/others level. ACL provides more precise control over any data (files or directories) customizable for individual users or groups. Before applying ACL to your data, please read and understand the following caveats. </p> <ul> <li> <p>By default, no ACL is set for user data. ACL provides a highly flexible permission control but also increases user access and management complexity. PIs normally want to share an entire project folder with all group members; for this, the Linux-based permissions are enough. We suggest that users implement ACL controls only when necessary. One example is to protect confidential data in the project space by allowing only certain users to access confidential directories or files.</p> </li> <li> <p>After ACL is set, Linux-based and ACL permissions will work together as a dual-guard system. The final effective access to data is granted only if permitted by both mechanisms. For example, if a folder is group-accessible to a user by Linux-based permission but restricted by ACL, the user cannot access this folder.</p> </li> <li> <p>Be sure you have enough knowledge setting up access via Linux-based permissions and ACL, i.e., you understand what \u201cusers\u201d, \u201cgroups,\u201d and each attribute in <code>rwx</code> mean and how to use them. Otherwise, please contact our Help Desk for assistance managing your data access. We are here and happy to help you set up the permissions to keep your data safe and accessible as required.</p> </li> </ul>"},{"location":"ssh/advance/#sharing-folders-with-a-user-within-a-group","title":"Sharing folders with a user within a group","text":"<p>Suppose there is a folder tree as below, and you want to allow the folder <code>my_folder</code> to be accessible by the user <code>drwho</code> only, and <code>drwho</code> is already a member of your group <code>drpepper</code>:</p> <pre><code>/project2/drpepper\n   |- my_folder\n   |- other_stuff\n</code></pre> <p>Before using ACL, you need to confirm that this folder is open to all members in the group <code>drpepper</code>:</p> <p><pre><code>$ cd /project2/drpepper\n$ chgrp -R pi-drpepper my_folder\n</code></pre> And,  <pre><code>$ cd /project2\n$ chmod -R 770 drpepper\n$ cd drpepper\n</code></pre></p> <p>By this steo, the folder <code>drpepper</code> becomes readable and writable by all members of group <code>pi-drpepper</code>. Then, you can use the <code>setfacl</code> command to control the individual user's access precisely. First, you need to remove the default group access by ACL:</p> <pre><code>$ setfacl -m g::--- my_folder\n</code></pre> <p>Although the command <code>ls -l</code> will still display group <code>rwx</code> access for the <code>my_folder</code> folder in the Linux-based permissions, users cannot access it anymore due to the permission set by ACL. Then, you can grant the user <code>drwho</code> access to the folder:</p> <pre><code>$ setfacl -m u:drwho:rwx my_folder\n</code></pre> <p>At this step, the user <code>drwho</code> has both read and write permissions to the folder <code>my_folder</code>. You can set up permissions for each user the way you want.</p> <p>To view the list of configured accesses on the folder <code>my_folder</code>, run:</p> <pre><code>$ getfacl my_folder\n# file: my_folder\n# owner: drwho\n# group: pi-drpepper\nuser::rwx\nuser:drwho:rwx\ngroup::---\nmask::rwx\nother::---\n</code></pre> <p>To revoke the permissions of the user <code>drwho</code> to the folder:</p> <pre><code>$ setfacl -x u:drwho my_folder\n</code></pre> <p>To clean up (remove) all ACL controls to the folder:</p> <pre><code>$ setfacl -b my_folder\n</code></pre>"},{"location":"ssh/advance/#sharing-folders-with-a-user-outside-a-group","title":"Sharing folders with a user outside a group","text":"<p>Suppose you would like to share your folder <code>/project2/drpepper/my_own_folder/shared_data</code> with another RCC user with CNetID <code>drj</code>, who is not in your group <code>pi-drpepper</code>. As the folder owner, you can execute the following two commands. <pre><code>setfacl -Rm d:u:drj:rw-,u:drj:rw- /project2/drpepper/my_own_folder/shared_data\nsetfacl -m u:drj:--x /project2/drpepper/my_own_folder\n</code></pre> The first command changes the ACL permission of the folder (and recursively its sub-folders and files) to allow the user <code>drj</code> to read and write. The second command adds execute permission to <code>drj</code> so that <code>drj</code> can access the parent folder <code>/project2/drpepper/my_own_folder</code> without read or write permissions. </p>"},{"location":"ssh/advance/#mobaxterm","title":"MobaXterm","text":"<p>Once the MobaXterm client is installed on your local machine, open the MobaXterm client and click on the Sessions icon at the upper left-hand corner of the client. Then, perform the following numbered steps, illustrated in the figure below, to establish a connection to RCC clusters. </p> <ol> <li>Click the SSH tab to expand the SSH login options.</li> <li>In the Remote host field input, please check this table for the cluster's host address. </li> <li>Select the Specify username button and input your CNetID</li> <li>Proceed to log in by clicking the OK button. </li> </ol> <p> </p> <p>Provide your CNetID password when prompted for a password. A Duo two-factor authentication window will then pop up, requesting you select from the 2FA options to authenticate.</p> <p> </p>"},{"location":"ssh/advance/#ssh-key-pairing","title":"SSH Key Pairing","text":"<p>ONLY members of the <code>pi-lgrandi</code> group (for the XENON experiment) can use SSH key pairing to connect to RCC servers.</p> <p>To set up SSH key pairing:</p> <p>1. Create your public key: Run the following command on your computer to generate a public key. (Replace <code>&lt;cnetid&gt;</code> with your CNetID.) Be sure you are not connected to an RCC server when you run the command; you want your public key associated with your local system, so RCC login nodes can use it to recognize your computer.</p> <pre><code>ssh-keygen -f ~/.ssh/&lt;cnetid&gt; -t rsa -b 4096\n</code></pre> <p>When you run this command in your shell (Mac terminal, Windows PowerShell, etc.), you will get a message specifying where your key has been saved. For example:</p> <p><pre><code>Your identification has been saved in /Users/&lt;local-user&gt;/.ssh/&lt;cnetid&gt;\nYour public key has been saved in /Users/&lt;local-user&gt;/.ssh/&lt;cnetid&gt;.pub\n</code></pre> Note that the <code>.</code> in <code>.ssh</code> indicates a hidden folder, so you will need to show hidden items to see your <code>&lt;cnetid&gt;.pub</code> file. You can do this from your shell (run <code>ls -la</code>) or your file explorer (press <code>command</code> + <code>shift</code> + <code>.</code> on Mac or select View &gt; Hidden items on Windows).</p> <p>2. Share your public key: Now that you have generated your public key, share it with the RCC so we can add it to our login nodes. Send help@rcc.uchicago.edu an email with the following information:</p> <ul> <li>Your CNetID</li> <li>Your public key (attach your <code>&lt;cnet&gt;.pub</code> file to the email OR copy/paste the contents of the file into the body of the email)</li> <li>Which RCC cluster you would like to connect to with SSH key pairing: Midway2, Midway3, or DaLI</li> </ul> <p>An RCC staff member will add your public key to the appropriate login nodes.</p>"},{"location":"ssh/faq/","title":"Connecting to Midway FAQ","text":""},{"location":"ssh/faq/#what-login-shells-are-supported-and-how-do-i-change-my-default-shell","title":"What login shells are supported and how do I change my default shell? \"","text":"<p>RCC supports the following shells: <pre><code>/bin/bash\n/bin/tcsh\n/bin/zsh\n</code></pre> Use this command to change your default shell: <pre><code>chsh -s /path/to/shell \n</code></pre></p> <p>It may take up to 30 minutes for that change to take effect.</p>"},{"location":"ssh/faq/#is-remote-access-with-mosh-supported","title":"Is remote access with Mosh supported? \"","text":"<p>Yes. To use Mosh, first log in to Midway via SSH, and add the command module load mosh to your <code>~/.bashrc</code> (or <code>~/.zshenv</code> if you use zsh). Then, you can log in by entering the following command in a terminal window:</p> Midway2 <pre><code>mosh &lt;CNetID&gt;@midway2.rcc.uchicago.edu \n</code></pre> Midway3 <pre><code>mosh &lt;CNetID&gt;@midway3.rcc.uchicago.edu\n</code></pre>"},{"location":"ssh/faq/#why-am-i-getting-ssh_exchange_identification-read-connection-reset-by-peer-when-i-try-to-log-in-via-ssh","title":"Why am I getting \u201cssh_exchange_identification: read: Connection reset by peer\u201d when I try to log in via SSH? \"","text":"<p>You can get this error if you incorrectly enter your password too many times. This is a security measure that is in place to limit the ability for malicious users to use brute force SSH attacks against our systems.</p> <p>After 3 failed password entry attempts, an IP address will be blocked for 4 hours.</p> <p>While you wait for the block to be lifted, you should still be able to access the RCC system using ThinLinc.</p>"},{"location":"ssh/faq/#why-am-i-getting-prompted-for-yubikey-when-i-try-to-log-in-via-ssh","title":"Why am I getting prompted for YubiKey when I try to log in via SSH? \"","text":"<p>There are few reasons to get that error message. Please enroll in two factor authentication if you have not done already by visiting https://cnet.uchicago.edu/2FA/. Please make sure you run:</p> Midway2 <pre><code>ssh -Y CNetID@midway2.rcc.uchicago.edu \n</code></pre> Midway3 <p><pre><code>ssh -Y CNetID@midway3.rcc.uchicago.edu\n</code></pre> Finally, please make sure your RCC account has not expired.</p>"},{"location":"ssh/main/","title":"SSH (Secure shell)","text":"<p>In this article, step-by-step, we review the process \"SSH\"ing to RCC's clusters so you know what is happening. </p>"},{"location":"ssh/main/#connecting-to-rcc-clusters-through-ssh","title":"Connecting to RCC clusters through SSH","text":"<p>There are countless 3rd party SSH clients for Windows, Mac, Linux (all flavors), Android, Chromebook, etc.  SSH client means an application installed on your computer/phone that can connect your computer (client) to RCC clusters (host) through SSH protocol.  Microsft Windows, Apple Mac Computers, and all flavors of Linux come with a preloaded SSH (native) SSH client.  Here, we focus on connecting to RCC clusters using these native clients if you are a pro user, consider using other 3rd party, more robust SSH clients (e.g. iTerm2, Termius, etc.) </p> <p>Apple Macintosh (Mac)</p> <p>Macintosh machines, through the \"terminal,\" can access the system's native SSH client app. Click on \"launchpad,\" then search and open the \"terminal\" app. </p> <p> </p> <p>Microsft Windows (10 and 11) Through the \"Windows PowerShell,\" Windows machines can access the system's native SSH client app. Click on the \"start\" menu, then search and open the \"Windows PowerShell\" app. </p> <p> </p> <p>!!! note Windows users running a version older than Windows 10\u2019s April 2018 release will have to download a 3rd party SSH client to connect via SSH. We recommend a free version of Termius SSH client. </p> <p>Now that we have \"terminal\" or \"PowerShell\" open. We can SSH to RCC clusters. </p> <p>The general format of the command to connect to an SSH host is this: </p> <p><code>ssh &lt;username&gt;@&lt;hostname&gt;</code> </p> <p>Here, instead of <code>username</code>, type in your <code>CNetID</code>, and <code>hostname</code>, depending on the cluster you need to connect, use one of the following SSH host addresses: </p>"},{"location":"ssh/main/#ssh-host-addresses","title":"SSH host addresses","text":""},{"location":"ssh/main/#shared-clusters","title":"Shared clusters","text":"Host name SSH host address Midway2 <code>midway2.rcc.uchicago.edu</code> Midway3 <code>midway3.rcc.uchicago.edu</code> Midway3-AMD <code>midway3-amd.rcc.uchicago.edu</code> DaLI <code>dali-login.rcc.uchicago.edu</code>"},{"location":"ssh/main/#restricted-clusters","title":"Restricted clusters","text":"Cluster's host name SSH host address Beagle3 <code>beagle3.rcc.uchicago.edu</code> SSD <code>ssd.rcc.uchicago.edu</code> <p>Note: For the family of <code>MidwayR</code> clusters, please check the MidwayR user guide. </p> <p>For example, to SSH to Midway3, we type in  <code>ssh jdoe@midway3.rcc.uchicago.edu</code> and then press <code>enter</code> on Windows or <code>return</code> on Apple keyboards. </p> <p>If this is your first time signing into a particular RCC cluster using your computer, the SSH client will ask, <code>Are you sure you want to continue connecting?</code>. Type <code>yes</code> and press the 'enter' button on your keyboard. </p> <p>Then, we get a prompt to enter our CNetID <code>password</code>. Note, as you type in your password, no character or other symbol will appear, but it is alright; type in your password and press <code>enter</code> on Windows or <code>return</code> on Apple keyboards. </p> <p>Then, the Duo's multi-factor authentication (MFA) prompt asks a few questions. </p> <p> </p> <p>After Duo's multi-factor authentication (MFA), you land on one of the many RCC's login nodes. <code>CNetID@clusterName-loginNodeNumber</code> </p> <p>Note</p> <p>See Advanced SSH options to read more about different arguments you can add to your SSH commands. </p>"},{"location":"ssh/main/#login-nodes","title":"Login nodes","text":"<p>Login nodes are the \"foyer\" of the RCC's clusters. They are connected to the Internet and enable you to transfer data to and from the system. They are not designed to carry out heavy workloads, and you should NOT run your computation on the login nodes. To connect to compute nodes to do computationally intensive work, there is one more step you need to go through.  x</p> <p> </p> <p>Warning</p> <p>The login nodes are NOT for computationally intensive work.  </p> <p>Note</p> <p>Login nodes have a small storage space for users to store a very small volume of data required for back-end processes such as authentication and other system-related processes upon logging in. Login nodes are not a storage space to save and install our packages. </p> <p>Note</p> <p>In compliance with the University of Chicago security guidelines, 2FA is required with limited exceptions. If you believe you have a justifiable need for SSH key-based authentication (only PIs), please contact our helpdesk and describe your situation. Once your request is received, the RCC security team will review it, and we will follow up with you as soon as possible. </p> <p>Note</p> <p>There are 2 or more login nodes on each cluster to share the workload from all the login users. You can land on one of the login nodes depending on their workload conditions at the time. You may choose to log in to a specific login node, e.g. <code>midway2-login2.rcc.uchicago.edu</code>, but it is typically discouraged.</p>"},{"location":"ssh/main/#compute-nodes","title":"Compute nodes","text":"<p>Compute nodes are designed to perform computationally intensive work. There is no Internet access on these nodes. To perform calculations or run simulations on the compute nodes, you need to submit job scripts to the queue via the <code>sbatch</code> command or via the <code>sinteractive</code> command to log into the allocated nodes  directly. More information is given in this page. </p>"},{"location":"ssh/main/#storage-nodes","title":"Storage nodes","text":"<p>Storage nodes generally store all files and folders under users' home, scratch, and PI's group project directories. To learn more about how storage nodes are interconnected to compute nodes and across RCC clusters (Midway2, 3, Beagle, DaLi, etc.), check this page. </p>"},{"location":"ssh/main/#data-transfer","title":"Data transfer","text":""},{"location":"ssh/main/#scp-secure-copy-protocol","title":"SCP - secure copy protocol","text":"<p>To copy files and folders from your personal computer (client) to RCC clusters (host) through SSH protocol, we use the following command, known as <code>SCP</code> (secure copy protocol.)</p> <p>Open <code>Terminal</code> (Macintosh) or <code>Windows Powershell</code> (Windows)</p> <p><code>scp &lt;sourceFile&gt; &lt;CNetID&gt;@&lt;hostAddress&gt;:&lt;targetPath&gt;</code></p> <p>Example 1-a: Copying a single file from Jane's personal computer (client) to Dr. Pepper's <code>project</code> directory:</p> <p><code>scp test.txt jdoe@midway3.rcc.uchicago.edu:/project/drpepper/users/jdoe/</code></p> <p>Example 1-b: Copying a single file from Jane's personal computer (client) to her <code>home</code> directory:</p> <p><code>scp test.txt jdoe@midway3.rcc.uchicago.edu:/home/jdoe/Documents/</code></p> <p>Example 2-a: Copying a directory (collection of files) from Jane's personal computer (client) to Dr. John's <code>project</code> directory:</p> <p><code>scp -r tests jdoe@midway3.rcc.uchicago.edu:/project/drpepper/users/jdoe/</code></p> <p>On MacOS, you need to add <code>-O</code> if there is no folder with the same name on the target server:</p> <p><code>scp -O -r tests jdoe@midway3.rcc.uchicago.edu:/project/drpepper/users/jdoe/</code></p> <p>Example 2-b: Copying a directory (collection of files) from Jane's personal computer (client) to her <code>home</code> directory:</p> <p><code>scp -r tests jdoe@midway3.rcc.uchicago.edu:/home/jdoe/Documents/</code></p> <p>After pressing <code>enter</code> on your keyboard, the rest is the same as logging into RCC clusters through SSH. </p>"},{"location":"ssh/main/#sftp-ssh-file-transfer-protocol","title":"SFTP - SSH file transfer protocol","text":"<p>SFTP is another SSH-based file transfer protocol that provides access, transfer, and management over any reliable data stream. RCC clusters support SFTP, and we strongly recommend this protocol for transferring data to/from RCC clusters. Termius SSH client, also supports SFTP. </p> <p> </p> <p> Termius </p>"},{"location":"ssh/main/#rsync","title":"Rsync","text":"<p>Rsync is a fast and versatile file transfer tool that keeps track of progress and the differences between the source and destination. There are many optimizations under the hood that make rsync tranfer files faster compared to <code>scp</code>. More information on the <code>rsync</code> command can be found at the rsync man page.</p> <p>Example 1: Copy/synchronize folder <code>tests</code> from Midway3 to your current directory</p> <p><code>rsync -avzhe ssh jdoe@midway3.rcc.uchicago.edu:/home/jdoe/Documents/tests .</code></p> <p>Example 2: Copy/synchronize folder <code>tests</code> from your current directory to Midway3</p> <p><code>rsync -avzhe ssh tests jdoe@midway3.rcc.uchicago.edu:/home/jdoe/Documents/</code></p>"},{"location":"storage/faq/","title":"Data Management FAQ","text":""},{"location":"storage/faq/#how-much-storage-space-do-i-have-leftused","title":"How much storage space do I have left/used?","text":"<p>Keep track of your storage usage by logging into Midway clusters and running the <code>quota</code> command. This handy tool on the Midway 2 and 3 ecosystems provides you with all the corresponding information you need.</p>"},{"location":"storage/faq/#im-over-quota-expired-quota-what-do-i-do","title":"I'm over quota (expired quota); what do I do?","text":"<p>If you find yourself over quota (expired quota), fret not! Follow these steps to get back on track:</p> <p>Identify whether your quota is expired due to the number of files (<code>files</code>) or total file size (<code>blocks</code>). If it's due to the number of files, consider zipping some files to count as one, rather than a large set of small files. If your quota is expired due to file size:</p> <ol> <li>If <code>/home</code> is expired, move your files to <code>/scratch</code> or <code>/project/drpepper</code>. Some users may also utilize <code>/dali/drpepper</code>, <code>/beagle3/drpepper</code>, <code>/cds/drpepper</code>, <code>/cds2/drpepper</code>, or <code>/cds3/drpepper</code>.</li> <li>If <code>/scratch</code> is expired, relocate your files to <code>/project/drpepper</code>. Similarly, some users may utilize <code>/dali/drpepper</code>, <code>/beagle3/drpepper</code>, <code>/cds/drpepper</code>, <code>/cds2/drpepper</code>, or <code>/cds3/drpepper</code>. Alternatively, delete unnecessary files.</li> <li>Request your PI to submit a research allocation request to obtain more storage. If the standard research allocation is insufficient, consider supplemental research allocation for temporary storage expansion.</li> <li>Ask your PI to purchase additional storage via the cluster partnership program.</li> </ol>"},{"location":"storage/faq/#why-cant-i-write-files-into-my-home-directory","title":"Why can't I write files into my home directory?","text":"<p>Encountering errors while writing files typically indicates that you're over-quota. Ensure that you're within quota limits in terms of both size and number of files using the <code>quota</code> command.</p>"},{"location":"storage/faq/#how-do-i-increase-my-storage-quota","title":"How do I increase my storage quota?","text":"<p>Expand your storage capacity through the Cluster Partnership Program. Alternatively, request additional storage as part of a Research II Allocation or Special Allocation.</p>"},{"location":"storage/faq/#how-do-i-share-files-with-others","title":"How do I share files with others?","text":"<p>Option 1: Globus Explore the Globus section of this user guide for comprehensive insights into file sharing via Globus.</p> <p>Option 2: Advanced access control via ACL Refer to the user guide section on <code>Advanced access control via ACL</code> for detailed instructions.</p> <p>Option 3: Allow them to join your RCC group Direct individuals to fill out the form for group access. Keep in mind that this grants access to all your <code>/project</code> files and compute resources, making it an all-encompassing choice for file sharing.</p>"},{"location":"storage/faq/#i-accidentally-deleted-or-lost-a-file-how-do-i-restore-it","title":"I accidentally deleted or lost a file. How do I restore it?","text":"<p>The most effective method for file recovery involves utilizing snapshots. Navigate through this user guide for details on <code>snapshots</code>.</p>"},{"location":"storage/faq/#unlocking-access-to-files-under-project-for-departed-users","title":"Unlocking access to files under <code>/project</code> for departed users","text":"<p>Have you stumbled upon files in <code>/project</code> belonging to a former UChicago member? No worries! We've got you covered. Simply shoot us an email at help@rcc.uchicago.edu with the precise path to the directories in question. Don't forget to include the PI's information for approval. We'll handle the rest and get you access in no time! </p>"},{"location":"storage/main/","title":"System Layout","text":"<p>Midway2,  Midway3, and Beagle3 have a high-performance GPFS shared file system that houses private home directories, shared project, project2, and beagle3 spaces, and high-performance scratch space. The shared and scratch directories of Midway2, Midway3, and Beagle3 are 'cross-mounted', meaning that they are accessible from system-specific login and compute nodes. However, <code>/home</code>, <code>/software</code>, and <code>/snapshots</code> are specific to each cluster and their respective login nodes.</p> <p> </p> <p>Folder Access</p> <p>You and you alone have access to your personal home directory (<code>/home/&lt;CNetID&gt;</code>), whereas everyone who is a member of your research group (<code>pi-&lt;PI_CNetID&gt;</code>) has access to your project folder (<code>/project/&lt;PI CNetID&gt;</code>).</p>"},{"location":"storage/main/#quotas","title":"Quotas","text":"<p>The amount of data that can be stored in home directories, project directories, and shared scratch directories is controlled by quota. RCC enforces hard and soft limits on quotas. A soft quota can be exceeded for a short period of time, called a grace period.  The hard quota cannot be exceeded under any circumstances. </p> Midway2, DaLIMidway3, Beagle3CDS Name Location Soft Quota Hard Quota Suitable For Home <code>/home/$USER</code> 30 GB  (or 300K files) 35 GB  (or 1M files) Personal data Project <code>/project2/&lt;folder&gt;</code> varies varies Shared data, environments Scratch <code>/scratch/midway2/$USER</code> 100 GB  (or 10M files) 5 TB  (or 20M files) Temporary files DaLI <code>/dali/&lt;folder&gt;</code> varies varies Shared data, environments Name Location Soft Quota Hard Quota Suitable For Home <code>/home/$USER</code> 30 GB  (or 300K files) 35 GB  (or 1M files) Personal data Project <code>/project/&lt;folder&gt;</code> varies varies Shared data, environments Scratch <code>/scratch/midway3/$USER</code> 100 GB 5 TB Temporary files Beagle 3 project <code>/project/&lt;folder&gt;</code> varies varies Shared data, environments Beagle 3 scratch <code>/scratch/beagle3/$USER</code> 400 GB   (or 5.1M files) 1 TB  (5.6M files) Temporary files Name Location Soft Quota Hard Quota Suitable For CDS <code>/cds/&lt;folder&gt;</code> varies varies Long-term, less frequently accessed shared data. CDS2 <code>/cds2/&lt;folder&gt;</code> varies varies Long-term, less frequently accessed shared data. CDS3 <code>/cds3/&lt;folder&gt;</code> varies varies Long-term, less frequently accessed shared data. <p>To check your current quotas, use the following commands: <pre><code>quota -u $USER\n</code></pre> <pre><code>rcchelp quota\n</code></pre></p> Explain a typical output <pre><code>---------------------------------------------------------------------------\nfileset          type                   used      quota      limit    grace\n---------------- ---------------- ---------- ---------- ---------- --------\nhome             blocks (user)         8.77G     30.00G     35.00G     none\n                 files  (user)        157865     300000    1000000     none\nscratch          blocks (user)       101.07G    100.00G      5.00T  30 days\n                 files  (user)        193028   10000000   20000000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n&gt;&gt;&gt; Capacity Filesystem: project2 (GPFS)\n---------------- ---------------- ---------- ---------- ---------- --------\npi-drpepper         blocks (group)       59.10T     60.00T     60.00T     none\n                 files  (group)     45825436  384500000  385500000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n---------------------------------------------------------------------------\n</code></pre> Field Meaning fileset File set or file system where this quota is valid type Type of quota. *Blocks* are the amount of consumed disk space. *Files* are the number of files in a directory. Blocks (or files) quotas can be set at the user or group level. used The amount of disk space consumed or the number of files in the specified location. quota The *soft quota* (disk space or file count) associated with the specified location. It is possible for usage to exceed the soft quota for the grace period or up to the hard limit. limit The *hard quota* (disk space or file count) associated with the specified location. When your usage exceeds this limit, you will NOT be able to write to that filesystem. grace The amount of time remaining that the soft quota can be exceeded. *None* means that the quota is not exceeded. After a soft quota has been exceeded for longer than the grace period, it will no longer be possible to create new files. <p>Over quota?</p> <p>If you exceed your quota, it can lead to errors since numerous applications may become unable to function properly. See our data management FAQ for multiple strategies for getting back under quota.</p>"},{"location":"storage/main/#high-performance-storage","title":"High-Performance Storage","text":""},{"location":"storage/main/#home-space","title":"Home Space","text":"<p>Every user has Midway2 and Midway3 home directories <code>/home/$USER</code>. Midway2 home dierctory is accessible from Midway2 and DaLI login nodes, while Midway3 home directory from Midway3, Beagle3, and SSD login nodes. Home directories are generally used for storing files that do not need to be shared with others and are only accessible by their owner (mode <code>0700</code>).</p>"},{"location":"storage/main/#research-space","title":"Research Space","text":"<p>New PIs are eligible to receive Midway3 startup storage for the duration of their appointment at UChicago. Every user who belongs to one or many <code>pi-&lt;PI_CNetID&gt;</code> groups may have access to the shared Midway3 project directories located at <code>/project/&lt;PI_CNetID&gt;</code> and/or (for old PI accounts) to the workspace Midway2 project space <code>/project2/&lt;PI_CNetID&gt;</code>. Members of a beagle3 group are additionally authorized to access Beagle3 project space at <code>/beagle3/&lt;PI_CNetID&gt;</code>. All these directories are accessible by all members of the PI's group and are generally used for storing, processing, and analyzing research data that needs to be shared by members of the group. The default group ownership is set to the PI group with read-write permissions for existing and newly created files and directories using a sticky bit (mode <code>2770</code>). Users may request access to multiple research spaces by submitting a request to be approved by the PI.</p>"},{"location":"storage/main/#scratch-space","title":"Scratch Space","text":""},{"location":"storage/main/#global-scratch","title":"Global Scratch","text":"<p>High-performance shared scratch spaces on Midway2 <code>/scratch/midway2/$USER</code>, Midway3 <code>/scratch/midway3/$USER</code>, and Beagle3 <code>/scratch/beagle3/$USER</code> are intended to be used for reading or writing data required by jobs running on the cluster. The default permissions for scratch space allow access only by its owner (mode <code>0700</code>). </p> <p>Warning</p> <p>Scratch space is neither snapshotted nor backed up; it should always be viewed as temporary, short-term storage only. It is the user's responsibility to ensure any important data in scratch space is moved to persistent storage. </p>"},{"location":"storage/main/#local-scratch","title":"Local Scratch","text":"<p>There is also a scratch space that resides on the local solid-state drives of each node and can only be used for jobs that do not require distributed parallel I/O. The capacity of the local solid-state drives varies across the systems and may depend on the usage of the node if your job resource request does not give you exclusive access to a node.  It is recommended that users use the local scratch space if they have high throughput I/O of many small files ( size &lt; 4 MB) for jobs that are not distributed across multiple nodes. To write files to local scratch, use environment variables <code>$TMPDIR</code> or <code>$SLURM_TMPDIR</code>, which are set to <code>/tmp/jobs/${SLURM_JOB_ID}</code> and add a line at the very end of your Slurm script to copy or move the output to the research space upon job completion. Otherwise, all temporary files will be purged once the job is completed or crashed. To check the size of the local scratch, submit an interactive job and execute the following command on the compute node: <pre><code>df -h $TMPDIR\n</code></pre></p>"},{"location":"storage/main/#cost-effective-data-storage","title":"Cost-Effective Data Storage","text":"<p>In addition to a high-performance GPFS file system, RCC also offers Cost-effective Data Storage (CDS) through the Cluster Partnership Program for long-term data storage. CDS is only available from login nodes and is meant to be used as a storage for less frequently accessed data. Before performing any computation on the data stored on CDS, it first needs to be copied to a high-performance file system.</p> <p>CDS includes multiple tiers (<code>/cds</code>, <code>/cds2</code>, <code>/cds3</code>) with the new data to be stored in <code>/cds3</code> cost-effective storage. Additionally, data can be moved from old tiers to the most recent tier using Globus. A user would need to provide the path on each endpoint, such as /cds or /cds2 on Midway2 and /cds3 on Midway3.  </p>"},{"location":"storage/main/#data-recovery-and-backups","title":"Data Recovery and Backups","text":""},{"location":"storage/main/#snapshots","title":"Snapshots","text":"<p>Automated snapshots for the GPFS directories (<code>home</code>, <code>project2</code>, <code>project</code>, <code>beagle3</code>, and <code>dali</code>) and CDS directories (<code>cds</code>, <code>cds2</code>, and <code>cds3</code>) are available from the login nodes for a limited time. Note that snapshot top-level directories, <code>.zfs</code> and <code>.snap</code>, are hidden and cannot be listed with <code>ls -al</code>. Instead, simply navigate to the directory as provided by the snapshot path:</p> Midway2, DaLIMidway3, Beagle3CDS Directory Snapshot kept Snapshot Path <code>/home/$USER</code> 7 daily and 2 weekly <code>/snapshots/home/&lt;SNAPSHOT&gt;/home/&lt;CNetID&gt;</code> <code>/project2/&lt;folder&gt;</code> 7 daily and 2 weekly <code>/snapshots/project2/&lt;SNAPSHOT&gt;/project2/&lt;folder&gt;</code> <code>/dali/&lt;folder&gt;</code> 7 daily and 2 weekly <code>/gpfs3/cap/.snapshots/&lt;SNAPSHOT&gt;</code> <p>Note: In order to access DaLI snapshots, first you need to log into one of the DaLI compute nodes. </p> Directory Snapshot kept Snapshot Path <code>/home/$USER</code> 7 daily and 4 weekly <code>/snapshots/&lt;SNAPSHOT&gt;/home/&lt;CNetID&gt;</code> <code>/project/&lt;folder&gt;</code> 7 daily and 4 weekly <code>/snapshots/&lt;SNAPSHOT&gt;/project/&lt;folder&gt;</code> <code>/beagle3/&lt;folder&gt;</code> 7 daily and 4 weekly <code>/beagle3/.snapshots/&lt;SNAPSHOT&gt;/beagle3/&lt;folder&gt;</code> Directory Snapshot kept Snapshot Path <code>/cds/&lt;workspace&gt;/&lt;folder&gt;</code> 4 hourly, 7 daily, 4 weekly <code>/cds/&lt;workspace&gt;/.zfs/snapshot/&lt;SNAPSHOT&gt;/&lt;folder&gt;</code> <code>/cds2/&lt;workspace&gt;/&lt;folder&gt;</code> 4 hourly, 7 daily, 4 weekly <code>/cds2/&lt;workspace&gt;/.zfs/snapshot/&lt;SNAPSHOT&gt;/&lt;folder&gt;</code> <code>/cds3/&lt;workspace&gt;/&lt;folder&gt;</code> 7 daily, 4 weekly, 2 monthly <code>/cds3/&lt;workspace&gt;/.snap/&lt;SNAPSHOT&gt;/&lt;folder&gt;</code> <p>The <code>&lt;SNAPSHOT&gt;</code> refers to the backup time, e.g., <code>daily-YYYY-MM-DD.0Xh30</code> or <code>weekly-YYYY-MM-DD.0Xh30</code>. To restore a file from a snapshot, simply copy it to where you want it with either <code>cp</code> or <code>rsync</code> or any other preferred method. </p>"},{"location":"storage/main/#acquiring-more-storage","title":"Acquiring More Storage","text":"<p>Additional storage is available through: Cluster Partnership Program - Includes the option to purchase high-capacity and cost-effective storage   Research I Allocation - Includes the option to request a small amount of no-cost high-capacity storage  Research II Allocation - Includes the option to request a small amount of no-cost high-capacity storage </p>"},{"location":"thinlinc/main/","title":"ThinLinc - Remote desktop","text":""},{"location":"thinlinc/main/#connecting-with-thinlinc","title":"Connecting with ThinLinc","text":"<p>ThinLinc is a remote desktop server used to connect to RCC clusters and obtain a remote graphical user interface (GUI). We recommend using ThinLinc to use software that requires a GUI. Remember, ThinLinc is much less stable than SSH. </p> <p>There are two methods to access ThinLinc on RCC clusters: 1. Through a web browser 2. Using the ThinLinc app. </p>"},{"location":"thinlinc/main/#accessing-thinlinc-through-a-web-browser","title":"Accessing ThinLinc through a web browser","text":"<p>Point your web browser to the following web address: </p> DaLIMidway2Midway3Midway3-AMDMidwaySSDBeagle3 <pre><code>https://dali-login1.rcc.uchicago.edu/main/\nhttps://dali-login2.rcc.uchicago.edu/main/\n</code></pre> <p><pre><code>https://midway2.rcc.uchicago.edu.\n</code></pre> You will land on this page: <p> </p> </p> <p><pre><code>https://midway3.rcc.uchicago.edu.\n</code></pre> You will land on this page: <p> </p> </p> <pre><code>https://midway3-amd.rcc.uchicago.edu/\n</code></pre> <pre><code>https://ssd.rcc.uchicago.edu/\n</code></pre> <pre><code>https://beagle3.rcc.uchicago.edu/\n</code></pre> <p>Proceed to log in with your CNetID and password.</p> <p>Duo two-factor authentication will request you select from the 2FA options to authenticate.</p>"},{"location":"thinlinc/main/#accessing-thinlinc-through-the-client-app","title":"Accessing ThinLinc through the client (app)","text":"<p>Download and install the appropriate ThinLinc client here. </p> <p>Open the ThinLinc client (app) and use the following information to set up your connection to Midway:</p> DaLIMidway2Midway3Midway3-AMDMidwaySSDBeagle3 <pre><code>Server: dali-login1.rcc.uchicago.edu/main/\nServer: dali-login2.rcc.uchicago.edu/main/\nUsername: CNetID\nPassword: CNetID password\n</code></pre> <p><pre><code>Server: midway2.rcc.uchicago.edu\nUsername: CNetID\nPassword: CNetID password\n</code></pre> Your client should look similar to this: <p> </p> </p> <p><pre><code>Server: midway3.rcc.uchicago.edu\nUsername: CNetID\nPassword: CNetID password\n</code></pre> Your client should look similar to this: <p> </p> </p> <pre><code>Server: midway3-amd.rcc.uchicago.edu/\nUsername: CNetID\nPassword: CNetID password\n</code></pre> <p><pre><code>Server: ssd.rcc.uchicago.edu\nUsername: CNetID\nPassword: CNetID password\n</code></pre> Your client should look similar to this: <p> </p> <p> </p> <p> </p> </p> <pre><code>Server: beagle3.rcc.uchicago.edu/main/\nUsername: CNetID\nPassword: CNetID password\n</code></pre> <p>The default setting for the ThinLinc client opens a fullscreen window that fills \u201call monitors.\u201d If you prefer to work with ThinLinc from its own window, click <code>Options</code> from the initial login interface and then Screen to adjust your settings. The following is an example of a setup that places the ThinLinc client in its own window: </p> <p> </p> <p>Optional: You are also able to export local resources via ThinLinc. To do so, click Options from the initial login interface and then Local Devices. To adjust your settings for exporting the local file system, click Details next to Drives.</p> <p> </p> <p>After clicking the <code>Connect</code> button, Duo two-factor authentication will request you select from the 2FA options to authenticate.</p> <p> </p>"},{"location":"thinlinc/main/#the-thinlinc-interface","title":"The ThinLinc interface","text":"Midway2, DaLIMidway3, Midway3-AMD, Beagle3MidwaySSD <p>You will be presented with an <code>IceWM desktop</code> upon successfully logging in. Select the <code>Applications</code> tab in the top left corner to access the terminal (for interactive sessions), file browser, and other utilities.  <p> </p></p> <p>Upon successfully logging in via ThinLinc, you will be connected to a login node and presented with a desktop interface. Select the <code>Applications</code> tab in the top left corner to access the terminal, file browser, and other utilities. <p> </p> To view all available applications, click the 3x3 dot grid at the bottom of the <code>Activities</code> Tab: <p> </p> </p> <p>Upon successfully logging in via ThinLinc, you will be connected to a login node and presented with a desktop interface.   <p> </p>  Select the <code>Applications</code> tab in the top left corner to access the terminal, file browser, and other utilities. <p> </p>  To open a terminal, type in <code>terminal</code>:  <p> </p>  Then, press <code>enter</code>:  <p> </p> For an interactive session, type in your required <code>sinteractive</code> setting:  <p> </p> Then, press <code>enter</code>:  <p> </p> After this step, you'll land on a compute node. </p> <p>To copy/paste text between your computer and ThinLinc (when copying code into the Terminal, for example), open the side toolbar by clicking the small blue handle. Click the Clipboard icon. The text field that just opened will be synced with the clipboard on the server so you can copy and paste to and from this text field. </p> <p> </p> <pre><code>\n</code></pre> <p>With ThinLinc, you can maintain an active session after you have closed your connection to RCC clusters. To disconnect from Midway but maintain an active session, simply close the ThinLinc window. You must have \"End existing session\" unchecked for this to occur.</p> <p>To exit ThinLinc and terminate your session completely, simply exit or close the ThinLinc application.</p>"},{"location":"thinlinc/main/#remote-visualization-on-midway2","title":"Remote Visualization on Midway2","text":"<p>RCC provides a mechanism for accessing a GPU-equipped visualization node, which can be used for running 3D and graphics-intensive visualization software packages. </p> <p>First, log into Midway2 via ThinLinc.</p> <p>Once logged in, open a terminal, and in the terminal window, issue the command <code>sviz</code>. This will take you to the visualization node. </p> <p>To exit the visualization node, simply close the terminal window from which it was launched. You can then log out of Midway2 by selecting Logout from the <code>Applications</code> menu in ThinLinc or simply closing the ThinLinc window. </p>"},{"location":"thinlinc/main/#common-mistakes-using-thinlinc","title":"Common mistakes using ThinLinc","text":"<p>Once you have connected to RCC clusters through ThinLinc (see Accessing RCC resources), you land on one of the login nodes. Login nodes may be used for compiling and debugging code, installing software, editing and managing files, submitting jobs, or any other work that is not long-running or computationally intensive. Login nodes should never be used for computationally intensive work.</p> <p>All intensive computations should be performed on compute nodes. If you are unsure whether your computations will be intensive, please request an interactive session and continue your work once connected to the compute node.</p> <p>Warning</p> <p>Running computationally intensive jobs on the login nodes prevents other users from efficiently using the cluster. RCC System Administrators may terminate your processes without warning if your processes disrupt other users\u2019 work on the RCC cluster. </p>"},{"location":"thinlinc/troubleshooting/","title":"ThinLinc - Troubleshooting","text":""},{"location":"thinlinc/troubleshooting/#thinlinc-client","title":"ThinLinc client","text":"<p>When logging into the ThinLinc app, click <code>end existing session</code>. This will terminal other open sessions. </p>"},{"location":"thinlinc/troubleshooting/#check-your-account-quota","title":"Check your account quota","text":"<p>If you have too many files in your home directory on Midway clusters with an <code>expired quota</code> flag, then ThinLinc cannot write its cache files upon login, which can result in having trouble with login through ThinLinc. To check your account <code>quota</code> or, in other words, the status of how much space files in your home directory are taking and how many files you have, log into <code>Midway3</code> (or <code>Midway3-AMD</code> or <code>MidwaySSD</code> or <code>Beagle3</code>) through SSH and then type in <code>quota</code> and then press enter if there is an <code>expired</code> on any of your home directories. </p> <p>An example output of <code>quota</code> command: </p> <pre><code>---------------------------------------------------------------------------\nfileset          type                   used      quota      limit    grace\n---------------- ---------------- ---------- ---------- ---------- --------\nMidway2 home     blocks (user)         2.30G     30.00G     35.00G     none\n                 files  (user)        300100     300000    1000000  expired\nMidway3 home     blocks (user)       768.94M     30.00G     35.00G     none\n                 files  (user)         21274     300000    1000000     none\nscratch/midway2  blocks (user)         0.00K    100.00G      5.00T     none\n                 files  (user)             1   10000000   20000000     none\nscratch/midway3  blocks (user)         0.00K    100.00G      2.00T     none\n                 files  (user)             1   10000000   20000000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n&gt;&gt;&gt; Capacity Filesystem: project (Midway3 GPFS)\n---------------- ---------------- ---------- ---------- ---------- --------\npi-drpepper      blocks (group)      111.44T    300.00T    301.00T     none\n                 files  (group)     34821665  230900000  231900000     none\n---------------- ---------------- ---------- ---------- ---------- --------\n&gt;&gt;&gt; Capacity Filesystem: project2 (Midway2 GPFS)\n---------------- ---------------- ---------- ---------- ---------- --------\npi-drpepper      blocks (group)      317.06T    500.49T    501.49T     none\n                 files  (group)     52948203  384875000  385875000     none\n---------------------------------------------------------------------------\n</code></pre> <p>In this example, the <code>expired</code> flag on <code>Midway2 home</code> means the user has too many files. After removing or moving some of the files from <code>Midway2 home</code> to <code>scratch/midway2</code> or <code>project2</code> directories, the issue will be resolved after our system reviews the accounts' quota again in a few hours. </p>"},{"location":"thinlinc/troubleshooting/#cleaning-cache-files-and-closing-unfinished-sessions","title":"Cleaning cache files and closing unfinished sessions","text":"<p>Sometimes, ThinLinc leaves some cache files from previous sessions that can cause issues. To close the unfinished sessions, log into the cluster through SSH and run the following command: </p> <pre><code>kill -9 `ps -ef|grep thin|grep $USER|awk '{print $2}'|paste -d \" \" -s`\n</code></pre> <p>This might give the following error, but you can ignore it and try to log in through ThinLinc again. </p> <pre><code>-bash: kill: (2601223) - No such process\n</code></pre> <p>To clean cache files, log in through SSH and go to your home directory: </p> <pre><code>cd $HOME\n</code></pre> <p>Then remove the cache files: </p> <pre><code>rm -rf .cache/* .config/* .dbus/*\n</code></pre> <p>And also, <code>.local/share</code> files: </p> <p><pre><code>cd .local/share\n</code></pre> Then: </p> <pre><code>rm -rf gnome-* nautilus\n</code></pre> <p>If the issue persists, let us know by contacting our helpdesk. </p>"},{"location":"thinlinc/troubleshooting/#conflict-with-conda-files","title":"Conflict with <code>conda</code> files","text":"<p>Log into the Midway cluster through SSH and then open <code>~/.bashrc</code> file. </p> <pre><code>vim ~/.bashrc\n</code></pre> <p>If there is anything related to the conda environment, please delete that. This would be any line in between:</p> <pre><code># &gt;&gt;&gt; conda initialize &gt;&gt;&gt;\nHide quoted text\n# !! Contents within this block are managed by 'conda init' !!\n............\nand\nunset __conda_setup\nShow quoted text\n</code></pre> <p>Sometime it appears as: </p> <pre><code>__conda_setup=\"$('/software/python-anaconda-2020.02-el7-x86_64/bin/conda' 'shell.bash' 'hook' 2&gt; /dev/null)\"\nif [ $? -eq 0 ]; then\neval \"$__conda_setup\"\nelse\nif [ -f \"/software/python-anaconda-2020.02-el7-x86_64/etc/profile.d/conda.sh\" ]; then\n. \"/software/python-anaconda-2020.02-el7-x86_64/etc/profile.d/conda.sh\"\nelse\nexport PATH=\"/software/python-anaconda-2020.02-el7-x86_64/bin:$PATH\"\nfi\nfi\nunset __conda_setup\n</code></pre>"},{"location":"tutorials/kicp/","title":"KICP Tutorial","text":"<p>Note</p> <p>This page was migrated from the previous user guide with minimal editing. Some details may now be out of date. See the main sections of this guide for the most up-to-date content. </p> <p>The KICP has exclusive access to a number of compute nodes associated with the RCC Midway cluster.  KICP users access those nodes through the same login nodes and interfaces as the primary cluster, making it trivial to move computational work between the two sets of resources. Most of the documentation available on this site is applicable to KICP members and the KICP nodes, however there are some specific differences which are described here.</p> <p>Email sent to kicp@rcc.uchicago.edu will be assigned a trouble ticket and reviewed by the RCC Help Desk.  Please don\u2019t hesitate to ask questions if you encounter any issues, or have any requests for software installation.</p>"},{"location":"tutorials/kicp/#get-an-account","title":"Get an account","text":"<p>Please complete the RCC User Account Request form to request an account and put KICP as the PI (note: this request will be reviewed for KICP membership).  Please clearly state your connection to the KICP, particularly if you are not a local or senior member.  If you are requesting access for someone not at the University of Chicago (i.e. someone who doesn\u2019t have a CNetID), the account creation process will involve creating a CNetID.</p> <p>To access the rest of the Midway cluster you will need to be added to a different account than KICP, typically provided by a faculty member acting as PI. All KICP faculty are eligible to act as PI for themselves and others, and many already have PI accounts on the Midway cluster.</p>"},{"location":"tutorials/kicp/#submit-a-job","title":"Submit A Job","text":"<p>As a shared resource, Midway uses a batch queueing system to allocate nodes to individuals and their jobs.  Midway uses the Slurm batch queuing system, which is similar to the possibly more familiar PBS batch system.</p> <p>Please see the Midway2 and Midway3 HPC Systems section of this User Guide for information on using Midway to perform computational tasks, typically by submitting batch jobs. The Slurm commands, reiterated below, can be used as described in that documentation, however KICP users may need to point to one of the two KICP partitions, kicp and kicp-ht, and select the kicp account.</p> <p>NOTE: Specifying \u2013account=kicp and \u2013partition=kicp is generally optional for users who belong to the KICP group and no other, however specifying them is generally good practice.</p> Useful Commands Description sbatch -p kicp -a kicp Submit a job to the Slurm scheduling system. sinteractive -p kicp Run an interactive job on a KICP compute node squeue -p kicp List the submitted and running jobs in the KICP partition. squeue -u $USER List the current users\u2019 own submitted and running jobs. sinfo -p kicp List the number of available and allocated KICP nodes. scancel job_id Cancel the job identified by the given job_id (e.g. 3636950). scancel -u $USER Cancel all jobs submitted by the current user <p>There are many ways to submit a batch job, depending on what that job requires (number of processors, number of nodes, etc). Slurm will automatically start your job in the directory from which it was submitted.  To submit a job, create a batch script, say my_job.sh and submit with the command sbatch my_job.sh.  The following is a list of commonly used sbatch commands.  A more complete list can be found in the sbatch man page.</p> <p>The following is a good example batch script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_job\n#SBATCH --output=my_job_%j.out\n#SBATCH --time=24:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --nodes=1\n#SBATCH --exclusive\n\necho $SLURM_JOB_ID starting execution `date` on `hostname`\n\n# load required modules (change to your requirements!)\n# example: module load openmpi/1.8\n\n# uncomment below if your code uses OpenMP to properly set the number of threads\n# export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\n# the commands to run your job\n# example: mpirun ./my_task\n# Note: slurm will automatically tell MPI how many tasks and tasks per node to use\n</code></pre>"},{"location":"tutorials/kicp/#kicp-queues","title":"KICP Queues","text":"<p>KICP has the access to the following queues (partition in Slurm terminology):</p> Partition Wallclock limit Job limits kicp 48h 256 cores, 64 jobs per user kicp-ht 36h 64 cores/job, 32 jobs per user kicp-long 100h 128 cores/queue, 64 cores/user <p>access to kicp-long requires special authorization.</p> <p>If you are running jobs with significant I/O or communication between nodes (typically MPI jobs), then you should use the the tightly-coupled, infiniband nodes accessed through the kicp and kicp-long partitions. Purely serial or embarrassingly parallel jobs with a large calculation to I/O ratio (say MCMC likelihood sampling) should use the high-throughput nodes in the kicp-ht queue.  The limits for kicp-ht were relaxed to encourage use.  If users start to conflict, they may be restricted to prevent a single user from dominating those nodes.</p> <p>Midway also includes two large memory (256GB) and four GPU enabled nodes, as well as a significantly larger set of nodes that are shared with the rest of the University.  Accessing these resources requires a separate allocation.  Please contact the RCC for more details.</p>"},{"location":"tutorials/kicp/#storage","title":"Storage","text":"<p>Your home directory has a 30G quota, and should be used for small files and codes.</p> <p>KICP has a 50TB allocation in <code>/project/kicp/</code>, and each user is initially given a 1TB quota and their own subdirectory (<code>/project/kicp/$USER)</code>. If you require more space, please let the RCC know and your quota may be increased on a case-by-case basis.</p> <p>New project space is no longer allocated under /project but under /project2.</p> <p>Both home and project space are backed up hourly to disk, and daily to tape.</p> <p>Finally, there is a high-performance filesystem mounted on /scratch/midway2 which should be used during runs and has a 5TB quota. This directory is not backed up and should not be used for long-term storage. In future, files older than a to be determined age may be removed automatically, so please practice good data management.</p>"},{"location":"tutorials/kicp/#snapshots-and-backups","title":"Snapshots and Backups","text":"<p>We all inadvertently delete or overwrite files from time to time.  Snapshots are automated backups that are accessible through a separate path.  Snapshots of a user\u2019s home directory can be found in <code>/snapshots/\\*/home/*cnetid*/</code> where the subdirectories refer to the frequency and time of the backup, e.g. daily-2012-10-04.06h15 or hourly-2012-10-09.11h00.</p>"},{"location":"tutorials/kicp/#software","title":"Software","text":"<p>Many common astrophysical codes and libraries have been installed or built on Midway. Other common astrophysics packages require configuration at compilation that prevent them from being installed system-side. Look here for program specific compilation flags, installation instructions, etc for these packages. Please contact the RCC if you notice any problems with any of the software or instructions.</p>"},{"location":"tutorials/kicp/#idl","title":"IDL","text":"<p>IDL is installed on Midway, however the RCC is unable to provide licenses to the entire community. Users who have their own licenses or license servers may configure them to be able to use IDL on Midway\u2019s login and compute nodes. Contact RCC for more details.</p>"},{"location":"tutorials/kicp/#cosmomc","title":"CosmoMC","text":"<p>CosmoMC is a Markov-Chain Monte-Carlo (MCMC) code which is integrated with the theoretical power spectrum code CAMB.  Since it is often modified by users, we don\u2019t install a system-wide version, however we have verified that the following parameters give good performance (Warning: under construction, don\u2019t use these instructions without first talking to the RCC).</p> <p>Specific installation instructions for a non-mpi build using the intel compiler and the intel math kernel library mkl 10.3 (note, these differ slightly from those provided by the CosmoMC readme ):</p> <ul> <li> <p>Download CosmoMC from cosmologist.info and untar on Midway</p> </li> <li> <p>Load the modules appropriate for the compiler you intend to use.  In this case a non-mpi build with the intel compiler: <code>module load intel/12.1 cfitsio/3+intel-12.1 mkl/10.3</code></p> </li> <li> <p>Edit the CosmoMC Makefile located in the source subdirectory</p> </li> </ul> <p>The WMAP7 likelihood code and data are already configured and installed on Midway in the <code>/project/kicp/opt/WMAP/</code> directory. The stock v4 and v4p1 versions from Lambda  are installed, as is a patched version of v4 with special optimizations from Cora Dvorkin &amp; Wayne Hu.  Select the version you wish to use and change the WMAP variable to point to the full directory, e.g. <code>WMAP = /project/kicp/opt/WMAP/likelihood_v4p1</code>.</p> <ul> <li>Modify the compiler and optimization options</li> </ul> <pre><code>F90C = ifort\nFFLAGS = -O2 -openmp -fpp\nLAPACKL = $(MKLROOT)/lib/intel64/libmkl_lapack95_lp64.a \\\n              -Wl,--start-group \\\n              $(MKLROOT)/lib/intel64/libmkl_intel_lp64.a \\\n              $(MKLROOT)/lib/intel64/libmkl_sequential.a \\\n              $(MKLROOT)/lib/intel64/libmkl_core.a \\\n              -Wl,--end-group -lpthread\n</code></pre> <ul> <li>Run make</li> </ul> <p>Note, this section is under construction.  Updated build instructions for a variety of compilers and mpi support will come soon.</p>"},{"location":"tutorials/kicp/#art","title":"ART","text":"<p>ART has default compilation flags for Midway.  Set the environment variable PLATFORM to midway. This platform file will automatically detect the MPI environment and compiler option you are using and configure the code accordinly.</p>"},{"location":"tutorials/kicp/#ramses","title":"RAMSES","text":"<p>Ramses is a cosmological hydrodynamic adaptive mesh refinement code originally written by Romain Teyssier.  It is public, and can be downloaded .  Oscar Agertz has compiled and run Ramses on Midway and reports good performance with the following makefile configuration:</p> <pre><code>F90 = mpif90 -O3\nFFLAGS = -cpp -DNVAR=$(NVAR) -DNDIM=$(NDIM) -DNPRE=$(NPRE) \\\n            -DSOLVER$(SOLVER) -DNOSYSTEM -DNVECTOR=$(NVECTOR)\nLIBMPI =\nLIBS = $(LIBMPI)\n</code></pre>"},{"location":"tutorials/kicp/#gadget","title":"Gadget","text":"<p>This refers to the public version of Gadget 2.0.7. The following Makefile configuration should work under all combination of compilers, MPI libraries, and Gadget options (including HDF5 support):</p> <pre><code>CC = mpicc\nOPTIMIZE = -O3\nMPICHLIB =\nHDF5INCL = -DH5_USE_16_API\nHDF5LIB = -lhdf5\n</code></pre> <p>The code requires that modules are loaded for fftw2, gsl, mpi, and an optional hdf5.  Make sure to load compiler and MPI library specific versions of the modules as necessary.  Some examples are given below:</p> <ul> <li>Intel compiler + Intel MPI (note, loading intelmpi will automatically load intel/12.1):</li> </ul> <pre><code>module load intelmpi/4.0+intel-12.1 fftw2/2.1.5+intelmpi-4.0+intel-12.1 hdf5/1.8 gsl/1.15\n</code></pre> <ul> <li>Intel compiler + OpenMPI:</li> </ul> <pre><code>module load openmpi/1.6+intel-12.1 fftw2/2.1.5+openmpi-1.6+intel-12.1 hdf5/1.8 gsl/1.15\n</code></pre> <ul> <li>GCC + OpenMPI:</li> </ul> <pre><code>module load openmpi/1.6 fftw2/2.1.5+openmpi-1.6 hdf5/1.8 gsl/1.15\n</code></pre>"},{"location":"tutorials/kicp/#automating-large-numbers-of-tasks","title":"Automating Large Numbers of Tasks","text":"<p>Researchers often need to perform a number of calculations that vary only in their initial conditions or input parameters. Such tasks naturally arise when exploring the predictions of a model over a range of parameters or when testing a numerical calculation for convergence. Automating these tasks is critical, both for computational efficiency and to minimize human error and ensure the calculation is reproducible.</p> <p>This tutorial will discuss a number of techniques and tools available on Midway for automating the running of tasks and their respective advantages and disadvantages. In particular we will focus on those tasks which are entirely independent of each other and where the total number of tasks is known (and fixed).</p> <p>When deciding between the various techniques, users should consider the following:</p> <ul> <li>overhead or cost of starting each task (including cost of starting remote processes)</li> <li>waiting time each batch job will spend in the queue</li> <li>total number of jobs compared to available resources and limits</li> <li>the average calculation time per job and its variance</li> <li>the cost in developer time needed for a given solution</li> </ul> <p>As a semi-realistic example, this tutorial will use the CLASS code to compute the non-linear matter power specturm for a range of the neutrino parameter N_eff.</p>"},{"location":"tutorials/kicp/#class-and-classy","title":"CLASS and classy","text":"<p>CLASS [1104.2932] is a Boltzmann code similar to CMBFAST, CAMB, and others. It can be used to compute a number of large-scale structure and CMB observables and since it is designed to perform calculations within MCMC-type likelihood analyses, it is a good option for these exercises.</p> <p>To install CLASS and its Python wrapper, classy, use the following commands:</p> <pre><code>module load git python/2.7-2014q3\ngit clone https://github.com/lesgourg/class_public\ncd class_public\nmake\n</code></pre> <p>NOTE: This will install the Class python wrappers in your .local directory while remembering where you compiled CLASS. Make sure you delete them both after completing the exercises.</p> <p>classy is a Python wrapper for the CLASS code which we will use for convenience. It allows us to avoid the common issue of dealing with parameter files.</p> <p>The code that uses classy to compute the non-linear matter power spectrum for a given N_eff is as follows:</p> <pre><code>#!/bin/env python\n\ndef compute_pk(N_eff=3.04, output=\"pk.dat\"):\n    import numpy as np\n    from classy import Class\n\n    # initialize Class with default parameters save N_eff\n    c = Class()\n    c.set({'output':'mPk', 'non linear':'halofit', 'N_eff':N_eff})\n    c.compute()\n    with open(output, \"w\") as output:\n        for k in np.logspace(-3., 0.5, 100):\n            print &gt;&gt;output, \"%.6e %.6e\" % (k, c.pk(k, z=0.0))\n    c.struct_cleanup()\n\n    # if necesssary for visualization, add a 5 second delay\n    #import time; time.sleep(5)\n\n# perform work associated with i out of N steps\ndef work(i, N=100):\n    N_eff_min = 2.5\n    N_eff_max = 4.5\n    N_eff = (N_eff_max-N_eff_min)*float(i)/float(N) + N_eff_min\n    output = \"pk_{}.dat\".format(i)\n    compute_pk(N_eff, output)\n\n# collect the resulting matter power spectra and plot \ndef plot_pk(file_pattern=\"pk_*.dat\",output=\"pk.png\"):\n    import pylab, glob\n    import numpy as np\n\n    f = pylab.figure(figsize=(5,5))\n    for data in glob.glob(file_pattern):\n        (k, pk) = np.loadtxt(data, unpack=True)\n        f.gca().loglog(k, pk, color='k', alpha=0.05)\n    f.gca().set_xlabel(\"k [Mpc/h]\")\n    f.gca().set_ylabel(\"P(k)\")\n    f.tight_layout()\n    f.savefig(output)\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) == 3:\n        work(int(sys.argv[1]), int(sys.argv[2]))\n    else:\n        plot_pk()\n\n    print \"done\"\n</code></pre> <p>Run this code without any input parameters to generate the following png figure from the resulting output files.</p>"},{"location":"tutorials/kicp/#parallel-programming","title":"Parallel Programming","text":"<p>Implementing your own parallel scheme is useful when the tasks are not completely independent, or represent only a part of a larger, non-trivial workflow. Calculations that rely on large pre-calculated tables or have costly initilization may also benefit from an explicit scheme, as those costs can be amortized over a larger number of tasks.</p>"},{"location":"tutorials/kicp/#multiprocessing","title":"Multiprocessing","text":"<p>Smaller numbers of tasks can be divided amongst workers on a single node. In high level languages like Python, or in lower level languages using threading language constructs such as OpenMP, this can be accomplished with little more effort than a serial loop. This example also demonstrates using Python as the script interpreter for a Slurm batch script, however note that since Slurm copies and executes batch scripts from a private directory, it is necessary to manually add the runtime directory to the Python search path.</p> <pre><code>#!/bin/env python\n\n#SBATCH --job-name=multiprocess\n#SBATCH --output=logs/multiprocess_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --nodes=1\n#SBATCH --exclusive\n\nimport multiprocessing\nimport sys\nimport os\n\n# necessary to add cwd to path when script run \n# by slurm (since it executes a copy)\nsys.path.append(os.getcwd()) \nfrom pk import work\n\n# get number of cpus available to job\ntry:\n    ncpus = int(os.environ[\"SLURM_JOB_CPUS_PER_NODE\"])\nexcept KeyError:\n    ncpus = multiprocessing.cpu_count()\n\n# create pool of ncpus workers\np = multiprocessing.Pool(ncpus)\n\n# apply work function in parallel\np.map(work, range(100))\n</code></pre>"},{"location":"tutorials/kicp/#mpi","title":"MPI","text":"<p>Process and threaded level parallelism is limited to a single machine.</p> <pre><code>#!/bin/env python\n\n#SBATCH --job-name=mpi\n#SBATCH --output=logs/mpi_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --ntasks=100\n\nfrom mpi4py import MPI\nfrom pk import work\n\ncomm = MPI.COMM_WORLD\nrank = comm.Get_rank()\nsize = comm.Get_size()\n\nwork(rank, size)\n</code></pre> <p>MPI programs and Python scripts must be launched using mpirun as shown in this Slurm batch script:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=mpi\n#SBATCH --output=logs/mpi_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=100\n\nmodule load mpi4py/1.3-2014q3+intelmpi-4.0\n\nmpirun python mpi_pk.py\n</code></pre> <p>In this case we are only using MPI as a mechanism to remotely launch tasks on distributed nodes. All processes must start and end at the same time, which can lead to waste of resources if some job steps take longer than others.</p>"},{"location":"tutorials/kicp/#job-scheduler","title":"Job Scheduler","text":"<p>Most of this workshop will focus on using various features of Midway\u2019s batch scheduler, Slurm as its sole purpose is to help organize batch job submission.</p>"},{"location":"tutorials/kicp/#slurm-task-per-job","title":"Slurm task per job","text":"<p>In some cases it may be easiest to wrap the job submission in a script or bash command, taking advantage of the fact that Slurm will pass on environment variables defined at the time of job submission (this is also why you can load modules before submitting a job rather than inside the job script itself).</p> <pre><code>for i in {0..10}; do export i; sbatch job.sbatch; done\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=job\n#SBATCH --output=logs/job_%j.out\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=1\n\npython pk.py $i 100\n</code></pre> <p>NOTE: It can be difficult to monitor and jobs submitted in this way. Be sure to use a unique job-name so you can identify a particular job group with commands like squeue and scancel, e.g. <code>scancel -n class</code></p>"},{"location":"tutorials/kicp/#gnu-parallel","title":"GNU Parallel","text":"<p>GNU Parallel is a tool for executing tasks in parallel, typically on a single machine. When coupled with the Slurm command srun, parallel becomes a powerful way of distributing a set of tasks amongst a number of workers. This is particularly useful when the number of tasks is significantly larger than the number of available workers (Slurm\u2019s <code>--ntasks</code>).</p> <pre><code>#!/bin/sh\n\n#SBATCH --time=01:00:00\n#SBATCH --output=logs/parallel.log\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=32\n#SBATCH --exclusive\n\nmodule load parallel\n\n# the --exclusive to srun makes srun use distinct CPUs for each job step\n# -N1 -n1 allocates a single core to each task\nsrun=\"srun --exclusive -N1 -n1\"\n\n# --delay .2 prevents overloading the controlling node\n# -j is the number of tasks parallel runs so we set it to $SLURM_NTASKS\n# --joblog makes parallel create a log of tasks that it has already run\n# --resume makes parallel use the joblog to resume from where it has left off\n# the combination of --joblog and --resume allow jobs to be resubmitted if\n# necessary and continue from where they left off\nparallel=\"parallel --delay .2 -j $SLURM_NTASKS --joblog logs/runtask.log --resume\"\n\n# this runs the parallel command we want\n# in this case, we are running a script named runtask\n# parallel uses ::: to separate options. Here {0..99} is a shell expansion\n# so parallel will run the command passing the numbers 0 through 99\n# via argument {1}\n$parallel \"$srun python pk.py {1} 100 &gt; logs/parallel_{1}.log\" ::: {0..99}\n</code></pre> <p>This job is submitted as with any Slurm batch job</p> <pre><code>$ sbatch parallel.sbatch\n</code></pre> <p>and will appear as a single job in the queue, assigned as many nodes/cores as was requested:</p> <pre><code>$ squeue -u $USER -p kicp\n   JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n11511073      kicp parallel    drudd  R       0:00      2 midway[203,390]\n</code></pre> <p>GNU Parallel maintains a log of the work that has already been done, along with the exit value of each step (useful for determining any failed steps).</p> <pre><code>$ head logs/runtask.log\nSeq Host    Starttime   Runtime Send    Receive Exitval Signal  Command\n1   :   1422211597.529  6.467   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 0 100 &gt; logs/runtask.0\n2   :   1422211597.732  6.466   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 1 100 &gt; logs/runtask.1\n3   :   1422211597.935  6.466   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 2 100 &gt; logs/runtask.2\n4   :   1422211598.138  6.464   0   0   0   0   srun --exclusive -N1 -n1 python pk.py 3 100 &gt; logs/runtask.3\n</code></pre> <p>In our case we requested the output from each work step be directed to a file logs/runtask.{1}, allowing us to peform further diagnostics if necessary. The parallel option <code>--resume</code> creates a file parallel.log which allows GNU Parallel to resume a job that has been stopped due to failure or by hitting a walltime limit before all tasks have been completed. If you need to rerun a GNU Parallel job, be sure to delete parallel.log or it will think it has already finished!</p> <p>NOTE: More information may found in the RCC documentation section Parallel batch jobs.</p>"},{"location":"tutorials/kicp/#slurm-job-array","title":"Slurm Job Array","text":"<p>Most HPC job schedulers support a special class of batch job known as array jobs (or job arrays). Slurm support for job arrays is relatively new and is undergoing active development. The GNU Parallel solution in the previous section was developed at RCC because of the former lack of Slurm array jobs.</p> <p>An example Slurm array job submission script is as follows:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=array\n#SBATCH --output=logs/array_%A_%a.out\n#SBATCH --array=0-99\n#SBATCH --time=01:00:00\n#SBATCH --partition=kicp\n#SBATCH --account=kicp\n#SBATCH --ntasks=1\n\n# the environment variable SLURM_ARRAY_TASK_ID contains\n# the index corresponding to the current job step\npython pk.py $SLURM_ARRAY_TASK_ID 100\n</code></pre> <p>This looks very similar to our single-job batch submission script, but with the addition of the <code>--array</code> feature. In this case, the <code>--array=0-99</code> will cause 100 individual array-tasks to be created when this job script is submitted. Each array task is a copy of the master script, with an environment variable called <code>SLURM_ARRAY_TASK_ID</code> set to the index of the array task. As with the GNU Parallel example, we simply pass the value of that environment variable into our program to perform that piece of work.</p> <p>Each array job will enter the queue and run when resources are available for it, as if we had submitted each job manually (this is merely a highly-convenient shortcut).</p> <p>Array job indices do not need to be a linear range, and can be specified in a number of ways.  For example:</p> <pre><code>A job array with index values of 1, 2, 5, 19, 27:\n#SBATCH --array=1,2,5,19,27\n\nA job array with index values between 1 and 7 with a step size of 2 (i.e. 1, 3, 5, 7):\n#SBATCH --array=1-7:2\n</code></pre> <p>The <code>%A_%a</code> construct in the output and error file names is used to generate unique output and error files based on the master job ID (%A) and the array-tasks ID (%a).  In this fashion, each array-task will be able to write to its own output and error files.</p> <p>When we submit a job array, we will see the master process, as well as any submitted, running or otherwise not completed array tasks with the naming convention <code>%A_%a</code>.</p> <pre><code>$ squeue\n           JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n11510950_[10-99]      kicp    array    drudd PD       0:00      1 (None)\n      11510950_0      kicp    array    drudd  R       0:00      1 midway185\n      11510950_1      kicp    array    drudd  R       0:00      1 midway185\n      11510950_2      kicp    array    drudd  R       0:00      1 midway185\n      11510950_3      kicp    array    drudd  R       0:00      1 midway185\n      11510950_4      kicp    array    drudd  R       0:00      1 midway185\n      11510950_5      kicp    array    drudd  R       0:00      1 midway185\n      11510950_6      kicp    array    drudd  R       0:00      1 midway185\n      11510950_7      kicp    array    drudd  R       0:00      1 midway185\n      11510950_8      kicp    array    drudd  R       0:00      1 midway185\n      11510950_9      kicp    array    drudd  R       0:00      1 midway185\n</code></pre> <p>We can cancel all array tasks associated with the master job ID as before, or cancel any subset of them using the naming convention <code>%A_%a</code></p> <pre><code># cancel job steps 10-100\n$ scancel 11510950_[10-100]\n\n# cancel all remaining job steps\n$ scancel 11510950\n</code></pre> <p>What happens if we try to submit a job with, say, <code>--array=0-1000</code>?</p> <pre><code>sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)\n</code></pre> <p>The number of jobs a user may have submitted (not running!) at any given time is limited, in order to avoid overloading the scheduler and to ensure users cannot accidentally swamp the machines with malformed job submissions. To see how many jobs can be run or submitted for a given partition+QOS, use the following command:</p> <pre><code>$ sacctmgr list qos kicp format=maxjobsperuser, maxsubmitjobsperuser\nMaxJobsPU MaxSubmitPU\n--------- -----------\n       64         128\n</code></pre> <p>The ability to submit array jobs which are larger than <code>MaxSubmitPU</code> is coming in a newer version of Slurm. Until then, each job should handle more than one piece of work, or the GNU Parallel solution should be used. For more information, see the RCC documentation section Job arrays.</p>"},{"location":"tutorials/kicp/#workflow-tools","title":"Workflow Tools","text":"<p>Other specialized tools have been created for handling parallel workflows, particularly in specific domains or for specific analysis or computational codes. Developing such tools is an open area of research.</p>"},{"location":"tutorials/msca/","title":"Introduction to RCC for MSc in Analytics","text":"<p>As a student in the Master of Science in Analytics (MScA) Program, you will be able to make use of The University of Chicago\u2019s Research Computing Center (RCC) resources in completing your capstone project.  Some courses in the program will also make use of RCC resources.</p> <p>RCC provides high-end research computing resources to researchers at the University of Chicago. These resources include centrally managed high-performance computing, storage, and visualization hardware, software, scientific and technical user support, as well as education and training opportunities to help researchers effectively make use of modern HPC technology.  To learn more about RCC, see https://rcc.uchicago.edu.</p> <p>Below are the basics you will need to know in order to get up and running at RCC.  For complete RCC technical documentation, see the main sections of this user guide. </p>"},{"location":"tutorials/msca/#getting-help","title":"Getting Help","text":"<p>RCC support staff is available to assist with technical issues (help logging in, questions about using the cluster, etc).  Please don\u2019t hesitate to ask questions if you encounter any technical issues.</p> <ul> <li> <p>The preferred way of requesting support is to contact our Help Desk.</p> </li> <li> <p>RCC\u2019s walk-in lab is open during business hours and is located in Regenstein Library room 216. Feel free to drop by to chat with one of our staff members if you get stuck.</p> </li> </ul>"},{"location":"tutorials/msca/#logging-into-midway","title":"Logging into Midway","text":"<p>For the most complete documentation regarding connecting to RCC resources see: Connecting to Midway.</p>"},{"location":"tutorials/msca/#using-midway","title":"Using Midway","text":"<p>See Running Jobs on Midway for detailed documentation on how to run your own programs on the cluster once you've connected. </p>"},{"location":"tutorials/msca/#software","title":"Software","text":"<p>Many commonly used software packages and libraries have been installed on Midway for your use.  For an overview of how to use Software Modules on Midway, consult the RCC Software documentation page.</p>"},{"location":"tutorials/msca/#sas","title":"SAS","text":"<p>SAS Studio is available to MScA students. SAS Studio is a web application frontend to SAS. To access SAS Studio, visit this link and log in with your CNetID and password:</p> <p>https://sas-studio.rcc.uchicago.edu</p> <p>Also, an instance of SAS Enterprise Miner is available to MScA students.  To access SAS Enterprise Miner, you can visit this link:</p> <p>https://sas-miner.rcc.uchicago.edu:8343/SASEnterpriseMinerJWS/Status</p> <p>SAS software is also available on Midway.  To load the SAS software module, use the command <code>module load sas</code>. It is recommended to use ThinLinc as described above to login to Midway if you want to use SAS in this manner.</p>"},{"location":"tutorials/msca/#nielsen-data","title":"Nielsen Data","text":"<p>The MScA program has obtained a subset of the Nielsen Homescan data for use in teaching and research projects.  Access to this data is controlled by MScA administration.  If you require access to this data, please consult your instructor or the MScA director and request that you be approved for access to the data.</p> <p>Once your user account has been approved for access to the Nielsen data, you will be able to access the data in the directory <code>/project/msca/data/nielsen/</code> on Midway.</p>"}]}